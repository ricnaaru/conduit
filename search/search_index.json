{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introduction Conduit Conduit is a fork from Stablekernel's Aqueduct webserver framework. The project originally split off when null-safety was introduced as a feature in Dart. Stablekernel elected to discontinue development for Aqueduct and a community effort began to resurrect the framework as Conduit. Getting Started For an educational experience read the Core Concepts page while working through the tutorial . If you simply need to start up a project quickly, you can use templates to deploy servers with authentication and database logic allready implemented. For additional information about Conduit read the API Reference . Conduit is catered towards test-driven development - the best way to write an application is to write tests using a test harness and run those tests after implementing an endpoint. You may also run the command conduit document client in your project directory to generate a web client for your application. This client can be opened in any browser and will execute requests against your locally running application.","title":"Introduction"},{"location":"#introduction","text":"","title":"Introduction"},{"location":"#conduit","text":"Conduit is a fork from Stablekernel's Aqueduct webserver framework. The project originally split off when null-safety was introduced as a feature in Dart. Stablekernel elected to discontinue development for Aqueduct and a community effort began to resurrect the framework as Conduit.","title":"Conduit"},{"location":"#getting-started","text":"For an educational experience read the Core Concepts page while working through the tutorial . If you simply need to start up a project quickly, you can use templates to deploy servers with authentication and database logic allready implemented. For additional information about Conduit read the API Reference . Conduit is catered towards test-driven development - the best way to write an application is to write tests using a test harness and run those tests after implementing an endpoint. You may also run the command conduit document client in your project directory to generate a web client for your application. This client can be opened in any browser and will execute requests against your locally running application.","title":"Getting Started"},{"location":"SUMMARY/","text":"Table of contents Introduction Core Concepts Best Practices In-depth Tutorial Getting Started Reading from a Database Storing Data in a Database Configuration and Writing Tests Authentication and Authorization with OAuth 2.0 Deploying a Conduit Application Deploying Conduit Deploy on a Local Machine Deploying on Docker Creating an Executable Script HTTP/REST Serving Files and Caching Uploading Files Handling Requests: Fundamentals Serializing Request and Response Bodies ResourceController Using Websockets in Conduit Routing Application Configuring an Application and its Environment Starting and Stopping an Application Multi-threading in Conduit Application and Project Structure Database access Database Migration and Tooling Connecting to a Database from Conduit Database Transactions Advanced Queries: Filtering, Joins, Paging and Reduce Validating Data Inserting, Updating, Deleting and Fetching Objects JSON Document Storage Modeling Data ManagedObject Serialization and Deserialization MySql Authentication Creating AuthServers to Authenticate and Authorize Manage OAuth 2.0 Clients Issue Access Tokens with AuthController auth_scopes Securing Routes with Authorizer Testing Using Conduit when Writing Client Applications Testing in Conduit Testing Applications That Use ORM and OAuth 2.0 Mocking External Services Debugging Conduit Applications Snippets Conduit Snippets Conduit HTTP Snippets Conduit ORM Snippets Conduit Authorization and Authentication Snippets OpenAPI Document Components Documenting Endpoint Controllers Creating OpenAPI Documents Documenting Middleware Controllers","title":"Table of contents"},{"location":"SUMMARY/#table-of-contents","text":"Introduction Core Concepts Best Practices In-depth Tutorial Getting Started Reading from a Database Storing Data in a Database Configuration and Writing Tests Authentication and Authorization with OAuth 2.0 Deploying a Conduit Application Deploying Conduit Deploy on a Local Machine Deploying on Docker Creating an Executable Script HTTP/REST Serving Files and Caching Uploading Files Handling Requests: Fundamentals Serializing Request and Response Bodies ResourceController Using Websockets in Conduit Routing Application Configuring an Application and its Environment Starting and Stopping an Application Multi-threading in Conduit Application and Project Structure Database access Database Migration and Tooling Connecting to a Database from Conduit Database Transactions Advanced Queries: Filtering, Joins, Paging and Reduce Validating Data Inserting, Updating, Deleting and Fetching Objects JSON Document Storage Modeling Data ManagedObject Serialization and Deserialization MySql Authentication Creating AuthServers to Authenticate and Authorize Manage OAuth 2.0 Clients Issue Access Tokens with AuthController auth_scopes Securing Routes with Authorizer Testing Using Conduit when Writing Client Applications Testing in Conduit Testing Applications That Use ORM and OAuth 2.0 Mocking External Services Debugging Conduit Applications Snippets Conduit Snippets Conduit HTTP Snippets Conduit ORM Snippets Conduit Authorization and Authentication Snippets OpenAPI Document Components Documenting Endpoint Controllers Creating OpenAPI Documents Documenting Middleware Controllers","title":"Table of contents"},{"location":"best_practices/","text":"Best Practices for Developing Conduit Applications Keep Dart Projects Separate Because Dart is cross-platform, developers should avoid combining client application projects with Conduit projects. Instead, use a single repository with an independent project for each facet of the system. When there are opportunities for code sharing between platforms (typically between Flutter and AngularDart), shared code can live in a dependency project in the same repository. A typical directory structure for an multi-faceted application looks like this: application_name/ conduit/ flutter/ angular/ shared/ {% hint style=\"info\" %} \"Project Definition\" A project is a directory that contain a pubspec.yaml file and lib directory. {% endhint %} It is tempting to share your data model types between your server and client applications, but this falls apart for anything but the most simple of applications. There are enough behavioral differences between the four representations of your data model - in the database, on the server, on the wire (JSON), and on the client - that a single type will have a hard time encompassing. Instead, generate an OpenAPI specification with conduit document and use one of the many open-source tools for generating client data model types. Split discrete components into separate packages It can often be useful to split discrete code pieces into separate packages with their own sub-repo. Non-trivial Flutter widgets are a good example. Having the code in a separate package facilitate allocating a single owner to the package. Packages with a single owner have much less management overhead and cleaner commit logs. It also stops developers treading on each others toes. Remember a component isn't just a flutter widget. It can be a collection of classes/functions that provide a specific service, this could be something like permission management or formating/parsing monetary amounts. Any collection of code that together delivers a singular 'concern' is a good candidate. Use Test Driven Development (or something close to it) In Conduit, testing is a first-class citizen. The conduit_test package has classes and methods for initializing and running an application for testing, making requests to that application, and verifying the responses. There is value to using tools like Postman or CURL to test proof of concept code, but the conduit_test package is geared specifically for replacing these tools while retaining automated tests as the project grows. An example test suite looks like this: void main() { final harness = new Harness()..install(); test(\"GET /endpoint returns 200 and a simple object\", () async { final response = await harness.agent.get(\"/endpoint\"); expectResponse(response, 200, body: {\"key\": \"value\"}); }); } Use a bin Script to Verify Assumptions Keep a simple Dart script file in the bin/ directory that imports your project. Use this file as a scratchpad to test exploratory code before committing to a test suite. Don't check this file into source control. import 'package:myapp/myapp.dart'; Future main() async { var whatIsThis = await someYetToBeNamedUsefullyMethod(); print(\"$whatIsThis\"); } Create New Projects from a Template Use conduit create to create applications with the appropriate structure and boilerplate. There are templates for different kinds of applications; view these templates with conduit create list-templates . Use a Debugger A debugger allows you to stop execution of a running application at a particular line of code to verify variable values, and then continue to step through that code line by line. It can be used when running test suites or when running the application through the bin/main.dart script. In IntelliJ IDEA, right-click on any file with a main function (which includes test suites) and select Debug option. Use breakpoints (by clicking on the gutter area to the left of the text editing area) to stop execution at a particular line before it is executed. Use the Suggested Project Directory Structure See Conduit Project Structure . Pass Services to Controllers in entryPoint Pass service objects to controllers in entryPoint and only pass the services the controller will use. class AppChannel extends ApplicationChannel { GitHub githubService; PostgreSQLConnection databaseConnection; @override Future prepare() async { databaseConnection = new PostgreSQLConnection(); githubService = new GitHub(); } @override Controller get entryPoint { final router = new Router(); router .route(\"/data\") .link(() => new DBController(databaseConnection)); router .route(\"/github\") .link(() => new GitHubController(githubService)); return router; } } Passing references like this allows for injecting dependencies that depend on the environment; e.g. in production, development or during tests. It also avoids tight coupling between the objects in your application. Minimize the access a controller has to its dependencies; e.g. don't pass it a StreamController when it only needs Sink or a Stream . Use a Test Harness A test harness initializes your application in a test suite. It has built in behavior that you can add to for things that are specific to your application. Documentation for using a test harness in your application is located here . Use config.src.yaml Use the convention of config.src.yaml file to prevent configuration errors and inject test dependencies. Understand how Conduit Uses Isolates See more in Application Structure . Use ResourceController Subclasses Subclassing ResourceController provides significant conveniences, safeties and behaviors used by the majority of an application's request handling logic. Prefer to use this class for non-middleware controllers. Keep ApplicationChannel Tidy A ApplicationChannel should handle initialization, routing and nothing more. Consider moving non-initialization behavior into a service object in a separate file. Avoid Raw SQL Queries Prefer to use the Conduit ORM. It sends appropriate HTTP responses for different kinds of errors, validates input data and is ensures the queries match up with your data model. Use API Reference Conduit is an object oriented framework - behaviors are implemented by instances of some type. The types of objects, their properties and their behaviors all follow similar naming conventions to make the API more discoverable. Many types in Conduit have a prefix in common with related types. For example, types like AuthServer , AuthServerDelegate and AuthCode are all related because they deal with authentication and authorization. Methods are named consistently across classes (e.g, asMap is a common method name). When looking for a solution, look at the API reference for the objects you have access to. These objects may already have the behavior you wish to implement or have a reference to an object with that behavior. Use try-catch Sparingly All request handling code is wrapped in a try-catch block that will interpret exceptions and errors and return meaningful HTTP responses. Unknown exceptions will yield a 500 Server Error response. In general, you do not need to use try-catch unless you want a different HTTP response than the one being returned for the exception. Code that throws an exception during initialization should not be caught if the error is fatal to the application launching successfully.","title":"Best Practices"},{"location":"best_practices/#best-practices-for-developing-conduit-applications","text":"","title":"Best Practices for Developing Conduit Applications"},{"location":"best_practices/#keep-dart-projects-separate","text":"Because Dart is cross-platform, developers should avoid combining client application projects with Conduit projects. Instead, use a single repository with an independent project for each facet of the system. When there are opportunities for code sharing between platforms (typically between Flutter and AngularDart), shared code can live in a dependency project in the same repository. A typical directory structure for an multi-faceted application looks like this: application_name/ conduit/ flutter/ angular/ shared/ {% hint style=\"info\" %} \"Project Definition\" A project is a directory that contain a pubspec.yaml file and lib directory. {% endhint %} It is tempting to share your data model types between your server and client applications, but this falls apart for anything but the most simple of applications. There are enough behavioral differences between the four representations of your data model - in the database, on the server, on the wire (JSON), and on the client - that a single type will have a hard time encompassing. Instead, generate an OpenAPI specification with conduit document and use one of the many open-source tools for generating client data model types.","title":"Keep Dart Projects Separate"},{"location":"best_practices/#split-discrete-components-into-separate-packages","text":"It can often be useful to split discrete code pieces into separate packages with their own sub-repo. Non-trivial Flutter widgets are a good example. Having the code in a separate package facilitate allocating a single owner to the package. Packages with a single owner have much less management overhead and cleaner commit logs. It also stops developers treading on each others toes. Remember a component isn't just a flutter widget. It can be a collection of classes/functions that provide a specific service, this could be something like permission management or formating/parsing monetary amounts. Any collection of code that together delivers a singular 'concern' is a good candidate.","title":"Split discrete components into separate packages"},{"location":"best_practices/#use-test-driven-development-or-something-close-to-it","text":"In Conduit, testing is a first-class citizen. The conduit_test package has classes and methods for initializing and running an application for testing, making requests to that application, and verifying the responses. There is value to using tools like Postman or CURL to test proof of concept code, but the conduit_test package is geared specifically for replacing these tools while retaining automated tests as the project grows. An example test suite looks like this: void main() { final harness = new Harness()..install(); test(\"GET /endpoint returns 200 and a simple object\", () async { final response = await harness.agent.get(\"/endpoint\"); expectResponse(response, 200, body: {\"key\": \"value\"}); }); }","title":"Use Test Driven Development (or something close to it)"},{"location":"best_practices/#use-a-bin-script-to-verify-assumptions","text":"Keep a simple Dart script file in the bin/ directory that imports your project. Use this file as a scratchpad to test exploratory code before committing to a test suite. Don't check this file into source control. import 'package:myapp/myapp.dart'; Future main() async { var whatIsThis = await someYetToBeNamedUsefullyMethod(); print(\"$whatIsThis\"); }","title":"Use a bin Script to Verify Assumptions"},{"location":"best_practices/#create-new-projects-from-a-template","text":"Use conduit create to create applications with the appropriate structure and boilerplate. There are templates for different kinds of applications; view these templates with conduit create list-templates .","title":"Create New Projects from a Template"},{"location":"best_practices/#use-a-debugger","text":"A debugger allows you to stop execution of a running application at a particular line of code to verify variable values, and then continue to step through that code line by line. It can be used when running test suites or when running the application through the bin/main.dart script. In IntelliJ IDEA, right-click on any file with a main function (which includes test suites) and select Debug option. Use breakpoints (by clicking on the gutter area to the left of the text editing area) to stop execution at a particular line before it is executed.","title":"Use a Debugger"},{"location":"best_practices/#use-the-suggested-project-directory-structure","text":"See Conduit Project Structure .","title":"Use the Suggested Project Directory Structure"},{"location":"best_practices/#pass-services-to-controllers-in-entrypoint","text":"Pass service objects to controllers in entryPoint and only pass the services the controller will use. class AppChannel extends ApplicationChannel { GitHub githubService; PostgreSQLConnection databaseConnection; @override Future prepare() async { databaseConnection = new PostgreSQLConnection(); githubService = new GitHub(); } @override Controller get entryPoint { final router = new Router(); router .route(\"/data\") .link(() => new DBController(databaseConnection)); router .route(\"/github\") .link(() => new GitHubController(githubService)); return router; } } Passing references like this allows for injecting dependencies that depend on the environment; e.g. in production, development or during tests. It also avoids tight coupling between the objects in your application. Minimize the access a controller has to its dependencies; e.g. don't pass it a StreamController when it only needs Sink or a Stream .","title":"Pass Services to Controllers in entryPoint"},{"location":"best_practices/#use-a-test-harness","text":"A test harness initializes your application in a test suite. It has built in behavior that you can add to for things that are specific to your application. Documentation for using a test harness in your application is located here .","title":"Use a Test Harness"},{"location":"best_practices/#use-configsrcyaml","text":"Use the convention of config.src.yaml file to prevent configuration errors and inject test dependencies.","title":"Use config.src.yaml"},{"location":"best_practices/#understand-how-conduit-uses-isolates","text":"See more in Application Structure .","title":"Understand how Conduit Uses Isolates"},{"location":"best_practices/#use-resourcecontroller-subclasses","text":"Subclassing ResourceController provides significant conveniences, safeties and behaviors used by the majority of an application's request handling logic. Prefer to use this class for non-middleware controllers.","title":"Use ResourceController Subclasses"},{"location":"best_practices/#keep-applicationchannel-tidy","text":"A ApplicationChannel should handle initialization, routing and nothing more. Consider moving non-initialization behavior into a service object in a separate file.","title":"Keep ApplicationChannel Tidy"},{"location":"best_practices/#avoid-raw-sql-queries","text":"Prefer to use the Conduit ORM. It sends appropriate HTTP responses for different kinds of errors, validates input data and is ensures the queries match up with your data model.","title":"Avoid Raw SQL Queries"},{"location":"best_practices/#use-api-reference","text":"Conduit is an object oriented framework - behaviors are implemented by instances of some type. The types of objects, their properties and their behaviors all follow similar naming conventions to make the API more discoverable. Many types in Conduit have a prefix in common with related types. For example, types like AuthServer , AuthServerDelegate and AuthCode are all related because they deal with authentication and authorization. Methods are named consistently across classes (e.g, asMap is a common method name). When looking for a solution, look at the API reference for the objects you have access to. These objects may already have the behavior you wish to implement or have a reference to an object with that behavior.","title":"Use API Reference"},{"location":"best_practices/#use-try-catch-sparingly","text":"All request handling code is wrapped in a try-catch block that will interpret exceptions and errors and return meaningful HTTP responses. Unknown exceptions will yield a 500 Server Error response. In general, you do not need to use try-catch unless you want a different HTTP response than the one being returned for the exception. Code that throws an exception during initialization should not be caught if the error is fatal to the application launching successfully.","title":"Use try-catch Sparingly"},{"location":"core_concepts/","text":"Core Concepts Resources Resources are the things your application exposes through its HTTP API. A resource can be anything - a user profile in an application, a temperature sensor in Antarctica, or a high score for a game. For example, the GitHub API exposes organization, repository, issue and pull request resources; a social network API has profiles, posts, and user relationships. Resources are organized into collections (e.g., all of the posts), for which individual resources within that collection can be uniquely identified (e.g., a single post). Requests are made to an application to retrieve the state of a resource or to provide the desired state of a resource. Most often, resources are represented as JSON arrays and objects. When retrieving a resource, its JSON representation is encoded into the response body. When providing the desired state of a resource, a client sends the JSON representation of the desired resource state in the request body. For more details on the concept of a resource, see the RFC Specification for HTTP/1.1 . Routing Resources are identified by the path of an HTTP request. For example, the URL http://example.com/organizations identifies the collection of organization resources on the server http://example.com . The URL http://example.com/organizations/1 identifies a single organization. An application exposes routes for each resource it manages. A route is a string that matches the path of a request. When a request's path matches a route, the associated handler is invoked to handle the request. Routes look like paths, but have some additional syntax. For example, the route /organizations will match requests with the path /organizations . The route /organizations/:id will match the paths /organizations/1 , /organizations/2 , and so on. Complex routes can be formed with additional syntax. See the guide on routing for usage details. Controllers Controllers are objects that handle requests. For example, a controller might fetch rows from a database and send them to the client in the response body. Another controller might verify the username and password of a request's Authorization header are valid. Controllers are linked together to form a series of actions to take for a request. These linked together controllers are called a channel . If the above examples were linked together, the channel would check if a request were authorized before it sent a response containing database rows. There are two flavors of controllers. An endpoint controller performs operations on a resource or resource collection, and always sends a response. Endpoint controllers fulfill requests by returning the state of a resource or by changing the state of a resource. You write most of your application-specific logic endpoint controllers. A middleware controller takes an action for a request, but isn't responsible for fulfilling the request. Middleware controllers can do many different things and are often reusable in many channels. Most often, a middleware controller validates something about a request before it reaches an endpoint controller. Middleware controllers can send a response for a request, and doing so prevents any other controller in that channel from handling the request. A channel must have exactly one endpoint controller. It can be preceded by zero or more middleware controllers. See the guides on Controllers and ResourceControllers for usage details. The Application Channel The application channel is an object that contains all of the controllers in an application. It designates one controller as the first controller to receive every request called its entry point . Controllers are linked to the entry point (directly or transitively) to form the entire application channel. In nearly every application, the entry point is a router; this controller splits the channel into sub-channels for a given route. The application channel is also responsible for initializing the application's services, reading configuration files and other startup related tasks. See the guide on the Application Channel for more details. Services A service is an object that encapsulates complex tasks or algorithms, external communication or tasks that will be reused across an application. The purpose of a service object is to provide a simple interface to more detailed behavior. For example, a database connection is a service object; a user of a database connection doesn't know the details of how the connection is made or how to encode the query onto the wire, but it can still execute queries. The primary user of service objects are controllers. Services are injected into controllers by passing them as arguments to the controller's constructor. The controller keeps a reference to the service, so that it can use it when handling a request. For more details on injecting services, see the guide on the Application Channel . Isolates Isolates are memory-isolated threads; an object created on one isolate can't be referenced by another isolate. When an application starts, one or more isolates containing replicas of your application code are spawned. This behavior effectively 'load balances' your application across multiple threads. A benefit to this structure is that each isolate has its own set of services, like database connections. This eliminates the need for techniques like 'database connection pooling', because the entire application is effectively 'pooled'. Bindings A request might contain headers, query parameters, a body and path parameters that need to be parsed, validated and used in controller code. Bindings are annotations added to variables that perform this parsing and validation automatically. Appropriate error responses are sent when a bound value can't be parsed into expected type or validation fails. Bindings cut down on boiler plate code and reduce testing surface, making development faster and code easier to reason about. For more information on bindings, see the guide on Resource Controllers . Queries and Data Models Application store information in databases for persistence. Writing database queries by hand is error-prone and doesn't leverage static analysis tools that are so valuable in a Dart application. Conduit's ORM (Object-Relational Mapping) provides statically-typed queries that are easy to write and test. Your application's data model is defined by creating Dart classes. Each class is mapped to a database table, and each property of that class is mapped to a column in that table. Conduit's command-line tool generates database migration files that detect changes in your data model that can be applied to a live, versioned database. A data model can also be represented as a JSON object to build tools on top of your application. For more details, see the guide on Databases . Authorization OAuth 2.0 is a standardized authorization framework. Conduit contains a specification-compliant implementation of an OAuth 2.0 server that can be integrated directly into your application, or stood up alone to provide an authorization server for federated services. This implementation is easily customizable - it can store authorization artifacts - like tokens and client identifiers - in different types of databases or use stateless authorization mechanisms like JWT. The default implementation leverages the Conduit ORM to store artifacts in PostgreSQL. For more details, see the guide on Authorization . Documentation OpenAPI 3.0 is a standardized documentation format for HTTP APIs. Many built-in Conduit objects support 'automatic' documentation. Objects that are specific to your application can build on top of this to immediately document your application for every change you make. For more details, see the guide on OpenAPI Documentation .","title":"Core Concepts"},{"location":"core_concepts/#core-concepts","text":"","title":"Core Concepts"},{"location":"core_concepts/#resources","text":"Resources are the things your application exposes through its HTTP API. A resource can be anything - a user profile in an application, a temperature sensor in Antarctica, or a high score for a game. For example, the GitHub API exposes organization, repository, issue and pull request resources; a social network API has profiles, posts, and user relationships. Resources are organized into collections (e.g., all of the posts), for which individual resources within that collection can be uniquely identified (e.g., a single post). Requests are made to an application to retrieve the state of a resource or to provide the desired state of a resource. Most often, resources are represented as JSON arrays and objects. When retrieving a resource, its JSON representation is encoded into the response body. When providing the desired state of a resource, a client sends the JSON representation of the desired resource state in the request body. For more details on the concept of a resource, see the RFC Specification for HTTP/1.1 .","title":"Resources"},{"location":"core_concepts/#routing","text":"Resources are identified by the path of an HTTP request. For example, the URL http://example.com/organizations identifies the collection of organization resources on the server http://example.com . The URL http://example.com/organizations/1 identifies a single organization. An application exposes routes for each resource it manages. A route is a string that matches the path of a request. When a request's path matches a route, the associated handler is invoked to handle the request. Routes look like paths, but have some additional syntax. For example, the route /organizations will match requests with the path /organizations . The route /organizations/:id will match the paths /organizations/1 , /organizations/2 , and so on. Complex routes can be formed with additional syntax. See the guide on routing for usage details.","title":"Routing"},{"location":"core_concepts/#controllers","text":"Controllers are objects that handle requests. For example, a controller might fetch rows from a database and send them to the client in the response body. Another controller might verify the username and password of a request's Authorization header are valid. Controllers are linked together to form a series of actions to take for a request. These linked together controllers are called a channel . If the above examples were linked together, the channel would check if a request were authorized before it sent a response containing database rows. There are two flavors of controllers. An endpoint controller performs operations on a resource or resource collection, and always sends a response. Endpoint controllers fulfill requests by returning the state of a resource or by changing the state of a resource. You write most of your application-specific logic endpoint controllers. A middleware controller takes an action for a request, but isn't responsible for fulfilling the request. Middleware controllers can do many different things and are often reusable in many channels. Most often, a middleware controller validates something about a request before it reaches an endpoint controller. Middleware controllers can send a response for a request, and doing so prevents any other controller in that channel from handling the request. A channel must have exactly one endpoint controller. It can be preceded by zero or more middleware controllers. See the guides on Controllers and ResourceControllers for usage details.","title":"Controllers"},{"location":"core_concepts/#the-application-channel","text":"The application channel is an object that contains all of the controllers in an application. It designates one controller as the first controller to receive every request called its entry point . Controllers are linked to the entry point (directly or transitively) to form the entire application channel. In nearly every application, the entry point is a router; this controller splits the channel into sub-channels for a given route. The application channel is also responsible for initializing the application's services, reading configuration files and other startup related tasks. See the guide on the Application Channel for more details.","title":"The Application Channel"},{"location":"core_concepts/#services","text":"A service is an object that encapsulates complex tasks or algorithms, external communication or tasks that will be reused across an application. The purpose of a service object is to provide a simple interface to more detailed behavior. For example, a database connection is a service object; a user of a database connection doesn't know the details of how the connection is made or how to encode the query onto the wire, but it can still execute queries. The primary user of service objects are controllers. Services are injected into controllers by passing them as arguments to the controller's constructor. The controller keeps a reference to the service, so that it can use it when handling a request. For more details on injecting services, see the guide on the Application Channel .","title":"Services"},{"location":"core_concepts/#isolates","text":"Isolates are memory-isolated threads; an object created on one isolate can't be referenced by another isolate. When an application starts, one or more isolates containing replicas of your application code are spawned. This behavior effectively 'load balances' your application across multiple threads. A benefit to this structure is that each isolate has its own set of services, like database connections. This eliminates the need for techniques like 'database connection pooling', because the entire application is effectively 'pooled'.","title":"Isolates"},{"location":"core_concepts/#bindings","text":"A request might contain headers, query parameters, a body and path parameters that need to be parsed, validated and used in controller code. Bindings are annotations added to variables that perform this parsing and validation automatically. Appropriate error responses are sent when a bound value can't be parsed into expected type or validation fails. Bindings cut down on boiler plate code and reduce testing surface, making development faster and code easier to reason about. For more information on bindings, see the guide on Resource Controllers .","title":"Bindings"},{"location":"core_concepts/#queries-and-data-models","text":"Application store information in databases for persistence. Writing database queries by hand is error-prone and doesn't leverage static analysis tools that are so valuable in a Dart application. Conduit's ORM (Object-Relational Mapping) provides statically-typed queries that are easy to write and test. Your application's data model is defined by creating Dart classes. Each class is mapped to a database table, and each property of that class is mapped to a column in that table. Conduit's command-line tool generates database migration files that detect changes in your data model that can be applied to a live, versioned database. A data model can also be represented as a JSON object to build tools on top of your application. For more details, see the guide on Databases .","title":"Queries and Data Models"},{"location":"core_concepts/#authorization","text":"OAuth 2.0 is a standardized authorization framework. Conduit contains a specification-compliant implementation of an OAuth 2.0 server that can be integrated directly into your application, or stood up alone to provide an authorization server for federated services. This implementation is easily customizable - it can store authorization artifacts - like tokens and client identifiers - in different types of databases or use stateless authorization mechanisms like JWT. The default implementation leverages the Conduit ORM to store artifacts in PostgreSQL. For more details, see the guide on Authorization .","title":"Authorization"},{"location":"core_concepts/#documentation","text":"OpenAPI 3.0 is a standardized documentation format for HTTP APIs. Many built-in Conduit objects support 'automatic' documentation. Objects that are specific to your application can build on top of this to immediately document your application for every change you make. For more details, see the guide on OpenAPI Documentation .","title":"Documentation"},{"location":"getting_started/","text":"Getting Started with Conduit Installation Install Dart . Activate the Conduit CLI text pub global activate conduit Create a new project. text conduit create my_project Open the project directory in an IntelliJ IDE , Atom or Visual Studio Code . All three IDEs have a Dart plugin. How to Learn Conduit There are different approaches depending on how you prefer to learn. The guided tutorial is a hands-on walkthrough where you build an application while learning basic Conduit concepts. The example repository contains a few deployable applications that you may review or tinker with. The guides (located in the menu on this website) dive deeply into the concepts of Conduit and show example code. Creating a new project and using the API reference to jump right in. It is best to first understand how HTTP requests are responded to - the foundation of Conduit - before moving on to topics such as the ORM and OAuth 2.0. Both the tutorial and the HTTP guides are the primary source of this information. A project created by the conduit tool has example routes connected for modification, too. Creating a Project The conduit create command-line tool creates new Conduit project directories. The default template contains the minimal project structure for running a Conduit application. A project name must be snake_case. conduit create my_project_name Other templates exist that contain foundational code for using Conduit's ORM and OAuth 2.0 implementation. These templates can be listed: conduit create list-templates You may provide the name of a template when creating a project to use that template: conduit create -t db my_project_name Using the Conduit ORM Conduit's ORM uses PostgreSQL. During development, you will need a locally running instance of PostgreSQL. On macOS, installing Postgres.app is a very convenient way to run PostgreSQL locally. For other platforms, see PostgreSQL's downloads page . When creating a project, use the db template. If adding to an existing project, see this guide . To create a database, make sure PostgreSQL is running and open the command-line utility to connect to it. psql !!! warning \"Location of psql with Postgres.app\" If you installed Postgres.app, psql is inside the application bundle. You can run this tool by selecting Open psql from the status bar item in the Finder. Then, create a database that your application will connect to and a user that it will connect with: CREATE DATABASE my_database_name; CREATE USER dart_app WITH PASSWORD 'dart'; GRANT ALL ON DATABASE my_database_name TO dart_app; An application must create a ManagedContext that handles the connection to this database: class MyChannel extends ApplicationChannel { ManagedContext context; @override Future prepare() async { var dataModel = new ManagedDataModel.fromCurrentMirrorSystem(); var store = new PostgreSQLPersistentStore.fromConnectionInfo( \"dart_app\", \"dart\", \"localhost\", 5432, \"my_database_name\"); context = new ManagedContext(dataModel, store); } ... } Once you have declared ManagedObject s in your application, generate the database schema by generating and executing migrations from your project's directory: conduit db generate conduit db upgrade --connect postgres://dart_app:dart@localhost:5432/my_database_name See the guides on connecting to a database and testing with a database for more details on configuring a database connection.","title":"Getting Started"},{"location":"getting_started/#getting-started-with-conduit","text":"","title":"Getting Started with Conduit"},{"location":"getting_started/#installation","text":"Install Dart . Activate the Conduit CLI text pub global activate conduit Create a new project. text conduit create my_project Open the project directory in an IntelliJ IDE , Atom or Visual Studio Code . All three IDEs have a Dart plugin.","title":"Installation"},{"location":"getting_started/#how-to-learn-conduit","text":"There are different approaches depending on how you prefer to learn. The guided tutorial is a hands-on walkthrough where you build an application while learning basic Conduit concepts. The example repository contains a few deployable applications that you may review or tinker with. The guides (located in the menu on this website) dive deeply into the concepts of Conduit and show example code. Creating a new project and using the API reference to jump right in. It is best to first understand how HTTP requests are responded to - the foundation of Conduit - before moving on to topics such as the ORM and OAuth 2.0. Both the tutorial and the HTTP guides are the primary source of this information. A project created by the conduit tool has example routes connected for modification, too.","title":"How to Learn Conduit"},{"location":"getting_started/#creating-a-project","text":"The conduit create command-line tool creates new Conduit project directories. The default template contains the minimal project structure for running a Conduit application. A project name must be snake_case. conduit create my_project_name Other templates exist that contain foundational code for using Conduit's ORM and OAuth 2.0 implementation. These templates can be listed: conduit create list-templates You may provide the name of a template when creating a project to use that template: conduit create -t db my_project_name","title":"Creating a Project"},{"location":"getting_started/#using-the-conduit-orm","text":"Conduit's ORM uses PostgreSQL. During development, you will need a locally running instance of PostgreSQL. On macOS, installing Postgres.app is a very convenient way to run PostgreSQL locally. For other platforms, see PostgreSQL's downloads page . When creating a project, use the db template. If adding to an existing project, see this guide . To create a database, make sure PostgreSQL is running and open the command-line utility to connect to it. psql !!! warning \"Location of psql with Postgres.app\" If you installed Postgres.app, psql is inside the application bundle. You can run this tool by selecting Open psql from the status bar item in the Finder. Then, create a database that your application will connect to and a user that it will connect with: CREATE DATABASE my_database_name; CREATE USER dart_app WITH PASSWORD 'dart'; GRANT ALL ON DATABASE my_database_name TO dart_app; An application must create a ManagedContext that handles the connection to this database: class MyChannel extends ApplicationChannel { ManagedContext context; @override Future prepare() async { var dataModel = new ManagedDataModel.fromCurrentMirrorSystem(); var store = new PostgreSQLPersistentStore.fromConnectionInfo( \"dart_app\", \"dart\", \"localhost\", 5432, \"my_database_name\"); context = new ManagedContext(dataModel, store); } ... } Once you have declared ManagedObject s in your application, generate the database schema by generating and executing migrations from your project's directory: conduit db generate conduit db upgrade --connect postgres://dart_app:dart@localhost:5432/my_database_name See the guides on connecting to a database and testing with a database for more details on configuring a database connection.","title":"Using the Conduit ORM"},{"location":"migration_guide/","text":"Migration: Aqueduct to Conduit Migrating from Aqueduct to Conduit Aqueduct is the predessor to Conduit and was developed by stablekernel who no longer support Aqueduct. Conduit is the community driven fork of Aqueduct. This guide is intended to help users of Aqueduct migrate to Conduit. Significant changes Cli tooling The most obvious change is the name and this is reflected in the cli tooling. The aqueduect cli command is now called conduit. To install conduit you run dart pub global activate conduit Test database In conduit the test database used for unit testing and the test harness had the following attributes: user: dart password: dart db name: dart_test In conduit these have been changed to: user: conduit_test_user password: conduit! db name: conduit_test_db","title":"Migration:  Aqueduct to Conduit"},{"location":"migration_guide/#migration-aqueduct-to-conduit","text":"","title":"Migration:  Aqueduct to Conduit"},{"location":"migration_guide/#migrating-from-aqueduct-to-conduit","text":"Aqueduct is the predessor to Conduit and was developed by stablekernel who no longer support Aqueduct. Conduit is the community driven fork of Aqueduct. This guide is intended to help users of Aqueduct migrate to Conduit.","title":"Migrating from Aqueduct to Conduit"},{"location":"migration_guide/#significant-changes","text":"","title":"Significant changes"},{"location":"migration_guide/#cli-tooling","text":"The most obvious change is the name and this is reflected in the cli tooling. The aqueduect cli command is now called conduit. To install conduit you run dart pub global activate conduit","title":"Cli tooling"},{"location":"migration_guide/#test-database","text":"In conduit the test database used for unit testing and the test harness had the following attributes: user: dart password: dart db name: dart_test In conduit these have been changed to: user: conduit_test_user password: conduit! db name: conduit_test_db","title":"Test database"},{"location":"tour/","text":"Conduit: A Tour The tour demonstrates many of Conduit's features. Command-Line Interface (CLI) The conduit command line tool creates, runs and documents Conduit applications; manages database migrations; and manages OAuth client identifiers. Install by running pub global activate conduit on a machine with Dart installed. Create and run an application: conduit create my_app cd my_app/ conduit serve Initialization A Conduit application starts at an ApplicationChannel . You subclass it once per application to handle initialization tasks like setting up routes and database connections. An example application looks like this: import 'package:conduit/conduit.dart'; class TodoApp extends ApplicationChannel { ManagedContext context; @override Future prepare() async { context = ManagedContext(...); } @override Controller get entryPoint { final router = Router(); router .route(\"/projects/[:id]\") .link(() => ProjectController(context)); return router; } } Routing A router determines which controller object should handle a request. The route specification syntax is a concise syntax to construct routes with variables and optional segments in a single statement. @override Controller get entryPoint { final router = Router(); // Handles /users, /users/1, /users/2, etc. router .route(\"/projects/[:id]\") .link(() => ProjectController()); // Handles any route that starts with /file/ router .route(\"/file/*\") .link(() => FileController()); // Handles the specific route /health router .route(\"/health\") .linkFunction((req) async => Response.ok(null)); return router; } Controllers Controllers handle requests. A controller handles a request by overriding its handle method. This method either returns a response or a request. If a response is returned, that response is sent to the client. If the request is returned, the linked controller handles the request. class SecretKeyAuthorizer extends Controller { @override Future<RequestOrResponse> handle(Request request) async { if (request.raw.headers.value(\"x-secret-key\") == \"secret!\") { return request; } return Response.badRequest(); } } This behavior allows for middleware controllers to be linked together, such that a request goes through a number of steps before it is finally handled. All controllers execute their code in an exception handler. If an exception is thrown in your controller code, a response with an appropriate error code is returned. You subclass HandlerException to provide error response customization for application-specific exceptions. ResourceControllers ResourceControllers are the most often used controller. Each operation - e.g. POST /projects , GET /projects and GET /projects/1 - is mapped to methods in a subclass. Parameters of those methods are annotated to bind the values of the request when the method is invoked. import 'package:conduit/conduit.dart' class ProjectController extends ResourceController { @Operation.get('id') Future<Response> getProjectById(@Bind.path(\"id\") int id) async { // GET /projects/:id return Response.ok(...); } @Operation.post() Future<Response> createProject(@Bind.body() Project project) async { // POST /project final inserted = await insertProject(project); return Response.ok(inserted); } @Operation.get() Future<Response> getAllProjects( @Bind.header(\"x-client-id\") String clientId, {@Bind.query(\"limit\") int limit: 10}) async { // GET /projects return Response.ok(...); } } ManagedObjectControllers ManagedObjectController<T> s are ResourceController s that automatically map a REST interface to database queries; e.g. POST inserts a row, GET gets all row of a type. They do not need to be subclassed, but can be to provide customization. router .route(\"/users/[:id]\") .link(() => ManagedObjectController<Project>(context)); Configuration An application's configuration is written in a YAML file. Each environment your application runs in (e.g., locally, under test, production, development) has different values for things like the port to listen on and database connection credentials. The format of a configuration file is defined by your application. An example looks like: // config.yaml database: host: api.projects.com port: 5432 databaseName: project port: 8000 Subclass Configuration and declare a property for each key in your configuration file: class TodoConfig extends Configuration { TodoConfig(String path) : super.fromFile(File(path)); DatabaseConfiguration database; int port; } The default name of your configuration file is config.yaml , but can be changed at the command-line. You create an instance of your configuration from the configuration file path from your application options: import 'package:conduit/conduit.dart'; class TodoApp extends ApplicationChannel { @override Future prepare() async { var options = TodoConfig(options.configurationFilePath); ... } } Running and Concurrency Conduit applications are run with the conduit serve command line tool. You can attach debugging and instrumentation tools and specify how many threads the application should run on: conduit serve --observe --isolates 5 --port 8888 Conduit applications are multi-isolate (multi-threaded). Each isolate runs a replica of the same web server with its own set of services like database connections. This makes behavior like database connection pooling implicit. PostgreSQL ORM The Query<T> class configures and executes database queries. Its type argument determines what table is to be queried and the type of object you will work with in your code. import 'package:conduit/conduit.dart' class ProjectController extends ResourceController { ProjectController(this.context); final ManagedContext context; @Operation.get() Future<Response> getAllProjects() async { final query = Query<Project>(context); final results = await query.fetch(); return Response.ok(results); } } Configuration of the query - like its WHERE clause - are configured through a fluent, type-safe syntax. A property selector identifies which column of the table to apply an expression to. The following query fetches all project's due in the next week and includes their tasks by joining the related table. final nextWeek = DateTime.now().add(Duration(days: 7)); final query = Query<Project>(context) ..where((project) => project.dueDate).isLessThan(nextWeek) ..join(set: (project) => project.tasks); final projects = await query.fetch(); Rows are inserted or updated by setting the statically-typed values of a query. final insertQuery = Query<Project>(context) ..values.name = \"Build an conduit\" ..values.dueDate = DateTime(year, month); var newProject = await insertQuery.insert(); final updateQuery = Query<Project>(context) ..where((project) => project.id).equalTo(newProject.id) ..values.name = \"Build a miniature conduit\"; newProject = await updateQuery.updateOne(); Query<T> s can perform sorting, joining and paging queries. final overdueQuery = Query<Project>(context) ..where((project) => project.dueDate).lessThan(DateTime().now()) ..sortBy((project) => project.dueDate, QuerySortOrder.ascending) ..join(object: (project) => project.owner); final overdueProjectsAndTheirOwners = await query.fetch(); Controllers will interpret exceptions thrown by queries to return an appropriate error response to the client. For example, unique constraint conflicts return 409, missing required properties return 400 and database connection failure returns 503. Defining a Data Model To use the ORM, you declare your tables as Dart types and create a subclass of ManagedObject<T> . A subclass maps to a table in the database, each instance maps to a row, and each property is a column. The following declaration will map to a table named _project with columns id , name and dueDate . class Project extends ManagedObject<_Project> implements _Project { bool get isPastDue => dueDate.difference(DateTime.now()).inSeconds < 0; } class _Project { @primaryKey int id; @Column(indexed: true) String name; DateTime dueDate; } Managed objects have relationships to other managed objects. Relationships can be has-one, has-many and many-to-many. A relationship is always two-sided - the related types must declare a property that references each other. class Project extends ManagedObject<_Project> implements _Project {} class _Project { ... // Project has-many Tasks ManagedSet<Task> tasks; } class Task extends ManagedObject<_Task> implements _Task {} class _Task { ... // Task belongs to a project, maps to 'project_id' foreign key column @Relate(#tasks) Project project; } ManagedObject<T> s are serializable and can be directly read from a request body, or encoded as a response body. class ProjectController extends ResourceController { @Operation.put('id') Future<Response> updateProject(@Bind.path('id') int projectId, @Bind.body() Project project) async { final query = Query<Project>(context) ..where((project) => project.id).equalTo(projectId) ..values = project; return Response.ok(await query.updateOne()); } } Database Migrations The CLI will automatically generate database migration scripts by detecting changes to your managed objects. The following, when ran in a project directory, will generate and execute a database migration. conduit db generate conduit db upgrade --connect postgres://user:password@host:5432/database You can edit migration files by hand to alter any assumptions or enter required values, and run conduit db validate to ensure the changes still yield the same schema. Be sure to keep generated files in version control. OAuth 2.0 An OAuth 2.0 server implementation handles authentication and authorization for Conduit applications. You create an AuthServer and its delegate as services in your application. The delegate is configurable and manages how tokens are generated and stored. By default, access tokens are a random 32-byte string and client identifiers, tokens and access codes are stored in your database using the ORM. import 'package:conduit/conduit.dart'; import 'package:conduit/managed_auth.dart'; class AppApplicationChannel extends ApplicationChannel { AuthServer authServer; ManagedContext context; @override Future prepare() async { context = ManagedContext(...); final delegate = ManagedAuthDelegate<User>(context); authServer = AuthServer(delegate); } } Built-in authentication controllers for exchanging user credentials for access tokens are named AuthController and AuthCodeController . Authorizer s are middleware that require a valid access token to access their linked controller. Controller get entryPoint { final router = Router(); // POST /auth/token with username and password (or access code) to get access token router .route(\"/auth/token\") .link(() => AuthController(authServer)); // GET /auth/code returns login form, POST /auth/code grants access code router .route(\"/auth/code\") .link(() => AuthCodeController(authServer)); // ProjectController requires request to include access token router .route(\"/projects/[:id]\") .link(() => Authorizer.bearer(authServer)) .link(() => ProjectController(context)); return router; } The CLI has tools to manage OAuth 2.0 client identifiers and access scopes. conduit auth add-client \\ --id com.app.mobile \\ --secret foobar \\ --redirect-uri https://somewhereoutthere.com \\ --allowed-scopes \"users projects admin.readonly\" Logging All requests are logged to an application-wide logger. Set up a listener for the logger in ApplicationChannel to write log messages to the console or another medium. class WildfireChannel extends ApplicationChannel { @override Future prepare() async { logger.onRecord.listen((record) { print(\"$record\"); }); } } Testing Conduit tests start a local version of your application and execute requests. You write expectations on the responses. A TestHarness manages the starting and stopping of an application, and exposes a default Agent for executing requests. An Agent can be configured to have default headers, and multiple agents can be used within the same test. import 'harness/app.dart'; void main() { final harness = TestHarness<TodoApp>()..install(); test(\"GET /projects returns all projects\" , () async { var response = await harness.agent.get(\"/projects\"); expectResponse(response, 200, body: every(partial({ \"id\": greaterThan(0), \"name\": isNotNull, \"dueDate\": isNotNull }))); }); } Testing with a Database Conduit's ORM uses PostgreSQL as its database. Before your tests run, Conduit will create your application's database tables in a local PostgreSQL database. After the tests complete, it will delete those tables. This allows you to start with an empty database for each test suite as well as control exactly which records are in your database while testing, but without having to manage database schemas or use an mock implementation (e.g., SQLite). This behavior, and behavior for managing applications with an OAuth 2.0 provider, are available as harness mixins . Documentation OpenAPI documents describe your application's interface. These documents can be used to generate documentation and client code. A document can be generated by reflecting on your application's codebase, just run the conduit document command. The conduit document client command creates a web page that can be used to configure issue requests specific to your application.","title":"Tour"},{"location":"tour/#conduit-a-tour","text":"The tour demonstrates many of Conduit's features.","title":"Conduit: A Tour"},{"location":"tour/#command-line-interface-cli","text":"The conduit command line tool creates, runs and documents Conduit applications; manages database migrations; and manages OAuth client identifiers. Install by running pub global activate conduit on a machine with Dart installed. Create and run an application: conduit create my_app cd my_app/ conduit serve","title":"Command-Line Interface (CLI)"},{"location":"tour/#initialization","text":"A Conduit application starts at an ApplicationChannel . You subclass it once per application to handle initialization tasks like setting up routes and database connections. An example application looks like this: import 'package:conduit/conduit.dart'; class TodoApp extends ApplicationChannel { ManagedContext context; @override Future prepare() async { context = ManagedContext(...); } @override Controller get entryPoint { final router = Router(); router .route(\"/projects/[:id]\") .link(() => ProjectController(context)); return router; } }","title":"Initialization"},{"location":"tour/#routing","text":"A router determines which controller object should handle a request. The route specification syntax is a concise syntax to construct routes with variables and optional segments in a single statement. @override Controller get entryPoint { final router = Router(); // Handles /users, /users/1, /users/2, etc. router .route(\"/projects/[:id]\") .link(() => ProjectController()); // Handles any route that starts with /file/ router .route(\"/file/*\") .link(() => FileController()); // Handles the specific route /health router .route(\"/health\") .linkFunction((req) async => Response.ok(null)); return router; }","title":"Routing"},{"location":"tour/#controllers","text":"Controllers handle requests. A controller handles a request by overriding its handle method. This method either returns a response or a request. If a response is returned, that response is sent to the client. If the request is returned, the linked controller handles the request. class SecretKeyAuthorizer extends Controller { @override Future<RequestOrResponse> handle(Request request) async { if (request.raw.headers.value(\"x-secret-key\") == \"secret!\") { return request; } return Response.badRequest(); } } This behavior allows for middleware controllers to be linked together, such that a request goes through a number of steps before it is finally handled. All controllers execute their code in an exception handler. If an exception is thrown in your controller code, a response with an appropriate error code is returned. You subclass HandlerException to provide error response customization for application-specific exceptions.","title":"Controllers"},{"location":"tour/#resourcecontrollers","text":"ResourceControllers are the most often used controller. Each operation - e.g. POST /projects , GET /projects and GET /projects/1 - is mapped to methods in a subclass. Parameters of those methods are annotated to bind the values of the request when the method is invoked. import 'package:conduit/conduit.dart' class ProjectController extends ResourceController { @Operation.get('id') Future<Response> getProjectById(@Bind.path(\"id\") int id) async { // GET /projects/:id return Response.ok(...); } @Operation.post() Future<Response> createProject(@Bind.body() Project project) async { // POST /project final inserted = await insertProject(project); return Response.ok(inserted); } @Operation.get() Future<Response> getAllProjects( @Bind.header(\"x-client-id\") String clientId, {@Bind.query(\"limit\") int limit: 10}) async { // GET /projects return Response.ok(...); } }","title":"ResourceControllers"},{"location":"tour/#managedobjectcontrollers","text":"ManagedObjectController<T> s are ResourceController s that automatically map a REST interface to database queries; e.g. POST inserts a row, GET gets all row of a type. They do not need to be subclassed, but can be to provide customization. router .route(\"/users/[:id]\") .link(() => ManagedObjectController<Project>(context));","title":"ManagedObjectControllers"},{"location":"tour/#configuration","text":"An application's configuration is written in a YAML file. Each environment your application runs in (e.g., locally, under test, production, development) has different values for things like the port to listen on and database connection credentials. The format of a configuration file is defined by your application. An example looks like: // config.yaml database: host: api.projects.com port: 5432 databaseName: project port: 8000 Subclass Configuration and declare a property for each key in your configuration file: class TodoConfig extends Configuration { TodoConfig(String path) : super.fromFile(File(path)); DatabaseConfiguration database; int port; } The default name of your configuration file is config.yaml , but can be changed at the command-line. You create an instance of your configuration from the configuration file path from your application options: import 'package:conduit/conduit.dart'; class TodoApp extends ApplicationChannel { @override Future prepare() async { var options = TodoConfig(options.configurationFilePath); ... } }","title":"Configuration"},{"location":"tour/#running-and-concurrency","text":"Conduit applications are run with the conduit serve command line tool. You can attach debugging and instrumentation tools and specify how many threads the application should run on: conduit serve --observe --isolates 5 --port 8888 Conduit applications are multi-isolate (multi-threaded). Each isolate runs a replica of the same web server with its own set of services like database connections. This makes behavior like database connection pooling implicit.","title":"Running and Concurrency"},{"location":"tour/#postgresql-orm","text":"The Query<T> class configures and executes database queries. Its type argument determines what table is to be queried and the type of object you will work with in your code. import 'package:conduit/conduit.dart' class ProjectController extends ResourceController { ProjectController(this.context); final ManagedContext context; @Operation.get() Future<Response> getAllProjects() async { final query = Query<Project>(context); final results = await query.fetch(); return Response.ok(results); } } Configuration of the query - like its WHERE clause - are configured through a fluent, type-safe syntax. A property selector identifies which column of the table to apply an expression to. The following query fetches all project's due in the next week and includes their tasks by joining the related table. final nextWeek = DateTime.now().add(Duration(days: 7)); final query = Query<Project>(context) ..where((project) => project.dueDate).isLessThan(nextWeek) ..join(set: (project) => project.tasks); final projects = await query.fetch(); Rows are inserted or updated by setting the statically-typed values of a query. final insertQuery = Query<Project>(context) ..values.name = \"Build an conduit\" ..values.dueDate = DateTime(year, month); var newProject = await insertQuery.insert(); final updateQuery = Query<Project>(context) ..where((project) => project.id).equalTo(newProject.id) ..values.name = \"Build a miniature conduit\"; newProject = await updateQuery.updateOne(); Query<T> s can perform sorting, joining and paging queries. final overdueQuery = Query<Project>(context) ..where((project) => project.dueDate).lessThan(DateTime().now()) ..sortBy((project) => project.dueDate, QuerySortOrder.ascending) ..join(object: (project) => project.owner); final overdueProjectsAndTheirOwners = await query.fetch(); Controllers will interpret exceptions thrown by queries to return an appropriate error response to the client. For example, unique constraint conflicts return 409, missing required properties return 400 and database connection failure returns 503.","title":"PostgreSQL ORM"},{"location":"tour/#defining-a-data-model","text":"To use the ORM, you declare your tables as Dart types and create a subclass of ManagedObject<T> . A subclass maps to a table in the database, each instance maps to a row, and each property is a column. The following declaration will map to a table named _project with columns id , name and dueDate . class Project extends ManagedObject<_Project> implements _Project { bool get isPastDue => dueDate.difference(DateTime.now()).inSeconds < 0; } class _Project { @primaryKey int id; @Column(indexed: true) String name; DateTime dueDate; } Managed objects have relationships to other managed objects. Relationships can be has-one, has-many and many-to-many. A relationship is always two-sided - the related types must declare a property that references each other. class Project extends ManagedObject<_Project> implements _Project {} class _Project { ... // Project has-many Tasks ManagedSet<Task> tasks; } class Task extends ManagedObject<_Task> implements _Task {} class _Task { ... // Task belongs to a project, maps to 'project_id' foreign key column @Relate(#tasks) Project project; } ManagedObject<T> s are serializable and can be directly read from a request body, or encoded as a response body. class ProjectController extends ResourceController { @Operation.put('id') Future<Response> updateProject(@Bind.path('id') int projectId, @Bind.body() Project project) async { final query = Query<Project>(context) ..where((project) => project.id).equalTo(projectId) ..values = project; return Response.ok(await query.updateOne()); } }","title":"Defining a Data Model"},{"location":"tour/#database-migrations","text":"The CLI will automatically generate database migration scripts by detecting changes to your managed objects. The following, when ran in a project directory, will generate and execute a database migration. conduit db generate conduit db upgrade --connect postgres://user:password@host:5432/database You can edit migration files by hand to alter any assumptions or enter required values, and run conduit db validate to ensure the changes still yield the same schema. Be sure to keep generated files in version control.","title":"Database Migrations"},{"location":"tour/#oauth-20","text":"An OAuth 2.0 server implementation handles authentication and authorization for Conduit applications. You create an AuthServer and its delegate as services in your application. The delegate is configurable and manages how tokens are generated and stored. By default, access tokens are a random 32-byte string and client identifiers, tokens and access codes are stored in your database using the ORM. import 'package:conduit/conduit.dart'; import 'package:conduit/managed_auth.dart'; class AppApplicationChannel extends ApplicationChannel { AuthServer authServer; ManagedContext context; @override Future prepare() async { context = ManagedContext(...); final delegate = ManagedAuthDelegate<User>(context); authServer = AuthServer(delegate); } } Built-in authentication controllers for exchanging user credentials for access tokens are named AuthController and AuthCodeController . Authorizer s are middleware that require a valid access token to access their linked controller. Controller get entryPoint { final router = Router(); // POST /auth/token with username and password (or access code) to get access token router .route(\"/auth/token\") .link(() => AuthController(authServer)); // GET /auth/code returns login form, POST /auth/code grants access code router .route(\"/auth/code\") .link(() => AuthCodeController(authServer)); // ProjectController requires request to include access token router .route(\"/projects/[:id]\") .link(() => Authorizer.bearer(authServer)) .link(() => ProjectController(context)); return router; } The CLI has tools to manage OAuth 2.0 client identifiers and access scopes. conduit auth add-client \\ --id com.app.mobile \\ --secret foobar \\ --redirect-uri https://somewhereoutthere.com \\ --allowed-scopes \"users projects admin.readonly\"","title":"OAuth 2.0"},{"location":"tour/#logging","text":"All requests are logged to an application-wide logger. Set up a listener for the logger in ApplicationChannel to write log messages to the console or another medium. class WildfireChannel extends ApplicationChannel { @override Future prepare() async { logger.onRecord.listen((record) { print(\"$record\"); }); } }","title":"Logging"},{"location":"tour/#testing","text":"Conduit tests start a local version of your application and execute requests. You write expectations on the responses. A TestHarness manages the starting and stopping of an application, and exposes a default Agent for executing requests. An Agent can be configured to have default headers, and multiple agents can be used within the same test. import 'harness/app.dart'; void main() { final harness = TestHarness<TodoApp>()..install(); test(\"GET /projects returns all projects\" , () async { var response = await harness.agent.get(\"/projects\"); expectResponse(response, 200, body: every(partial({ \"id\": greaterThan(0), \"name\": isNotNull, \"dueDate\": isNotNull }))); }); }","title":"Testing"},{"location":"tour/#testing-with-a-database","text":"Conduit's ORM uses PostgreSQL as its database. Before your tests run, Conduit will create your application's database tables in a local PostgreSQL database. After the tests complete, it will delete those tables. This allows you to start with an empty database for each test suite as well as control exactly which records are in your database while testing, but without having to manage database schemas or use an mock implementation (e.g., SQLite). This behavior, and behavior for managing applications with an OAuth 2.0 provider, are available as harness mixins .","title":"Testing with a Database"},{"location":"tour/#documentation","text":"OpenAPI documents describe your application's interface. These documents can be used to generate documentation and client code. A document can be generated by reflecting on your application's codebase, just run the conduit document command. The conduit document client command creates a web page that can be used to configure issue requests specific to your application.","title":"Documentation"},{"location":"application/","text":"Application A Conduit application starts an HTTP server and invokes your code for each request. The code that is invoked might depend on the request's path, method, and other attributes. For example, the request GET /heroes will invoke different code than POST /authors . You configure which code is invoked in an ApplicationChannel subclass; every application declares exactly one ApplicationChannel subclass. This subclass also sets up services, reads configuration data from files and environment variables and performs any other initialization for your application. For example, an application channel often reads database connection information from environment variables and then sets up a connection to that database. Conduit applications create multiple threads, and each thread takes turn handling incoming requests. Your application channel subclass is created for each thread, creating replica instances of your application. Guides Starting and Stopping Applications Configuring an Application and its Environment Application and Project Structure Performance: Multi-threading","title":"Application"},{"location":"application/#application","text":"A Conduit application starts an HTTP server and invokes your code for each request. The code that is invoked might depend on the request's path, method, and other attributes. For example, the request GET /heroes will invoke different code than POST /authors . You configure which code is invoked in an ApplicationChannel subclass; every application declares exactly one ApplicationChannel subclass. This subclass also sets up services, reads configuration data from files and environment variables and performs any other initialization for your application. For example, an application channel often reads database connection information from environment variables and then sets up a connection to that database. Conduit applications create multiple threads, and each thread takes turn handling incoming requests. Your application channel subclass is created for each thread, creating replica instances of your application.","title":"Application"},{"location":"application/#guides","text":"Starting and Stopping Applications Configuring an Application and its Environment Application and Project Structure Performance: Multi-threading","title":"Guides"},{"location":"application/channel/","text":"Starting and Stopping an Application Learn how an application is initialized so it can serve requests. Overview Applications are started by running conduit serve or dart bin/main.script in a Conduit project directory. Either way, a number of threads are created and your ApplicationChannel subclass is instantiated on each thread. The channel subclass initializes application behavior which is often the following: reads configuration data for environment specific setup initializes service objects like database connections sets up controller objects to handle requests Initializing ApplicationChannel Controllers Each application channel has an entry point - a controller that handles all incoming requests. This controller is often a router that routes requests to an appropriate handler. Every controller that will be used in the application is linked to either the entry point in some way. Here's an example: class AppChannel extends ApplicationChannel { @override Controller get entryPoint { final router = new Router(); router .route(\"/users\") .link(() => Authorizer()) .link(() => UserController()); return router; } } This method links together a Router -> Authorizer -> UserController . Because the router is returned from this method, it handles all incoming requests. It will pass a request to an Authorizer when the request path is /users , which will then pass that request to a UserController if it is authorized. All controllers in your application will be linked to the entry point, either directly or indirectly. !!! note \"Linking Controllers\" The link() method takes a closure that creates a new controller. Some controllers get instantiated for each request, and others get reused for every request. See the chapter on controllers for more information. Initializing Service Objects Controllers often need to get (or create) information from outside the application. The most common example is database access, but it could be anything: another REST API, a connected device, etc. A service object encapsulates the information and behavior needed to work with an external system. This separation of concerns between controllers and service objects allows for better structured and more testable code. Service objects are instantiated by overriding ApplicationChannel.prepare . class AppChannel extends ApplicationChannel { PostgreSQLConnection database; @override Future prepare() async { database = PostgreSQLConnection(); } @override Controller get entryPoint { final router = new Router(); router .route(\"/users\") .link(() => new Authorizer()) .link(() => new UserController(database)); return router; } } This methods gets invoked before entryPoint . You store created services in instance variables so that you can inject them into controllers in entryPoint . Services are injected through a controller's constructor arguments. For example, the above shows a database service that is injected into UserController . Application Channel Configuration A benefit to using service objects is that they can be altered depending on the environment the application is running in without requiring changes to code. For example, the database an application will connect to will be different when running in production than when running tests. Besides service configuration, there may be other types of initialization an application wants to take. Common tasks include adding codecs to CodecRegistry or setting the default CORSPolicy . All of this initialization is done in prepare() . Some of the information needed to configure an application will come from a configuration file or environment variables. For more information on using a configuration file and environment variables to guide initialization, see this guide . Multi-threaded Conduit Applications Conduit applications can - and should - be spread across a number of threads. This allows an application to take advantage of multiple CPUs and serve requests faster. In Dart, threads are called isolates . An instance of your ApplicationChannel is created for each isolate. When your application receives an HTTP request, the request is passed to one of these instances' entry points. These instances are replicas of one another and it doesn't matter which instance processes the request. This isolate-channel architecture is very similar to running multiple servers that run the same application. The number of isolates an application will use is configurable at startup when using the conduit serve command. An isolate can't share memory with another isolate. If an object is created on one isolate, it cannot be referenced by another. Therefore, each ApplicationChannel instance has its own set of services that are configured in the same way. This behavior also makes design patterns like connection pooling implicit; instead of a pool of database connections, there is a pool of application channels that each have their own database connection. This architecture intentionally prevents you from keeping state in your application. When you scale to multiple servers, you can trust that your cluster works correctly because you are already effectively clustering on a single server node. For further reading on writing multi-threaded applications, see this guide . Initialization Callbacks Both prepare() and entryPoint are part of the initialization process of an application channel. Most applications only ever need these two methods. Another method, that is rarely used, is willStartReceivingRequests() . This method is called after prepare() and entryPoint have been executed, and right before your application will start receiving requests. These three initialization callbacks are called once per isolate to initialize the channel running on that isolate. For initialization that should only occur once per application start (regardless of how many isolates are running), an ApplicationChannel subclass can implement a static method named initializeApplication() . class AppChannel extends ApplicationChannel { static Future initializeApplication(ApplicationOptions options) async { ... do one time setup ... } ... } This method is invoked before any ApplicationChannel instances are created. Any changes made to options will be available in each ApplicationChannel 's options property. For example: class AppChannel extends ApplicationChannel { static Future initializeApplication(ApplicationOptions options) async { options.context[\"special item\"] = \"xyz\"; } Future prepare() async { var parsedConfigValues = options.context[\"special item\"]; // == xyz ... } } Each isolate has its own heap. initializeApplication is executed in the main isolate, whereas each ApplicationChannel is instantiated in its own isolate. This means that any values stored in ApplicationOptions must be safe to pass across isolates - i.e., they can't contain references to closures. Additionally, any global variables or static properties that are set in the main isolate will not be set in other isolates. Configuration types like CodecRegistry do not share values across isolates, because they use a static property to hold a reference to the repository of codecs. Therefore, they must be set up in ApplicationChannel.prepare() . Also, because static methods cannot be overridden in Dart, it is important that you ensure the name and signature of initializeApplication exactly matches what is shown in these code samples. The analyzer can't help you here, unfortunately. Application Channel File An ApplicationChannel subclass is most often declared in its own file named lib/channel.dart . This file must be exported from the application library file. For example, if the application is named wildfire , the application library file is lib/wildfire.dart . Here is a sample directory structure: wildfire/ lib/ wildfire.dart channel.dart controllers/ user_controller.dart ... See this guide for more details on how a Conduit application's files are structured. Lazy Services Many service objects will establish a persistent network connection. A network connection can sometimes be interrupted and have to re-establish itself. If these connections are only opened when the application first starts, the application will not be able to reopen these connections without restarting the application. This would be very bad. For that reason, services should manage their own connectivity behavior. For example, a database connection should connect it when it is asked to execute a query. If it already has a valid connection, it will go ahead and execute the query. Otherwise, it will establish the connection and then execute the query. The caller doesn't care - it gets a Future with the desired result. The pseudo-code looks something like this: Future execute(String sql) async { if (connection == null || !connection.isAvailable) { connection = new Connection(...); await connection.open(); } return connection.executeSQL(sql); } The Application Object Hidden in all of this discussion is the Application<T> object. Because the conduit serve command manages creating an Application<T> instance, your code rarely concerns itself with this type. An Application<T> is the top-level object in a Conduit application; it sets up HTTP listeners and directs requests to ApplicationChannel s. The Application<T> itself is just a generic container for ApplicationChannel s; it doesn't do much other than kick everything off. The application's start method will initialize at least one instance of the application's ApplicationChannel . If something goes wrong during this initialization process, the application will throw an exception and halt starting the server. For example, setting up an invalid route in a ApplicationChannel subclass would trigger this type of startup exception. An Application<T> has a number of options that determine how it will listen for HTTP requests, such as which port it is listening on or the SSL certificate it will use. These values are available in the channel's options property, an instance of ApplicationOptions .","title":"Starting and Stopping Applications"},{"location":"application/channel/#starting-and-stopping-an-application","text":"Learn how an application is initialized so it can serve requests.","title":"Starting and Stopping an Application"},{"location":"application/channel/#overview","text":"Applications are started by running conduit serve or dart bin/main.script in a Conduit project directory. Either way, a number of threads are created and your ApplicationChannel subclass is instantiated on each thread. The channel subclass initializes application behavior which is often the following: reads configuration data for environment specific setup initializes service objects like database connections sets up controller objects to handle requests","title":"Overview"},{"location":"application/channel/#initializing-applicationchannel-controllers","text":"Each application channel has an entry point - a controller that handles all incoming requests. This controller is often a router that routes requests to an appropriate handler. Every controller that will be used in the application is linked to either the entry point in some way. Here's an example: class AppChannel extends ApplicationChannel { @override Controller get entryPoint { final router = new Router(); router .route(\"/users\") .link(() => Authorizer()) .link(() => UserController()); return router; } } This method links together a Router -> Authorizer -> UserController . Because the router is returned from this method, it handles all incoming requests. It will pass a request to an Authorizer when the request path is /users , which will then pass that request to a UserController if it is authorized. All controllers in your application will be linked to the entry point, either directly or indirectly. !!! note \"Linking Controllers\" The link() method takes a closure that creates a new controller. Some controllers get instantiated for each request, and others get reused for every request. See the chapter on controllers for more information.","title":"Initializing ApplicationChannel Controllers"},{"location":"application/channel/#initializing-service-objects","text":"Controllers often need to get (or create) information from outside the application. The most common example is database access, but it could be anything: another REST API, a connected device, etc. A service object encapsulates the information and behavior needed to work with an external system. This separation of concerns between controllers and service objects allows for better structured and more testable code. Service objects are instantiated by overriding ApplicationChannel.prepare . class AppChannel extends ApplicationChannel { PostgreSQLConnection database; @override Future prepare() async { database = PostgreSQLConnection(); } @override Controller get entryPoint { final router = new Router(); router .route(\"/users\") .link(() => new Authorizer()) .link(() => new UserController(database)); return router; } } This methods gets invoked before entryPoint . You store created services in instance variables so that you can inject them into controllers in entryPoint . Services are injected through a controller's constructor arguments. For example, the above shows a database service that is injected into UserController .","title":"Initializing Service Objects"},{"location":"application/channel/#application-channel-configuration","text":"A benefit to using service objects is that they can be altered depending on the environment the application is running in without requiring changes to code. For example, the database an application will connect to will be different when running in production than when running tests. Besides service configuration, there may be other types of initialization an application wants to take. Common tasks include adding codecs to CodecRegistry or setting the default CORSPolicy . All of this initialization is done in prepare() . Some of the information needed to configure an application will come from a configuration file or environment variables. For more information on using a configuration file and environment variables to guide initialization, see this guide .","title":"Application Channel Configuration"},{"location":"application/channel/#multi-threaded-conduit-applications","text":"Conduit applications can - and should - be spread across a number of threads. This allows an application to take advantage of multiple CPUs and serve requests faster. In Dart, threads are called isolates . An instance of your ApplicationChannel is created for each isolate. When your application receives an HTTP request, the request is passed to one of these instances' entry points. These instances are replicas of one another and it doesn't matter which instance processes the request. This isolate-channel architecture is very similar to running multiple servers that run the same application. The number of isolates an application will use is configurable at startup when using the conduit serve command. An isolate can't share memory with another isolate. If an object is created on one isolate, it cannot be referenced by another. Therefore, each ApplicationChannel instance has its own set of services that are configured in the same way. This behavior also makes design patterns like connection pooling implicit; instead of a pool of database connections, there is a pool of application channels that each have their own database connection. This architecture intentionally prevents you from keeping state in your application. When you scale to multiple servers, you can trust that your cluster works correctly because you are already effectively clustering on a single server node. For further reading on writing multi-threaded applications, see this guide .","title":"Multi-threaded Conduit Applications"},{"location":"application/channel/#initialization-callbacks","text":"Both prepare() and entryPoint are part of the initialization process of an application channel. Most applications only ever need these two methods. Another method, that is rarely used, is willStartReceivingRequests() . This method is called after prepare() and entryPoint have been executed, and right before your application will start receiving requests. These three initialization callbacks are called once per isolate to initialize the channel running on that isolate. For initialization that should only occur once per application start (regardless of how many isolates are running), an ApplicationChannel subclass can implement a static method named initializeApplication() . class AppChannel extends ApplicationChannel { static Future initializeApplication(ApplicationOptions options) async { ... do one time setup ... } ... } This method is invoked before any ApplicationChannel instances are created. Any changes made to options will be available in each ApplicationChannel 's options property. For example: class AppChannel extends ApplicationChannel { static Future initializeApplication(ApplicationOptions options) async { options.context[\"special item\"] = \"xyz\"; } Future prepare() async { var parsedConfigValues = options.context[\"special item\"]; // == xyz ... } } Each isolate has its own heap. initializeApplication is executed in the main isolate, whereas each ApplicationChannel is instantiated in its own isolate. This means that any values stored in ApplicationOptions must be safe to pass across isolates - i.e., they can't contain references to closures. Additionally, any global variables or static properties that are set in the main isolate will not be set in other isolates. Configuration types like CodecRegistry do not share values across isolates, because they use a static property to hold a reference to the repository of codecs. Therefore, they must be set up in ApplicationChannel.prepare() . Also, because static methods cannot be overridden in Dart, it is important that you ensure the name and signature of initializeApplication exactly matches what is shown in these code samples. The analyzer can't help you here, unfortunately.","title":"Initialization Callbacks"},{"location":"application/channel/#application-channel-file","text":"An ApplicationChannel subclass is most often declared in its own file named lib/channel.dart . This file must be exported from the application library file. For example, if the application is named wildfire , the application library file is lib/wildfire.dart . Here is a sample directory structure: wildfire/ lib/ wildfire.dart channel.dart controllers/ user_controller.dart ... See this guide for more details on how a Conduit application's files are structured.","title":"Application Channel File"},{"location":"application/channel/#lazy-services","text":"Many service objects will establish a persistent network connection. A network connection can sometimes be interrupted and have to re-establish itself. If these connections are only opened when the application first starts, the application will not be able to reopen these connections without restarting the application. This would be very bad. For that reason, services should manage their own connectivity behavior. For example, a database connection should connect it when it is asked to execute a query. If it already has a valid connection, it will go ahead and execute the query. Otherwise, it will establish the connection and then execute the query. The caller doesn't care - it gets a Future with the desired result. The pseudo-code looks something like this: Future execute(String sql) async { if (connection == null || !connection.isAvailable) { connection = new Connection(...); await connection.open(); } return connection.executeSQL(sql); }","title":"Lazy Services"},{"location":"application/channel/#the-application-object","text":"Hidden in all of this discussion is the Application<T> object. Because the conduit serve command manages creating an Application<T> instance, your code rarely concerns itself with this type. An Application<T> is the top-level object in a Conduit application; it sets up HTTP listeners and directs requests to ApplicationChannel s. The Application<T> itself is just a generic container for ApplicationChannel s; it doesn't do much other than kick everything off. The application's start method will initialize at least one instance of the application's ApplicationChannel . If something goes wrong during this initialization process, the application will throw an exception and halt starting the server. For example, setting up an invalid route in a ApplicationChannel subclass would trigger this type of startup exception. An Application<T> has a number of options that determine how it will listen for HTTP requests, such as which port it is listening on or the SSL certificate it will use. These values are available in the channel's options property, an instance of ApplicationOptions .","title":"The Application Object"},{"location":"application/configure/","text":"Configuring an Application and its Environment This guide covers configuring a Conduit application. Configuration Files Conduit applications use YAML configuration files to provide environment-specific values like database connection information. Use separate configuration files for testing and different deployment environments. The path of a configuration file is available to an ApplicationChannel through its options property. class TodoAppChannel extends ApplicationChannel { @override Future prepare() async { var config = TodoConfiguration(options.configurationFilePath); ... } } The default value is config.yaml . The best practice for reading a configuration file is to subclass Configuration . A Configuration declares a property for each key in a configuration file. For example, see the following Configuration subclass: class TodoConfiguration extends Configuration { TodoConfiguration(String fileName) : super.fromFile(File(fileName)); DatabaseConnectionConfiguration database; String apiBaseURL; @optionalConfiguration int identifier; } This would read a YAML file like this: database: username: fred password: fredspassword host: db.myapp.com port: 5432 databaseName: fredsdb apiBaseURL: /api identifier: 2 If required properties are omitted from the YAML file being read, application startup will fail and throw an informative error. Environment Variables A configuration file can use an environment variable instead of a literal value. In config.yaml , use a $ -prefixed environment variable name instead of a value: database: $DATABASE_CONNECTION_URL apiBaseURL: /api If the environment variable DATABASE_CONNECTION_URL 's value were \"postgres://user:password@localhost:5432/test\" , the value of TodoConfiguration.database will be that string at runtime. The safe_config package has instructions for more additional usages. Configuration Conventions and Deployment Options Conduit uses two configuration files for a project: config.yaml and config.src.yaml . The latter is the configuration source file . The configuration source file declares key-value pairs that will be used when running the application tests. Deployed instances use config.yaml . This pattern is used for two reasons: It is the template for the config.yaml that will be read on deployed applications, providing documentation for your application's configuration. It has the configuration values used during testing to inject mock dependencies. For example, a production API instance might have the following config.yaml file with connection info for a production database: database: postgres://app_user:$%4jlkn#an*@mOZkea2@somedns.name.com:5432/production_db Whereas config.src.yaml would have connection info for a local, test database: database: postgres://test:test@localhost:5432/temporary_db The source configuration file should be checked into version control. Whether or not config.yaml is checked in depends on how you are deploying your code. If you are using environment variables to control application configuration, you should check config.yaml into source control and provide $ -prefixed environment variable values. If you are using managing configuration files on each deployed instance, do not check config.yaml into source control because it'll be a different file for each instance. It can sometimes makes sense to have a local.yaml with values for running the application locally, e.g. when doing client testing. Use --config-path with conduit serve to use a non-default name. Preventing Resource Leaks When a Conduit application starts, the application and its ApplicationChannel s will likely create services that they use to respond to requests. In order for application tests to complete successfully, these services must be \"closed\" when the application stops. For built-in services, like PostgreSQLPersistentStore , this happens automatically when Application.stop() is invoked. A ServiceRegistry automatically stops registered services. Registration looks like this: var connection = new ConnectionOfSomeKind(); await connection.open(); ServiceRegistry.defaultInstance .register<ConnectionOfSomeKind>(connection, (c) => c.close()); This method takes the service to be closed and a closure that closes it. The service is passed as an argument to the closure. If the closure returns a Future , ServiceRegistry.close will not complete until the Future completes. ServiceRegistry.defaultInstance is closed in Application.stop() , any registries created by the programmer must be closed manually. The return type of ServiceRegistry.register is the object being registered. This makes registration syntax a bit more palatable: var connection = ServiceRegistry.defaultInstance .register<ConnectionOfSomeKind>( new ConnectionOfSomeKind(), (c) => c.close()); await connection.open(); Configuring CORS Headers All controllers have built-in behavior for handling CORS requests from a browser. When a preflight request is received from a browser (an OPTIONS request with Access-Control-Request-Method header and Origin headers), the response is created by evaluating the policy of the Controller that will respond to the real request. In practice, this means that the policy of the last controller in a channel is used. For example, the policy of FooController generates the preflight response: router .route(\"/foo\") .link(() => new Authorizer(...)) .link(() => new FooController()); Every Controller has a policy property (a CORSPolicy instance). The policy has properties for configuring CORS options for that particular endpoint. By having a policy , every Controller automatically implements logic to respond to preflight requests without any additional code. Policies can be set at the controller level or at the application level. The static property CORSPolicy.defaultPolicy can be modified at initialization time to set the CORS options for every controller. class MyApplicationChannel extends ApplicationChannel { @override Future prepare() async { CORSPolicy.defaultPolicy.allowedOrigins = [\"http://mywebsite.com/\"]; } } The default policy is very permissive: POST, PUT, DELETE and GET are allowed methods. All origins are valid (*). Each individual controller can override or replace the default policy by modifying its own policy in its constructor. class MyResourceController extends ResourceController { MyResourceController() { policy.allowedMethods = [\"POST\"]; } } Configuring HTTPS By default, a Conduit application does not use HTTPS. In many cases, a Conduit application sits behind an SSL-enabled load balancer or some other proxy. The traffic from the load balancer is sent to the Conduit application unencrypted over HTTP. However, Conduit may be configured to manage HTTPS connections itself. By passing the value private key and SSL certificate paths as options to --ssl-key-path and --ssl-certificate-path in conduit serve , a Conduit application will configure itself to only allow HTTPS connections. conduit serve --ssl-key-path server.key.pem --ssl-certificate-path server.cert.pem Both the key and certificate file must be unencrypted PEM files, and both must be provided to this command. These files are typically issued by a \"Certificate Authority\", such as letsencrypt.org . When an application is started with these options, the certificateFilePath and keyFilePath are set on the ApplicationOptions your application is being run with. (If you are not using conduit serve , you can set these values directly when instantiating ApplicationOptions .) For more granular control over setting up an HTTPS server, you may override securityContext in ApplicationChannel . By default, this property will create a SecurityContext from the certificateFilePath and keyFilePath in the channels's options . A SecurityContext allows for password-encrypted credential files, configuring client certificates and other less used HTTPS schemes. class MyApplicationChannel extends ApplicationChannel { @override SecurityContext get securityContext { return new SecurityContext() ..usePrivateKey(\"server.key\", password: \"1234\") ..useCertificateChain(\"server.crt\", password: \"1234\"); } }","title":"Configuring an Application and its Environment"},{"location":"application/configure/#configuring-an-application-and-its-environment","text":"This guide covers configuring a Conduit application.","title":"Configuring an Application and its Environment"},{"location":"application/configure/#configuration-files","text":"Conduit applications use YAML configuration files to provide environment-specific values like database connection information. Use separate configuration files for testing and different deployment environments. The path of a configuration file is available to an ApplicationChannel through its options property. class TodoAppChannel extends ApplicationChannel { @override Future prepare() async { var config = TodoConfiguration(options.configurationFilePath); ... } } The default value is config.yaml . The best practice for reading a configuration file is to subclass Configuration . A Configuration declares a property for each key in a configuration file. For example, see the following Configuration subclass: class TodoConfiguration extends Configuration { TodoConfiguration(String fileName) : super.fromFile(File(fileName)); DatabaseConnectionConfiguration database; String apiBaseURL; @optionalConfiguration int identifier; } This would read a YAML file like this: database: username: fred password: fredspassword host: db.myapp.com port: 5432 databaseName: fredsdb apiBaseURL: /api identifier: 2 If required properties are omitted from the YAML file being read, application startup will fail and throw an informative error.","title":"Configuration Files"},{"location":"application/configure/#environment-variables","text":"A configuration file can use an environment variable instead of a literal value. In config.yaml , use a $ -prefixed environment variable name instead of a value: database: $DATABASE_CONNECTION_URL apiBaseURL: /api If the environment variable DATABASE_CONNECTION_URL 's value were \"postgres://user:password@localhost:5432/test\" , the value of TodoConfiguration.database will be that string at runtime. The safe_config package has instructions for more additional usages.","title":"Environment Variables"},{"location":"application/configure/#configuration-conventions-and-deployment-options","text":"Conduit uses two configuration files for a project: config.yaml and config.src.yaml . The latter is the configuration source file . The configuration source file declares key-value pairs that will be used when running the application tests. Deployed instances use config.yaml . This pattern is used for two reasons: It is the template for the config.yaml that will be read on deployed applications, providing documentation for your application's configuration. It has the configuration values used during testing to inject mock dependencies. For example, a production API instance might have the following config.yaml file with connection info for a production database: database: postgres://app_user:$%4jlkn#an*@mOZkea2@somedns.name.com:5432/production_db Whereas config.src.yaml would have connection info for a local, test database: database: postgres://test:test@localhost:5432/temporary_db The source configuration file should be checked into version control. Whether or not config.yaml is checked in depends on how you are deploying your code. If you are using environment variables to control application configuration, you should check config.yaml into source control and provide $ -prefixed environment variable values. If you are using managing configuration files on each deployed instance, do not check config.yaml into source control because it'll be a different file for each instance. It can sometimes makes sense to have a local.yaml with values for running the application locally, e.g. when doing client testing. Use --config-path with conduit serve to use a non-default name.","title":"Configuration Conventions and Deployment Options"},{"location":"application/configure/#preventing-resource-leaks","text":"When a Conduit application starts, the application and its ApplicationChannel s will likely create services that they use to respond to requests. In order for application tests to complete successfully, these services must be \"closed\" when the application stops. For built-in services, like PostgreSQLPersistentStore , this happens automatically when Application.stop() is invoked. A ServiceRegistry automatically stops registered services. Registration looks like this: var connection = new ConnectionOfSomeKind(); await connection.open(); ServiceRegistry.defaultInstance .register<ConnectionOfSomeKind>(connection, (c) => c.close()); This method takes the service to be closed and a closure that closes it. The service is passed as an argument to the closure. If the closure returns a Future , ServiceRegistry.close will not complete until the Future completes. ServiceRegistry.defaultInstance is closed in Application.stop() , any registries created by the programmer must be closed manually. The return type of ServiceRegistry.register is the object being registered. This makes registration syntax a bit more palatable: var connection = ServiceRegistry.defaultInstance .register<ConnectionOfSomeKind>( new ConnectionOfSomeKind(), (c) => c.close()); await connection.open();","title":"Preventing Resource Leaks"},{"location":"application/configure/#configuring-cors-headers","text":"All controllers have built-in behavior for handling CORS requests from a browser. When a preflight request is received from a browser (an OPTIONS request with Access-Control-Request-Method header and Origin headers), the response is created by evaluating the policy of the Controller that will respond to the real request. In practice, this means that the policy of the last controller in a channel is used. For example, the policy of FooController generates the preflight response: router .route(\"/foo\") .link(() => new Authorizer(...)) .link(() => new FooController()); Every Controller has a policy property (a CORSPolicy instance). The policy has properties for configuring CORS options for that particular endpoint. By having a policy , every Controller automatically implements logic to respond to preflight requests without any additional code. Policies can be set at the controller level or at the application level. The static property CORSPolicy.defaultPolicy can be modified at initialization time to set the CORS options for every controller. class MyApplicationChannel extends ApplicationChannel { @override Future prepare() async { CORSPolicy.defaultPolicy.allowedOrigins = [\"http://mywebsite.com/\"]; } } The default policy is very permissive: POST, PUT, DELETE and GET are allowed methods. All origins are valid (*). Each individual controller can override or replace the default policy by modifying its own policy in its constructor. class MyResourceController extends ResourceController { MyResourceController() { policy.allowedMethods = [\"POST\"]; } }","title":"Configuring CORS Headers"},{"location":"application/configure/#configuring-https","text":"By default, a Conduit application does not use HTTPS. In many cases, a Conduit application sits behind an SSL-enabled load balancer or some other proxy. The traffic from the load balancer is sent to the Conduit application unencrypted over HTTP. However, Conduit may be configured to manage HTTPS connections itself. By passing the value private key and SSL certificate paths as options to --ssl-key-path and --ssl-certificate-path in conduit serve , a Conduit application will configure itself to only allow HTTPS connections. conduit serve --ssl-key-path server.key.pem --ssl-certificate-path server.cert.pem Both the key and certificate file must be unencrypted PEM files, and both must be provided to this command. These files are typically issued by a \"Certificate Authority\", such as letsencrypt.org . When an application is started with these options, the certificateFilePath and keyFilePath are set on the ApplicationOptions your application is being run with. (If you are not using conduit serve , you can set these values directly when instantiating ApplicationOptions .) For more granular control over setting up an HTTPS server, you may override securityContext in ApplicationChannel . By default, this property will create a SecurityContext from the certificateFilePath and keyFilePath in the channels's options . A SecurityContext allows for password-encrypted credential files, configuring client certificates and other less used HTTPS schemes. class MyApplicationChannel extends ApplicationChannel { @override SecurityContext get securityContext { return new SecurityContext() ..usePrivateKey(\"server.key\", password: \"1234\") ..useCertificateChain(\"server.crt\", password: \"1234\"); } }","title":"Configuring HTTPS"},{"location":"application/structure/","text":"Application and Project Structure The purpose of this document is to understand the objects that comprise a Conduit application, and how they work with one another to serve HTTP requests. It also discusses the project structure on the filesystem. Controllers are Building Blocks The building blocks of a Conduit application are Controllers . Each controller type has logic to handle an HTTP request in some way. Controllers are linked together to form a channel ; an ordered series of controllers. A channel is a composition of its controllers' behaviors. For example, consider an Authorizer controller that verifies the request's authorization credentials are correct, and a SecretController that sends a response with secret information. By composing these two controllers together, we have a channel that verifies credentials before sending a secret. The benefit of controllers and channels is that controllers can be reused in multiple channels; the Authorizer can protect other types of controllers without any change to its logic. The last controller in a channel must always respond to a request. These types of controllers are called endpoint controllers and implement the business logic for your application's endpoints. For example, an endpoint controller might fetch a list of books from a database and send them in a response. The other controllers in a channel are called middleware controllers . These types of controllers typically verify something about a request before letting the next controller in the channel handle it. Middleware controllers can respond to a request, but doing so prevents the rest of the controllers in the channel from handling the request. For example, an \"authorization\" controller could send a 401 Unauthorized response protecting the endpoint controller from unauthorized requests. A \"caching\" controller could send a response with information from a cache, preventing the endpoint controller from performing an expensive query. Both middleware and endpoint controllers are instances of Controller (or a subclass). Middleware controllers are typically reusable, while endpoint controllers are typically not. If a middleware controller is not reusable, its logic might be better suited for the endpoint controller it precedes in the channel. Most endpoint controllers are created by subclassing ResourceController (itself a subclass of Controller ). This class allows you to implement methods for each HTTP method (like GET or POST) for a given endpoint. The Application Channel and Entry Point Each application designates one controller as the entry point of the application. This controller is the first to receive a new request and is the head of the application's channel. In most applications, the entry point is a Router ; this controller allows multiple channels to be linked, effectively splitting the channel into sub-channels. The diagram above looks like this in code: class AppChannel extends ApplicationChannel { @override Controller get entry { final router = new Router(); router .route(\"/a\") .link(() => new AController()); router .route(\"/b\") .link(() => new Authorizer(...)) .link(() => new BController()); router .route(\"/c\") .link(() => new Authorizer(...)) .link(() => new CController()); return router; } } See this guide for more details on the application channel and entry point. Conduit Project Structure and Organization A Conduit project is a directory that contains, at minimum, the following file structure: pubspec.yaml lib/ application_name.dart The name of any Dart application is defined by the name key in pubspec.yaml . In order for conduit serve to run your application, there must be a .dart file in lib/ with that same name. This is your application library file and it must declare a ApplicationChannel subclass or import a file that does. This is the bare minimum requirement to run a Conduit application. (See Deploying for more details on running applications.) For organizing applications of reasonable size, we recommend the following structure: pubspec.yaml config.src.yaml config.yaml lib/ application_name.dart channel.dart controller/ user_controller.dart model/ user.dart test/ user_controller_test.dart harness/ app.dart The required pubspec.yaml and lib/application_name.dart files are present alongside a few others: config.yaml : A configuration file for the running application. config.src.yaml : A template for config.yaml . channel.dart : A file solely for the ApplicationChannel of an application. This file should be exported from application_name.dart . controller/ : A directory for Controller subclass files. model/ : A directory for ManagedObject<T> subclass files. test/harness/app.dart : A test harness ) for automated testing. Feel free to create other subdirectories in lib/ for organizing other types of files. Conduit and dart:io Conduit runs on top of dart:io and relies on its HttpServer implementation. When a Conduit application is started, one or more HttpServer instances are bound to the port specified by conduit serve . For each HTTP request, an instance of Request is created to wrap the HttpRequest from dart:io . The Request is added to a ApplicationChannel , sending it through the channel of Controller s until it is responded to. In rare circumstances, you may choose to remove a Request from the application channel and manipulate the request with dart:io only. Once removed, it is your responsibility to respond to the request by setting properties on and closing the HttpRequest.response . To take a request out of the channel, simply return null from a Controller : @override Controller get entryPoint { final router = new Router(); router .route(\"/bypass_conduit\") .linkFunction((req) async { req.response.statusCode = 200; req.response.close(); return null; }); return router; } This technique is valuable when Conduit can't do something you want it to do or when using websockets .","title":"Application and Project Structure"},{"location":"application/structure/#application-and-project-structure","text":"The purpose of this document is to understand the objects that comprise a Conduit application, and how they work with one another to serve HTTP requests. It also discusses the project structure on the filesystem.","title":"Application and Project Structure"},{"location":"application/structure/#controllers-are-building-blocks","text":"The building blocks of a Conduit application are Controllers . Each controller type has logic to handle an HTTP request in some way. Controllers are linked together to form a channel ; an ordered series of controllers. A channel is a composition of its controllers' behaviors. For example, consider an Authorizer controller that verifies the request's authorization credentials are correct, and a SecretController that sends a response with secret information. By composing these two controllers together, we have a channel that verifies credentials before sending a secret. The benefit of controllers and channels is that controllers can be reused in multiple channels; the Authorizer can protect other types of controllers without any change to its logic. The last controller in a channel must always respond to a request. These types of controllers are called endpoint controllers and implement the business logic for your application's endpoints. For example, an endpoint controller might fetch a list of books from a database and send them in a response. The other controllers in a channel are called middleware controllers . These types of controllers typically verify something about a request before letting the next controller in the channel handle it. Middleware controllers can respond to a request, but doing so prevents the rest of the controllers in the channel from handling the request. For example, an \"authorization\" controller could send a 401 Unauthorized response protecting the endpoint controller from unauthorized requests. A \"caching\" controller could send a response with information from a cache, preventing the endpoint controller from performing an expensive query. Both middleware and endpoint controllers are instances of Controller (or a subclass). Middleware controllers are typically reusable, while endpoint controllers are typically not. If a middleware controller is not reusable, its logic might be better suited for the endpoint controller it precedes in the channel. Most endpoint controllers are created by subclassing ResourceController (itself a subclass of Controller ). This class allows you to implement methods for each HTTP method (like GET or POST) for a given endpoint.","title":"Controllers are Building Blocks"},{"location":"application/structure/#the-application-channel-and-entry-point","text":"Each application designates one controller as the entry point of the application. This controller is the first to receive a new request and is the head of the application's channel. In most applications, the entry point is a Router ; this controller allows multiple channels to be linked, effectively splitting the channel into sub-channels. The diagram above looks like this in code: class AppChannel extends ApplicationChannel { @override Controller get entry { final router = new Router(); router .route(\"/a\") .link(() => new AController()); router .route(\"/b\") .link(() => new Authorizer(...)) .link(() => new BController()); router .route(\"/c\") .link(() => new Authorizer(...)) .link(() => new CController()); return router; } } See this guide for more details on the application channel and entry point.","title":"The Application Channel and Entry Point"},{"location":"application/structure/#conduit-project-structure-and-organization","text":"A Conduit project is a directory that contains, at minimum, the following file structure: pubspec.yaml lib/ application_name.dart The name of any Dart application is defined by the name key in pubspec.yaml . In order for conduit serve to run your application, there must be a .dart file in lib/ with that same name. This is your application library file and it must declare a ApplicationChannel subclass or import a file that does. This is the bare minimum requirement to run a Conduit application. (See Deploying for more details on running applications.) For organizing applications of reasonable size, we recommend the following structure: pubspec.yaml config.src.yaml config.yaml lib/ application_name.dart channel.dart controller/ user_controller.dart model/ user.dart test/ user_controller_test.dart harness/ app.dart The required pubspec.yaml and lib/application_name.dart files are present alongside a few others: config.yaml : A configuration file for the running application. config.src.yaml : A template for config.yaml . channel.dart : A file solely for the ApplicationChannel of an application. This file should be exported from application_name.dart . controller/ : A directory for Controller subclass files. model/ : A directory for ManagedObject<T> subclass files. test/harness/app.dart : A test harness ) for automated testing. Feel free to create other subdirectories in lib/ for organizing other types of files.","title":"Conduit Project Structure and Organization"},{"location":"application/structure/#conduit-and-dartio","text":"Conduit runs on top of dart:io and relies on its HttpServer implementation. When a Conduit application is started, one or more HttpServer instances are bound to the port specified by conduit serve . For each HTTP request, an instance of Request is created to wrap the HttpRequest from dart:io . The Request is added to a ApplicationChannel , sending it through the channel of Controller s until it is responded to. In rare circumstances, you may choose to remove a Request from the application channel and manipulate the request with dart:io only. Once removed, it is your responsibility to respond to the request by setting properties on and closing the HttpRequest.response . To take a request out of the channel, simply return null from a Controller : @override Controller get entryPoint { final router = new Router(); router .route(\"/bypass_conduit\") .linkFunction((req) async { req.response.statusCode = 200; req.response.close(); return null; }); return router; } This technique is valuable when Conduit can't do something you want it to do or when using websockets .","title":"Conduit and dart:io"},{"location":"application/threading/","text":"Multi-threading in Conduit One of the primary differentiators between Conduit and other server frameworks is its multi-threaded behavior. When a Conduit application starts, it replicates the application logic across a number of threads. In Dart, threads are called isolates . The difference in naming isn't just to be cute - an isolate is a little bit different than a thread in that memory is not shared between isolates. Each isolate has its own heap (this is where memory for objects is allocated from) that other isolates can't access. An isolated thread is very valuable. Many multi-threaded applications share memory across threads, which require difficult design patterns and can easily introduce hard to track bugs that even the most experienced programmer will have a hard time avoiding. How Conduit Uses Isolates An application is initialized by invoking a series of initialization methods in a ApplicationChannel . Once these methods are finished executing, the application starts sending HTTP requests through the channel created by the ApplicationChannel . Because an ApplicationChannel is a type - and can be instantiated - Conduit simply creates a number of isolates and instantiates ApplicationChannel for each. The initialization code is therefore identical for each isolate, which means that the ongoing behavior of each isolate is also identical. More importantly, you - the programmer - have to do absolutely nothing to take advantage of Conduit's multi-threaded behavior. You simply have to pick the number of isolates you want to run the application on (see this section ). While you don't have to do anything in a Conduit application to take advantage of multiple processors, there are things you shouldn't do or should do in another way. First, you must be careful of keeping any state in your application. After initialization, any objects created while handling a request should be destroyed once the request is fulfilled. Any data that needs to be persisted must be stored in a database or other data store. This is just good practice for a REST API anyhow, so nothing is really lost here. However, there are times where you do need to track state. For example, if you are managing websocket connections, you do need to store some state after initialization - a reference to the websocket. This guide covers this topic in detail; the simple explanation is to use the ApplicationMessageHub . Another thing that is important to consider is initialization. The methods prepare() and entryPoint in an application channel will be invoked on each isolate. This behavior is guaranteed to occur for each isolate and there is often little to worry about. However, when implementing ApplicationChannel.initializeApplication , code runs on the main isolate. Any changes to static variables or singletons will not be replicated to the isolates running the application logic. The use case for this method is rather minimal, but it is very important that types like CodecRegistry aren't configured in this method. How Many Isolates Should I Use To give you a starting point, the default number of isolates for an application is 3 when started with conduit serve . While less than 3 isolates will most certainly degrade performance, more than 3 doesn't necessarily improve performance. (And many more will certainly degrade performance.) There are a number of variables that factor into the isolate count decision. First, recall a computer essentially does two things: it executes instructions and transmits data. Both of these tasks take time, especially when that data is transmitted to another computer thousands of miles away. (It is a modern marvel that these tasks occur as fast as they do - one that we often take for granted.) While a few milliseconds difference in speed to handle a single request isn't all that meaningful, when you start receiving thousands of requests at a time, these milliseconds add up. When your application is struggling to keep up with executing instructions, it is said to be CPU-bound . (When your application is struggling to transmit data, it is said to be IO-bound .) A CPU-bound application has two choices: execute less instructions or have more processors (or cores) to execute instructions with. Most computers these days have multiple processors. When only using a single isolate, a Conduit application can only use one of those processors at a time. As the number of isolates increases, so too do the number of processors that can be used at a time. Thus, more isolates means more processors means more instructions and your application bound less by the CPU. However, there is a limit - creating 100 isolates when there are only two processors doesn't yield any greater performance, because 50 isolates will fight over a single processor. In fact, the amount of work to schedule these instructions and the amount of memory this many isolates will consume will hurt performance. For example, when running benchmarks with wrk on my four-core machine, I get significantly better results as I add isolates 1 through 4, but then I get marginal gains and finally less or equal performance as I increase the number of isolates past 4. The blue bar represents the number of requests per second for each isolate count when making a simple HTTP call to Conduit. (Note that benchmarks are a good way of measuring relative performance of an application and identifying bottlenecks, but real world usability performance across a network is the only measurement that matters. The absolute value of these benchmarks should not be taken seriously, as they entirely remove the network portion of the transmission.) But this isn't the whole story. Server applications are rarely CPU-bound, but instead IO-bound. The red bar represents the number of requests per second when making a database query and returning the results of that query as JSON in the response body. When using Observatory, the measurements indicate that the overwhelming majority of the time is spent transmitting data to and from the database. This is an example of being bound by IO (and the speed of the query). Recall that each isolate has its own database connection. A database connection is a serial queue - it can only handle one query at a time. Increasing the number of database connections means handling more queries at a time. This is no more apparent than when looking at the following graph, which measures the latency of requests with and without a database call. When there is only one database connection (one isolate), the latency is significantly higher per request - the application is entirely bound by the speed of the database serial queue. Adding a second isolate, and therefore a second database connection, drops the latency by more than half. There are diminishing returns as more database connections are added. That's because the same thing about the number of threads per processor also applies to the number of database connections. Adding more database connections doesn't magically make the database server run any faster. As a general rule, start with N-1 isolates, where N is the number of processors on the machine. Use wrk and Observatory to profile your application and tune accordingly. In a multi-instance environment, remember that the total number of database connections is MxN, where M is the number of machines and N is the number of isolates. If you find yourself in a jam where IO would be better served by less isolates, but CPU would be better served by more isolates, you may consider using a database connection pool isolate.","title":"Multi-threading"},{"location":"application/threading/#multi-threading-in-conduit","text":"One of the primary differentiators between Conduit and other server frameworks is its multi-threaded behavior. When a Conduit application starts, it replicates the application logic across a number of threads. In Dart, threads are called isolates . The difference in naming isn't just to be cute - an isolate is a little bit different than a thread in that memory is not shared between isolates. Each isolate has its own heap (this is where memory for objects is allocated from) that other isolates can't access. An isolated thread is very valuable. Many multi-threaded applications share memory across threads, which require difficult design patterns and can easily introduce hard to track bugs that even the most experienced programmer will have a hard time avoiding.","title":"Multi-threading in Conduit"},{"location":"application/threading/#how-conduit-uses-isolates","text":"An application is initialized by invoking a series of initialization methods in a ApplicationChannel . Once these methods are finished executing, the application starts sending HTTP requests through the channel created by the ApplicationChannel . Because an ApplicationChannel is a type - and can be instantiated - Conduit simply creates a number of isolates and instantiates ApplicationChannel for each. The initialization code is therefore identical for each isolate, which means that the ongoing behavior of each isolate is also identical. More importantly, you - the programmer - have to do absolutely nothing to take advantage of Conduit's multi-threaded behavior. You simply have to pick the number of isolates you want to run the application on (see this section ). While you don't have to do anything in a Conduit application to take advantage of multiple processors, there are things you shouldn't do or should do in another way. First, you must be careful of keeping any state in your application. After initialization, any objects created while handling a request should be destroyed once the request is fulfilled. Any data that needs to be persisted must be stored in a database or other data store. This is just good practice for a REST API anyhow, so nothing is really lost here. However, there are times where you do need to track state. For example, if you are managing websocket connections, you do need to store some state after initialization - a reference to the websocket. This guide covers this topic in detail; the simple explanation is to use the ApplicationMessageHub . Another thing that is important to consider is initialization. The methods prepare() and entryPoint in an application channel will be invoked on each isolate. This behavior is guaranteed to occur for each isolate and there is often little to worry about. However, when implementing ApplicationChannel.initializeApplication , code runs on the main isolate. Any changes to static variables or singletons will not be replicated to the isolates running the application logic. The use case for this method is rather minimal, but it is very important that types like CodecRegistry aren't configured in this method.","title":"How Conduit Uses Isolates"},{"location":"application/threading/#how-many-isolates-should-i-use","text":"To give you a starting point, the default number of isolates for an application is 3 when started with conduit serve . While less than 3 isolates will most certainly degrade performance, more than 3 doesn't necessarily improve performance. (And many more will certainly degrade performance.) There are a number of variables that factor into the isolate count decision. First, recall a computer essentially does two things: it executes instructions and transmits data. Both of these tasks take time, especially when that data is transmitted to another computer thousands of miles away. (It is a modern marvel that these tasks occur as fast as they do - one that we often take for granted.) While a few milliseconds difference in speed to handle a single request isn't all that meaningful, when you start receiving thousands of requests at a time, these milliseconds add up. When your application is struggling to keep up with executing instructions, it is said to be CPU-bound . (When your application is struggling to transmit data, it is said to be IO-bound .) A CPU-bound application has two choices: execute less instructions or have more processors (or cores) to execute instructions with. Most computers these days have multiple processors. When only using a single isolate, a Conduit application can only use one of those processors at a time. As the number of isolates increases, so too do the number of processors that can be used at a time. Thus, more isolates means more processors means more instructions and your application bound less by the CPU. However, there is a limit - creating 100 isolates when there are only two processors doesn't yield any greater performance, because 50 isolates will fight over a single processor. In fact, the amount of work to schedule these instructions and the amount of memory this many isolates will consume will hurt performance. For example, when running benchmarks with wrk on my four-core machine, I get significantly better results as I add isolates 1 through 4, but then I get marginal gains and finally less or equal performance as I increase the number of isolates past 4. The blue bar represents the number of requests per second for each isolate count when making a simple HTTP call to Conduit. (Note that benchmarks are a good way of measuring relative performance of an application and identifying bottlenecks, but real world usability performance across a network is the only measurement that matters. The absolute value of these benchmarks should not be taken seriously, as they entirely remove the network portion of the transmission.) But this isn't the whole story. Server applications are rarely CPU-bound, but instead IO-bound. The red bar represents the number of requests per second when making a database query and returning the results of that query as JSON in the response body. When using Observatory, the measurements indicate that the overwhelming majority of the time is spent transmitting data to and from the database. This is an example of being bound by IO (and the speed of the query). Recall that each isolate has its own database connection. A database connection is a serial queue - it can only handle one query at a time. Increasing the number of database connections means handling more queries at a time. This is no more apparent than when looking at the following graph, which measures the latency of requests with and without a database call. When there is only one database connection (one isolate), the latency is significantly higher per request - the application is entirely bound by the speed of the database serial queue. Adding a second isolate, and therefore a second database connection, drops the latency by more than half. There are diminishing returns as more database connections are added. That's because the same thing about the number of threads per processor also applies to the number of database connections. Adding more database connections doesn't magically make the database server run any faster. As a general rule, start with N-1 isolates, where N is the number of processors on the machine. Use wrk and Observatory to profile your application and tune accordingly. In a multi-instance environment, remember that the total number of database connections is MxN, where M is the number of machines and N is the number of isolates. If you find yourself in a jam where IO would be better served by less isolates, but CPU would be better served by more isolates, you may consider using a database connection pool isolate.","title":"How Many Isolates Should I Use"},{"location":"auth/","text":"Authentication Conduit has types to manage authentication and authorization according to the OAuth 2.0 specification . You create an AuthServer service object for your application that manages authentication and authorization logic. An AuthServer requires a helper object that implements AuthServerDelegate to handle configuration and required data storage. Most often, this object is a ManagedAuthDelegate<T> that uses the Conduit ORM to manage this storage. An AuthServer service object is injected into Authorizer controllers that protect access to controller channels. An AuthServer is also injected into AuthCodeController and AuthController to provide HTTP APIs for authentication. The conduit auth command-line tool manages configuration - such as client identifier management - for live applications. Guides What is OAuth 2.0? Creating and Using AuthServers Securing Routes with Authorizer Adding Authentication Endpoints Using Scopes to Control Access Managing OAuth 2.0 Clients","title":"Authentication"},{"location":"auth/#authentication","text":"Conduit has types to manage authentication and authorization according to the OAuth 2.0 specification . You create an AuthServer service object for your application that manages authentication and authorization logic. An AuthServer requires a helper object that implements AuthServerDelegate to handle configuration and required data storage. Most often, this object is a ManagedAuthDelegate<T> that uses the Conduit ORM to manage this storage. An AuthServer service object is injected into Authorizer controllers that protect access to controller channels. An AuthServer is also injected into AuthCodeController and AuthController to provide HTTP APIs for authentication. The conduit auth command-line tool manages configuration - such as client identifier management - for live applications.","title":"Authentication"},{"location":"auth/#guides","text":"What is OAuth 2.0? Creating and Using AuthServers Securing Routes with Authorizer Adding Authentication Endpoints Using Scopes to Control Access Managing OAuth 2.0 Clients","title":"Guides"},{"location":"auth/auth_scopes/","text":"auth_scopes Granular Authorization with OAuth 2.0 Scopes In many applications, operations have varying levels of access control. For example, a user may need special permission to create 'notes', but every user can read notes. In OAuth 2.0, permissions for operations are determined by an access token's scope . Operations can be defined to require certain scopes, and a request may only invoke those operations if its access token was granted with those scopes. A scope is a string identifier, like notes or notes.readonly . When a client application authenticates on behalf of a user, it requests one or more of these scope identifiers to be granted to the access token. Valid scopes will be stored with the access token, so that the scope can be referenced by subsequent uses of the access token. Scope Usage in Conduit An access token's scope is determined when a user authenticates. During authentication, a client application indicates the requested scope, and the Conduit application determines if that scope is permissible for the client application and the user. This scope information is attached to the access token. When a request is made with an access token, an Authorizer retrieves the token's scope. After the request is validated, the Authorizer stores scope information in Request.authorization . Linked controllers can use this information to determine how the request is handled. In general, a controller will reject a request and send a 403 Forbidden response when an access token has insufficient scope for an operation. Therefore, adding scopes to an application consists of three steps: Adding scope restrictions to operations. Adding permissible scopes for OAuth2 client identifiers (and optionally users). Updating client applications to request scope when authenticating. Adding Scope Restrictions to Operations When an Authorizer handles a request, it creates an Authorization object that is attached to the request. An Authorization object has a scopes property that contains every scope granted for the access token. This object also has a convenience method for checking if a particular scope is valid for that list of scopes: class NoteController extends Controller { @override Future<RequestOrResponse> handle(Request request) async { if (!request.authorization.isAuthorizedForScope(\"notes\")) { return Response.forbidden(); } return Response.ok(await getAllNotes()); } } !!! warning \"Use an Authorizer\" The authorization property of Request is only valid after the request is handled by an Authorizer . It is null otherwise. An Authorizer may also validate the scope of a request before letting it pass to its linked controller. router .route('/notes') .link(() => Authorizer.bearer(authServer, scopes: ['notes'])) .link(() => NoteController()); In the above, the NoteController will only be reached if the request's bearer token has 'notes' scope. If there is insufficient scope, a 403 Forbidden response is sent. This applies to all operations of the NoteController . It often makes sense to have separate scope for different operations on the same resource. The Scope annotation may be added to ResourceController operation methods for this purpose. class NoteController extends ResourceController { @Scope(['notes.readonly']) @Operation.get() Future<Response> getNotes() async => ...; @Scope(['notes']) @Operation.post() Future<Response> createNote(@Bind.body() Note note) async => ...; } If a request does not have sufficient scope for the intended operation method, a 403 Forbidden response is sent. When using Scope annotations, you must link an Authorizer prior to the ResourceController , but it is not necessary to specify Authorizer scopes. If a Scope annotation or Authorizer contains multiple scope entries, an access token must have scope for each of those entries. For example, the annotation @Scope(['notes', 'user']) requires an access token to have both 'notes' and 'user' scope. Defining Permissible Scope When a client application authenticates on behalf of a user, it includes a list of request scopes for the access token. A Conduit application will grant the requested scopes to the token if the scopes are permissible for both the authenticating client identifier and the authenticating user. To add permissible scopes to an authenticating client, you use the conduit auth command-line tool. When creating a new client identifier, include the --allowed-scopes options: conduit auth add-client \\ --id com.app.mobile \\ --secret myspecialsecret \\ --allowed-scopes 'notes users' \\ --connect postgres://user:password@dbhost:5432/db_name When modifying an existing client identifier, use the command conduit auth set-scope : conduit auth set-scope \\ --id com.app.mobile \\ --scopes 'notes users' \\ --connect postgres://user:password@dbhost:5432/db_name Each scope is a space-delimited string; the above examples allow clients authenticating with the com.app.mobile client ID to grant access tokens with 'notes' and 'users' scope. If a client application requests scopes that are not available for that client application, the granted access token will not contain that scope. If none of the request scopes are available for the client identifier, no access token is granted. When adding scope restrictions to your application, you must ensure that all of the client applications that have access to those operations are able to grant that scope. Scopes may also be limited by some attribute of your application's concept of a 'user'. This user-level filtering is done by overriding getAllowedScopes in AuthServerDelegate . By default, this method returns AuthScope.Any - which means there are no restrictions. If the client application allows the scope, then any user that logs in with that application can request that scope. This method may return a list of AuthScope s that are valid for the authenticating user. The following example shows a ManagedAuthDelegate<T> subclass that allows any scope for @conduit.dart.com usernames, no scopes for @hotmail.com addresses and some limited scope for everyone else: class DomainBasedAuthDelegate extends ManagedAuthDelegate<User> { DomainBasedAuthDelegate(ManagedContext context, {int tokenLimit: 40}) : super(context, tokenLimit: tokenLimit); @override List<AuthScope> getAllowedScopes(covariant User user) { if (user.username.endsWith(\"@conduit.dart.com\")) { return AuthScope.Any; } else if (user.username.endsWith(\"@hotmail.com\")) { return []; } else { return [AuthScope(\"user\")]; } } } The user passed to getAllowedScopes is the user being authenticated. It will have previously been fetched by the AuthServer . The AuthServer fetches this object by invoking AuthDelegate.getResourceOwner . The default implementation of this method for ManagedAuthDelegate<T> only fetches the id , username , salt and hashedPassword of the user. When using some other attribute of an application's user object to restrict allowed scopes, you must also override getResourceOwner to fetch these attributes. For example, if your application's user has a role attribute, you must fetch it and the other four required properties. Here's an example implementation: class RoleBasedAuthDelegate extends ManagedAuthDelegate<User> { RoleBasedAuthDelegate(ManagedContext context, {int tokenLimit: 40}) : super(context, tokenLimit: tokenLimit); @override Future<User> getResourceOwner( AuthServer server, String username) { final query = Query<User>(context) ..where((u) => u.username).equalTo(username) ..returningProperties((t) => [t.id, t.username, t.hashedPassword, t.salt, t.role]); return query.fetchOne(); } @override List<AuthScope> getAllowedScopes(covariant User user) { var scopeStrings = []; if (user.role == \"admin\") { scopeStrings = [\"admin\", \"user\"]; } else if (user.role == \"user\") { scopeStrings = [\"user:email\"]; } return scopeStrings.map((str) => AuthScope(str)).toList(); } } Client Application Integration Client applications that integrate with your scoped Conduit application must include a list of requested scopes when performing authentication. When authenticating through AuthController , a scope parameter must be added to the form data body. This parameter's value must be a space-delimited, URL-encoded list of requested scopes. username=bob&password=foo&grant_type=password&scope=notes%20users When authenticating via an AuthCodeController , this same query parameter is added to the initial GET request to render the login form. When authentication is complete, the list of granted scopes will be available in the JSON response body as a space-delimited string. { \"access_token\": \"...\", \"refresh_token\": \"...\", \"token_type\": \"bearer\", \"expires_in\": 3600, \"scopes\": \"notes users\" } Scope Format and Hierarchy There is no definitive guide on what a scope string should look like, other than being restricted to alphanumeric characters and some symbols. Conduit, however, provides a simple scoping structure - there are two special symbols, : and . . Hierarchy is specified by the : character. For example, the following is a hierarchy of scopes related to a user and its sub-resources: user (can read/write everything a user has) user:email (can read/write a user's email) user:documents (can read/write a user's documents) user:documents:spreadsheets (can read/write a user's spreadsheet documents) Notice how these scopes form a hierarchy. Each segment makes the scope more restrictive. For example, if an access token has user:email scope, it only allows access to a user's email. However, if the access token has user scope, it allows access to everything a user has, including their email. As another example, an access token with user:documents scope can access all of a user's documents, but the scope user:documents:spreadsheets is limited to only spreadsheet documents. Scope is often used to indicate read vs. write access. At first glance, it might sound like a good idea to use the hierarchy operator, e.g. user:email:read and user:email:write . However, an access token with user:email:write does not have permission to read email and this is likely unintended. This is where scope modifiers come in. A scope modifier is added after a . at the end of a scope string. For example, user:email.readonly grants readonly access to a user's email whereas user:email grants read and write access. An access token without a modifier has permission any modifier. Thus, user and user:email can both access user:email.readonly protected resources and actions, but user:email.readonly cannot access resources protected by user:email . A scope modifier is only valid for the last segment of a scope string. That is, user:documents.readonly:spreadsheets is not valid, but user:documents:spreadsheets.readonly is.","title":"OAuth 2.0 Scoping"},{"location":"auth/auth_scopes/#auth_scopes","text":"","title":"auth_scopes"},{"location":"auth/auth_scopes/#granular-authorization-with-oauth-20-scopes","text":"In many applications, operations have varying levels of access control. For example, a user may need special permission to create 'notes', but every user can read notes. In OAuth 2.0, permissions for operations are determined by an access token's scope . Operations can be defined to require certain scopes, and a request may only invoke those operations if its access token was granted with those scopes. A scope is a string identifier, like notes or notes.readonly . When a client application authenticates on behalf of a user, it requests one or more of these scope identifiers to be granted to the access token. Valid scopes will be stored with the access token, so that the scope can be referenced by subsequent uses of the access token.","title":"Granular Authorization with OAuth 2.0 Scopes"},{"location":"auth/auth_scopes/#scope-usage-in-conduit","text":"An access token's scope is determined when a user authenticates. During authentication, a client application indicates the requested scope, and the Conduit application determines if that scope is permissible for the client application and the user. This scope information is attached to the access token. When a request is made with an access token, an Authorizer retrieves the token's scope. After the request is validated, the Authorizer stores scope information in Request.authorization . Linked controllers can use this information to determine how the request is handled. In general, a controller will reject a request and send a 403 Forbidden response when an access token has insufficient scope for an operation. Therefore, adding scopes to an application consists of three steps: Adding scope restrictions to operations. Adding permissible scopes for OAuth2 client identifiers (and optionally users). Updating client applications to request scope when authenticating.","title":"Scope Usage in Conduit"},{"location":"auth/auth_scopes/#adding-scope-restrictions-to-operations","text":"When an Authorizer handles a request, it creates an Authorization object that is attached to the request. An Authorization object has a scopes property that contains every scope granted for the access token. This object also has a convenience method for checking if a particular scope is valid for that list of scopes: class NoteController extends Controller { @override Future<RequestOrResponse> handle(Request request) async { if (!request.authorization.isAuthorizedForScope(\"notes\")) { return Response.forbidden(); } return Response.ok(await getAllNotes()); } } !!! warning \"Use an Authorizer\" The authorization property of Request is only valid after the request is handled by an Authorizer . It is null otherwise. An Authorizer may also validate the scope of a request before letting it pass to its linked controller. router .route('/notes') .link(() => Authorizer.bearer(authServer, scopes: ['notes'])) .link(() => NoteController()); In the above, the NoteController will only be reached if the request's bearer token has 'notes' scope. If there is insufficient scope, a 403 Forbidden response is sent. This applies to all operations of the NoteController . It often makes sense to have separate scope for different operations on the same resource. The Scope annotation may be added to ResourceController operation methods for this purpose. class NoteController extends ResourceController { @Scope(['notes.readonly']) @Operation.get() Future<Response> getNotes() async => ...; @Scope(['notes']) @Operation.post() Future<Response> createNote(@Bind.body() Note note) async => ...; } If a request does not have sufficient scope for the intended operation method, a 403 Forbidden response is sent. When using Scope annotations, you must link an Authorizer prior to the ResourceController , but it is not necessary to specify Authorizer scopes. If a Scope annotation or Authorizer contains multiple scope entries, an access token must have scope for each of those entries. For example, the annotation @Scope(['notes', 'user']) requires an access token to have both 'notes' and 'user' scope.","title":"Adding Scope Restrictions to Operations"},{"location":"auth/auth_scopes/#defining-permissible-scope","text":"When a client application authenticates on behalf of a user, it includes a list of request scopes for the access token. A Conduit application will grant the requested scopes to the token if the scopes are permissible for both the authenticating client identifier and the authenticating user. To add permissible scopes to an authenticating client, you use the conduit auth command-line tool. When creating a new client identifier, include the --allowed-scopes options: conduit auth add-client \\ --id com.app.mobile \\ --secret myspecialsecret \\ --allowed-scopes 'notes users' \\ --connect postgres://user:password@dbhost:5432/db_name When modifying an existing client identifier, use the command conduit auth set-scope : conduit auth set-scope \\ --id com.app.mobile \\ --scopes 'notes users' \\ --connect postgres://user:password@dbhost:5432/db_name Each scope is a space-delimited string; the above examples allow clients authenticating with the com.app.mobile client ID to grant access tokens with 'notes' and 'users' scope. If a client application requests scopes that are not available for that client application, the granted access token will not contain that scope. If none of the request scopes are available for the client identifier, no access token is granted. When adding scope restrictions to your application, you must ensure that all of the client applications that have access to those operations are able to grant that scope. Scopes may also be limited by some attribute of your application's concept of a 'user'. This user-level filtering is done by overriding getAllowedScopes in AuthServerDelegate . By default, this method returns AuthScope.Any - which means there are no restrictions. If the client application allows the scope, then any user that logs in with that application can request that scope. This method may return a list of AuthScope s that are valid for the authenticating user. The following example shows a ManagedAuthDelegate<T> subclass that allows any scope for @conduit.dart.com usernames, no scopes for @hotmail.com addresses and some limited scope for everyone else: class DomainBasedAuthDelegate extends ManagedAuthDelegate<User> { DomainBasedAuthDelegate(ManagedContext context, {int tokenLimit: 40}) : super(context, tokenLimit: tokenLimit); @override List<AuthScope> getAllowedScopes(covariant User user) { if (user.username.endsWith(\"@conduit.dart.com\")) { return AuthScope.Any; } else if (user.username.endsWith(\"@hotmail.com\")) { return []; } else { return [AuthScope(\"user\")]; } } } The user passed to getAllowedScopes is the user being authenticated. It will have previously been fetched by the AuthServer . The AuthServer fetches this object by invoking AuthDelegate.getResourceOwner . The default implementation of this method for ManagedAuthDelegate<T> only fetches the id , username , salt and hashedPassword of the user. When using some other attribute of an application's user object to restrict allowed scopes, you must also override getResourceOwner to fetch these attributes. For example, if your application's user has a role attribute, you must fetch it and the other four required properties. Here's an example implementation: class RoleBasedAuthDelegate extends ManagedAuthDelegate<User> { RoleBasedAuthDelegate(ManagedContext context, {int tokenLimit: 40}) : super(context, tokenLimit: tokenLimit); @override Future<User> getResourceOwner( AuthServer server, String username) { final query = Query<User>(context) ..where((u) => u.username).equalTo(username) ..returningProperties((t) => [t.id, t.username, t.hashedPassword, t.salt, t.role]); return query.fetchOne(); } @override List<AuthScope> getAllowedScopes(covariant User user) { var scopeStrings = []; if (user.role == \"admin\") { scopeStrings = [\"admin\", \"user\"]; } else if (user.role == \"user\") { scopeStrings = [\"user:email\"]; } return scopeStrings.map((str) => AuthScope(str)).toList(); } }","title":"Defining Permissible Scope"},{"location":"auth/auth_scopes/#client-application-integration","text":"Client applications that integrate with your scoped Conduit application must include a list of requested scopes when performing authentication. When authenticating through AuthController , a scope parameter must be added to the form data body. This parameter's value must be a space-delimited, URL-encoded list of requested scopes. username=bob&password=foo&grant_type=password&scope=notes%20users When authenticating via an AuthCodeController , this same query parameter is added to the initial GET request to render the login form. When authentication is complete, the list of granted scopes will be available in the JSON response body as a space-delimited string. { \"access_token\": \"...\", \"refresh_token\": \"...\", \"token_type\": \"bearer\", \"expires_in\": 3600, \"scopes\": \"notes users\" }","title":"Client Application Integration"},{"location":"auth/auth_scopes/#scope-format-and-hierarchy","text":"There is no definitive guide on what a scope string should look like, other than being restricted to alphanumeric characters and some symbols. Conduit, however, provides a simple scoping structure - there are two special symbols, : and . . Hierarchy is specified by the : character. For example, the following is a hierarchy of scopes related to a user and its sub-resources: user (can read/write everything a user has) user:email (can read/write a user's email) user:documents (can read/write a user's documents) user:documents:spreadsheets (can read/write a user's spreadsheet documents) Notice how these scopes form a hierarchy. Each segment makes the scope more restrictive. For example, if an access token has user:email scope, it only allows access to a user's email. However, if the access token has user scope, it allows access to everything a user has, including their email. As another example, an access token with user:documents scope can access all of a user's documents, but the scope user:documents:spreadsheets is limited to only spreadsheet documents. Scope is often used to indicate read vs. write access. At first glance, it might sound like a good idea to use the hierarchy operator, e.g. user:email:read and user:email:write . However, an access token with user:email:write does not have permission to read email and this is likely unintended. This is where scope modifiers come in. A scope modifier is added after a . at the end of a scope string. For example, user:email.readonly grants readonly access to a user's email whereas user:email grants read and write access. An access token without a modifier has permission any modifier. Thus, user and user:email can both access user:email.readonly protected resources and actions, but user:email.readonly cannot access resources protected by user:email . A scope modifier is only valid for the last segment of a scope string. That is, user:documents.readonly:spreadsheets is not valid, but user:documents:spreadsheets.readonly is.","title":"Scope Format and Hierarchy"},{"location":"auth/authorizer/","text":"Securing Routes with Authorizer Instances of Authorizer are added to an application channel to verify HTTP request's authorization information before passing the request onwards. They protect channel access and typically come right after route . Here's an example: @override Controller get entryPoint { final router = Router(); router .route(\"/protected\") .link(() => Authorizer.bearer(authServer)) .link(() => ProtectedController()); router .route(\"/other\") .link(() => Authorizer.basic(authServer)) .link(() => OtherProtectedController()); return router; } An Authorizer parses the Authorization header of an HTTP request. The named constructors of Authorizer indicate the required format of Authorization header. The Authorization.bearer() constructor expects an OAuth 2.0 bearer token in the header, which has the following format: Authorization: Bearer 768iuzjkx82jkasjkd9z9 Authorizer.basic expects HTTP Basic Authentication, where the username and password are joined with the colon character ( : ) and Base 64-encoded: // 'dXNlcjpwYXNzd29yZA==' is 'user:password' Authorization: Basic dXNlcjpwYXNzd29yZA== If the header can't be parsed, doesn't exist or is in the wrong format, an Authorizer responds to the request with a 401 status code and prevents the next controller from receiving the request. Once parsed, an Authorizer sends the information - either the bearer token, or the username and password - to its AuthServer for verification. If the AuthServer rejects the authorization info, the Authorizer responds to the request with a 401 status code and prevents the next controller from receiving the request. Otherwise, the request continues to the next controller. For Authorizer.bearer , the value in a request's header must be a valid, unexpired access token. These types of authorizers are used when an endpoint requires a logged in user. For Authorizer.basic authorizers, credentials are verified by finding an OAuth 2.0 client identifier and ensuring its client secret matches. Routes with this type of authorizer are known as client authenticated routes. These types of authorizers are used when an endpoint requires a valid client application, but not a logged in user. Authorizer and OAuth 2.0 Scope An Authorizer may restrict access to controllers based on the scope of the request's bearer token. By default, an Authorizer.bearer allows any valid bearer token to pass through it. If desired, an Authorizer is initialized with a list of required scopes. A request may only pass the Authorizer if it has access to all scopes listed in the Authorizer . For example, the following requires at least user:posts and location scope: router .route(\"/checkin\") .link(() => Authorizer.bearer(authServer, scopes: [\"user:posts\", \"location\"])) .link(() => CheckInController()); Note that you don't have to use an Authorizer to restrict access based on scope. A controller has access to scope information after the request has passed through an Authorizer , so it can use the scope to make more granular authorization decisions. Authorization Objects A bearer token represents a granted authorization - at some point in the past, a user provided their credentials and the token is the proof of that. When a bearer token is sent in the authorization header of an HTTP request, the application can look up which user the token is for and the client application it was issued for. This information is stored in an instance of Authorization after the token has been verified and is assigned to Request.authorization . Controllers protected by an Authorizer can access this information to further determine their behavior. For example, a social networking application might have a /news_feed endpoint protected by an Authorizer . When an authenticated user makes a request for /news_feed , the controller will return that user's news feed. It can determine this by using the Authorization : class NewsFeedController extends ResourceController { NewsFeedController(this.context); ManagedContext context; @Operation.get() Future<Response> getNewsFeed() async { var forUserID = request.authorization.ownerID; var query = Query<Post>(context) ..where((p) => p.author).identifiedBy(forUserID); return Response.ok(await query.fetch()); } } In the above controller, it's impossible for a user to access another user's posts. Authorization objects also retain the scope of an access token so that a controller can make more granular decisions about the information/action in the endpoint. Checking whether an Authorization has access to a particular scope is accomplished by either looking at the list of its scopes or using authorizedForScope : class NewsFeedController extends ResourceController { NewsFeedController(this.context); ManagedContext context; @Operation.get() Future<Response> getNewsFeed() async { if (!request.authorization.authorizedForScope(\"user:feed\")) { return Response.unauthorized(); } var forUserID = request.authorization.ownerID; var query = Query<Post>(context) ..where((p) => p.author).identifiedBy(forUserID); return Response.ok(await query.fetch()); } } Using Authorizers Without AuthServer Throughout this guide, the argument to an instance of Authorizer has been referred to as an AuthServer . This is true - but only because AuthServer implements AuthValidator . AuthValidator is an interface for verifying bearer tokens and username/password credentials. You may use Authorizer without using AuthServer . For example, an application that doesn't use OAuth 2.0 could provide its own AuthValidator interface to simply verify the username and password of every request: class BasicValidator implements AuthValidator { @override FutureOr<Authorization> validate<T>(AuthorizationParser<T> parser, T authorizationData, {List<AuthScope> requiredScope}) {} var user = await userForName(usernameAndPassword.username); if (user.password == hash(usernameAndPassword.password, user.salt)) { return Authorization(...); } // Will end up creating a 401 Not Authorized Response return null; } } The validate method must return an Authorization if the credentials are valid, or null if they are not. The parser lets the validator know the format of the Authorization header (e.g., 'Basic' or 'Bearer') and authorizationData is the meaningful information in that header. There are two concrete types of AuthorizationParser<T> : AuthorizationBasicParser and AuthorizationBearerParser . The authorization data for a basic parser is an instance of AuthBasicCredentials that contain the username and password, while the bearer parser's authorization data is the bearer token string.","title":"Protecting Routes"},{"location":"auth/authorizer/#securing-routes-with-authorizer","text":"Instances of Authorizer are added to an application channel to verify HTTP request's authorization information before passing the request onwards. They protect channel access and typically come right after route . Here's an example: @override Controller get entryPoint { final router = Router(); router .route(\"/protected\") .link(() => Authorizer.bearer(authServer)) .link(() => ProtectedController()); router .route(\"/other\") .link(() => Authorizer.basic(authServer)) .link(() => OtherProtectedController()); return router; } An Authorizer parses the Authorization header of an HTTP request. The named constructors of Authorizer indicate the required format of Authorization header. The Authorization.bearer() constructor expects an OAuth 2.0 bearer token in the header, which has the following format: Authorization: Bearer 768iuzjkx82jkasjkd9z9 Authorizer.basic expects HTTP Basic Authentication, where the username and password are joined with the colon character ( : ) and Base 64-encoded: // 'dXNlcjpwYXNzd29yZA==' is 'user:password' Authorization: Basic dXNlcjpwYXNzd29yZA== If the header can't be parsed, doesn't exist or is in the wrong format, an Authorizer responds to the request with a 401 status code and prevents the next controller from receiving the request. Once parsed, an Authorizer sends the information - either the bearer token, or the username and password - to its AuthServer for verification. If the AuthServer rejects the authorization info, the Authorizer responds to the request with a 401 status code and prevents the next controller from receiving the request. Otherwise, the request continues to the next controller. For Authorizer.bearer , the value in a request's header must be a valid, unexpired access token. These types of authorizers are used when an endpoint requires a logged in user. For Authorizer.basic authorizers, credentials are verified by finding an OAuth 2.0 client identifier and ensuring its client secret matches. Routes with this type of authorizer are known as client authenticated routes. These types of authorizers are used when an endpoint requires a valid client application, but not a logged in user.","title":"Securing Routes with Authorizer"},{"location":"auth/authorizer/#authorizer-and-oauth-20-scope","text":"An Authorizer may restrict access to controllers based on the scope of the request's bearer token. By default, an Authorizer.bearer allows any valid bearer token to pass through it. If desired, an Authorizer is initialized with a list of required scopes. A request may only pass the Authorizer if it has access to all scopes listed in the Authorizer . For example, the following requires at least user:posts and location scope: router .route(\"/checkin\") .link(() => Authorizer.bearer(authServer, scopes: [\"user:posts\", \"location\"])) .link(() => CheckInController()); Note that you don't have to use an Authorizer to restrict access based on scope. A controller has access to scope information after the request has passed through an Authorizer , so it can use the scope to make more granular authorization decisions.","title":"Authorizer and OAuth 2.0 Scope"},{"location":"auth/authorizer/#authorization-objects","text":"A bearer token represents a granted authorization - at some point in the past, a user provided their credentials and the token is the proof of that. When a bearer token is sent in the authorization header of an HTTP request, the application can look up which user the token is for and the client application it was issued for. This information is stored in an instance of Authorization after the token has been verified and is assigned to Request.authorization . Controllers protected by an Authorizer can access this information to further determine their behavior. For example, a social networking application might have a /news_feed endpoint protected by an Authorizer . When an authenticated user makes a request for /news_feed , the controller will return that user's news feed. It can determine this by using the Authorization : class NewsFeedController extends ResourceController { NewsFeedController(this.context); ManagedContext context; @Operation.get() Future<Response> getNewsFeed() async { var forUserID = request.authorization.ownerID; var query = Query<Post>(context) ..where((p) => p.author).identifiedBy(forUserID); return Response.ok(await query.fetch()); } } In the above controller, it's impossible for a user to access another user's posts. Authorization objects also retain the scope of an access token so that a controller can make more granular decisions about the information/action in the endpoint. Checking whether an Authorization has access to a particular scope is accomplished by either looking at the list of its scopes or using authorizedForScope : class NewsFeedController extends ResourceController { NewsFeedController(this.context); ManagedContext context; @Operation.get() Future<Response> getNewsFeed() async { if (!request.authorization.authorizedForScope(\"user:feed\")) { return Response.unauthorized(); } var forUserID = request.authorization.ownerID; var query = Query<Post>(context) ..where((p) => p.author).identifiedBy(forUserID); return Response.ok(await query.fetch()); } }","title":"Authorization Objects"},{"location":"auth/authorizer/#using-authorizers-without-authserver","text":"Throughout this guide, the argument to an instance of Authorizer has been referred to as an AuthServer . This is true - but only because AuthServer implements AuthValidator . AuthValidator is an interface for verifying bearer tokens and username/password credentials. You may use Authorizer without using AuthServer . For example, an application that doesn't use OAuth 2.0 could provide its own AuthValidator interface to simply verify the username and password of every request: class BasicValidator implements AuthValidator { @override FutureOr<Authorization> validate<T>(AuthorizationParser<T> parser, T authorizationData, {List<AuthScope> requiredScope}) {} var user = await userForName(usernameAndPassword.username); if (user.password == hash(usernameAndPassword.password, user.salt)) { return Authorization(...); } // Will end up creating a 401 Not Authorized Response return null; } } The validate method must return an Authorization if the credentials are valid, or null if they are not. The parser lets the validator know the format of the Authorization header (e.g., 'Basic' or 'Bearer') and authorizationData is the meaningful information in that header. There are two concrete types of AuthorizationParser<T> : AuthorizationBasicParser and AuthorizationBearerParser . The authorization data for a basic parser is an instance of AuthBasicCredentials that contain the username and password, while the bearer parser's authorization data is the bearer token string.","title":"Using Authorizers Without AuthServer"},{"location":"auth/cli/","text":"Manage OAuth 2.0 Clients The conduit auth command line tool creates OAuth 2.0 client application identifiers and inserts them into an application's database. To use this tool, you must use ManagedAuthDelegate<T> and your database must be contain the tables to support it (see this guide for more details). Exchanging a username and password for an authorization token requires a registered client identifier. A token belongs to both the authenticating user and the client application. Clients are represented by instances of ManagedAuthClient from conduit/managed_auth . Authenticating clients must provide their client ID (and client secret, if applicable) in the Authorization header when requesting access tokens. An OAuth 2.0 client must have a string identifier that uniquely identifies the client. For example, com.food_app.mobile may be a client identifier for the mobile applications for some 'Food App'. To create a simple OAuth 2.0 client, the following command line utility can be run: conduit auth add-client \\ --id com.food_app.mobile \\ --connect postgres://user:password@dbhost:5432/food_app The connect option identifies the database for the application, which this tool will connect to and insert a record into the ManagedAuthClient database table. The identifier is provided through the id option. An OAuth 2.0 client created in this way is a public client; there is no client secret. An OAuth 2.0 client that uses the resource owner grant flow, but cannot secure its client secret, should use this type of client. An application can't secure its client secret if its source code is viewable - like any JavaScript application. It is suggested that native mobile applications also use public clients because their source code could potentially be disassembled to reveal a client secret, but isn't necessarily required. When making requests to client authenticated endpoints (those protected with Authorizer.basic ), the client secret is omitted from the authorization header. The string to base64 encode is clientID: , where the colon ( : ) is required. For example, to generate an authorization header in Dart for a public client: var clientID = \"com.foobar.xyz\"; var clientCredentials = Base64Encoder().convert(\"$clientID:\".codeUnits); var header = \"Basic $clientCredentials\"; Confidential Clients An OAuth 2.0 client is confidential if it has a client secret. Client secrets can be provided with the auth tool: conduit auth add-client \\ --id com.food_app.mobile \\ --secret myspecialsecret \\ --connect postgres://user:password@dbhost:5432/food_app Client secrets are hashed (many times) with a randomly generated salt before they are stored. Therefore, their actual value must be stored securely elsewhere. (We use LastPass, for example.) Redirect URIs To allow the authorization code flow (provided by AuthCodeController ), a client must have a redirect URI. This is the URI that an authenticating user's browser will be redirected to after entering their username and password. A client must be a confidential client to have a redirect URI. conduit auth add-client \\ --id com.food_app.mobile \\ --secret myspecialsecret \\ --redirect-uri https://someapp.com/callback \\ --connect postgres://user:password@dbhost:5432/food_app Scopes If an application is using OAuth 2.0 scopes, a client can have scopes that it allows tokens to have access to. This allows scopes to be restricted by the client they are authenticating with. conduit auth add-client \\ --id com.food_app.mobile \\ --secret myspecialsecret \\ --allowed-scopes 'scopeA scopeB scopeC.readonly' \\ --connect postgres://user:password@dbhost:5432/food_app Scopes are space-delimited and must be enclosed in quotes so that your shell will treat the entire string as one value. Scope may be set after a client has already been created with conduit auth set-scope : conduit auth set-scope \\ --id com.food_app.mobile \\ --scopes 'scopeA scopeC' \\ --connect postgres://user:password@dbhost:5432/food_app Other Info Like all conduit commands that send commands to a database, the connect option can be replaced by a database.yaml file in the project directory with the following format: username: \"user\" password: \"password\" host: \"host\" port: 5432 databaseName: \"my_app\"","title":"Managing OAuth 2.0 Clients"},{"location":"auth/cli/#manage-oauth-20-clients","text":"The conduit auth command line tool creates OAuth 2.0 client application identifiers and inserts them into an application's database. To use this tool, you must use ManagedAuthDelegate<T> and your database must be contain the tables to support it (see this guide for more details). Exchanging a username and password for an authorization token requires a registered client identifier. A token belongs to both the authenticating user and the client application. Clients are represented by instances of ManagedAuthClient from conduit/managed_auth . Authenticating clients must provide their client ID (and client secret, if applicable) in the Authorization header when requesting access tokens. An OAuth 2.0 client must have a string identifier that uniquely identifies the client. For example, com.food_app.mobile may be a client identifier for the mobile applications for some 'Food App'. To create a simple OAuth 2.0 client, the following command line utility can be run: conduit auth add-client \\ --id com.food_app.mobile \\ --connect postgres://user:password@dbhost:5432/food_app The connect option identifies the database for the application, which this tool will connect to and insert a record into the ManagedAuthClient database table. The identifier is provided through the id option. An OAuth 2.0 client created in this way is a public client; there is no client secret. An OAuth 2.0 client that uses the resource owner grant flow, but cannot secure its client secret, should use this type of client. An application can't secure its client secret if its source code is viewable - like any JavaScript application. It is suggested that native mobile applications also use public clients because their source code could potentially be disassembled to reveal a client secret, but isn't necessarily required. When making requests to client authenticated endpoints (those protected with Authorizer.basic ), the client secret is omitted from the authorization header. The string to base64 encode is clientID: , where the colon ( : ) is required. For example, to generate an authorization header in Dart for a public client: var clientID = \"com.foobar.xyz\"; var clientCredentials = Base64Encoder().convert(\"$clientID:\".codeUnits); var header = \"Basic $clientCredentials\";","title":"Manage OAuth 2.0 Clients"},{"location":"auth/cli/#confidential-clients","text":"An OAuth 2.0 client is confidential if it has a client secret. Client secrets can be provided with the auth tool: conduit auth add-client \\ --id com.food_app.mobile \\ --secret myspecialsecret \\ --connect postgres://user:password@dbhost:5432/food_app Client secrets are hashed (many times) with a randomly generated salt before they are stored. Therefore, their actual value must be stored securely elsewhere. (We use LastPass, for example.)","title":"Confidential Clients"},{"location":"auth/cli/#redirect-uris","text":"To allow the authorization code flow (provided by AuthCodeController ), a client must have a redirect URI. This is the URI that an authenticating user's browser will be redirected to after entering their username and password. A client must be a confidential client to have a redirect URI. conduit auth add-client \\ --id com.food_app.mobile \\ --secret myspecialsecret \\ --redirect-uri https://someapp.com/callback \\ --connect postgres://user:password@dbhost:5432/food_app","title":"Redirect URIs"},{"location":"auth/cli/#scopes","text":"If an application is using OAuth 2.0 scopes, a client can have scopes that it allows tokens to have access to. This allows scopes to be restricted by the client they are authenticating with. conduit auth add-client \\ --id com.food_app.mobile \\ --secret myspecialsecret \\ --allowed-scopes 'scopeA scopeB scopeC.readonly' \\ --connect postgres://user:password@dbhost:5432/food_app Scopes are space-delimited and must be enclosed in quotes so that your shell will treat the entire string as one value. Scope may be set after a client has already been created with conduit auth set-scope : conduit auth set-scope \\ --id com.food_app.mobile \\ --scopes 'scopeA scopeC' \\ --connect postgres://user:password@dbhost:5432/food_app","title":"Scopes"},{"location":"auth/cli/#other-info","text":"Like all conduit commands that send commands to a database, the connect option can be replaced by a database.yaml file in the project directory with the following format: username: \"user\" password: \"password\" host: \"host\" port: 5432 databaseName: \"my_app\"","title":"Other Info"},{"location":"auth/controllers/","text":"Issue Access Tokens with AuthController An application using Conduit's Auth framework must have endpoints to exchange credentials for access tokens. While a developer could implement these endpoints themselves and talk directly to an AuthServer , the OAuth 2.0 specification is where happiness goes to die. Therefore, there exist two Controller s in Conduit that handle granting and refreshing authorization tokens - AuthController and AuthCodeController . Issue, Refresh and Exchange Tokens with AuthController An AuthController grants access tokens and refreshes them. It also exchanges authorization codes obtained from AuthCodeController for access tokens. Using an AuthController in an application is straightforward - hook it up to a Router and pass it an AuthServer . @override Controller get entryPoint { final router = Router(); router .route(\"/auth/token\") .link(() => AuthController(authServer)); return router; } To grant an access token, a client application sends a HTTP POST to the controller. The request must have: an Authorization header with the Client ID and Client Secret (if one exists) and, a x-www-form-urlencoded body with the username and password of the authenticating user. The body must also contain the key-value pair grant_type=password . For example, the following Dart code will initiate successful authentication: var clientID = \"com.app.demo\"; var clientSecret = \"mySecret\"; var body = \"username=bob@conduit.dart.com&password=foobar&grant_type=password\"; var clientCredentials = Base64Encoder().convert(\"$clientID:$clientSecret\".codeUnits); var response = await http.post( \"https://conduit.dart.com/auth/token\", headers: { \"Content-Type\": \"application/x-www-form-urlencoded\", \"Authorization\": \"Basic $clientCredentials\" }, body: body); If the OAuth 2.0 client ID is public - that is, it does not have a client secret - the secret is omitted from the authorization header: // Notice that the separating colon (:) is still present. var clientCredentials = Base64Encoder().convert(\"$clientID:\".codeUnits); The response to a password token request is a JSON body that follows the OAuth 2.0 specification: { \"access_token\": \"...\" \"refresh_token\": \"...\", \"expires_in\": 3600, \"token_type\": \"bearer\" } !!! warning \"\" The expires_in field is a computed property based on the delta of the issue date and expiration date. The unit is seconds. You should avoid manually editing the values for the columns issuedate and expirationdate Tokens are refreshed through the same endpoint, but with a payload that only contains the refresh token and grant_type=refresh_token . grant_type=refresh_token&refresh_token=kjasdiuz9u3namnsd See Conduit Auth CLI for more details on creating OAuth 2.0 client identifier and secrets. If a Conduit application is using scope, an additional scope parameter can contain a space-delimited list of requested authorization scope. Only allowed scopes are returned and granted, and if no scopes are allowed then the request fails. If scope is provided, granted scope will be available in the response body. It is important that an Authorizer must not protect instances of AuthController . The Authorization header is parsed and verified by AuthController . Once granted, an access token can be used to pass Authorizer.bearer() s in the application channel. Issue Authorization Codes with AuthCodeController An AuthCodeController manages the OAuth 2.0 authorization code flow. The authorization code flow is used when a Conduit application allows third party applications access to authorized resources. Let's say you've built a Conduit application that allows people to store notes for themselves. Now, a friend approaches you with their application that is a to-do list. Instead of building their own note-taking feature, your friend wants users of their application to access the notes the user has stored in your application. While trustworthy, you don't want your friend to have access to the username and passwords of your subscribers. Your friend adds a link to their application that takes the user to an HTML page hosted by your server. The user enters their credentials in this page, which sends a POST request to your server. Your server responds by redirecting the user's browser back into your friend's application. An authorization code is included in the query string of the redirect URL. Your friend's application parses the code from the URL and sends it to their server. Behind the scenes, their server exchanges this code with your server for an access token. An AuthCodeController responds to both GET and POST requests. When issued a GET , it serves up a HTML page with a login form. This login form's submit action sends a POST to the same endpoint with the username and password of the user. Upon success, the response from the POST is a 302 redirect with an authorization code. Setting up an AuthCodeController is nearly as simple as setting up an AuthController , but requires a function that renders the HTML login form. Here's an example: @override Controller get entryPoint { final router = Router(); router .route(\"/auth/code\") .link(() => AuthCodeController( authServer, renderAuthorizationPageHTML: renderLogin)); return router; } Future<String> renderLogin( AuthCodeController requestingController, URI requestURI, Map<String, String> queryParameters) { var html = HTMLRenderer.templateWithSubstitutions( \"web/login.html\", requestURI, queryParameters); return html; } It is important that all values passed to HTML rendering function are sent in the form's query parameters - they contain necessary security components and scope information. When your friend's application links to your login page - GET /auth/code - they must include three query parameters: state , client_id , response_type . They may optionally include scope . https://conduit.dart.com/auth/code?client_id=friend.app&response_type=code&state=87uijn3rkja The value of client_id must be created specifically for your friend's application and stored in your database. (See more on generating client identifiers with conduit auth in Conduit Auth CLI .) The response_type must always be code . The state must be a value your friend's application creates - it is often some random value like a session cookie. When a user of your friend's application goes through this process, they are redirected back into your friend's application. Both the generated authorization code and the value for state will be query parameters in the URL. That redirect URL will look like: https://friends.app/code_callback?code=abcd672kk&state=87uijn3rkja The redirect URL is pre-determined when generating the client identifier with conduit auth . Your friend's application verifies that state matches the state they sent in GET /auth/code . They then send the code to their server. The server then exchanges this code with your server by issuing a POST to an AuthController - NOT the AuthCodeController - with the following application/x-www-form-urlencoded body: grant_type=authorization_code&code=abcd672kk An access token will be returned to the server which your friend then stores in their database. Whenever one of their users makes a request that requires accessing your application's data, they will execute requests with that access token.","title":"Issuing Access Tokens"},{"location":"auth/controllers/#issue-access-tokens-with-authcontroller","text":"An application using Conduit's Auth framework must have endpoints to exchange credentials for access tokens. While a developer could implement these endpoints themselves and talk directly to an AuthServer , the OAuth 2.0 specification is where happiness goes to die. Therefore, there exist two Controller s in Conduit that handle granting and refreshing authorization tokens - AuthController and AuthCodeController .","title":"Issue Access Tokens with AuthController"},{"location":"auth/controllers/#issue-refresh-and-exchange-tokens-with-authcontroller","text":"An AuthController grants access tokens and refreshes them. It also exchanges authorization codes obtained from AuthCodeController for access tokens. Using an AuthController in an application is straightforward - hook it up to a Router and pass it an AuthServer . @override Controller get entryPoint { final router = Router(); router .route(\"/auth/token\") .link(() => AuthController(authServer)); return router; } To grant an access token, a client application sends a HTTP POST to the controller. The request must have: an Authorization header with the Client ID and Client Secret (if one exists) and, a x-www-form-urlencoded body with the username and password of the authenticating user. The body must also contain the key-value pair grant_type=password . For example, the following Dart code will initiate successful authentication: var clientID = \"com.app.demo\"; var clientSecret = \"mySecret\"; var body = \"username=bob@conduit.dart.com&password=foobar&grant_type=password\"; var clientCredentials = Base64Encoder().convert(\"$clientID:$clientSecret\".codeUnits); var response = await http.post( \"https://conduit.dart.com/auth/token\", headers: { \"Content-Type\": \"application/x-www-form-urlencoded\", \"Authorization\": \"Basic $clientCredentials\" }, body: body); If the OAuth 2.0 client ID is public - that is, it does not have a client secret - the secret is omitted from the authorization header: // Notice that the separating colon (:) is still present. var clientCredentials = Base64Encoder().convert(\"$clientID:\".codeUnits); The response to a password token request is a JSON body that follows the OAuth 2.0 specification: { \"access_token\": \"...\" \"refresh_token\": \"...\", \"expires_in\": 3600, \"token_type\": \"bearer\" } !!! warning \"\" The expires_in field is a computed property based on the delta of the issue date and expiration date. The unit is seconds. You should avoid manually editing the values for the columns issuedate and expirationdate Tokens are refreshed through the same endpoint, but with a payload that only contains the refresh token and grant_type=refresh_token . grant_type=refresh_token&refresh_token=kjasdiuz9u3namnsd See Conduit Auth CLI for more details on creating OAuth 2.0 client identifier and secrets. If a Conduit application is using scope, an additional scope parameter can contain a space-delimited list of requested authorization scope. Only allowed scopes are returned and granted, and if no scopes are allowed then the request fails. If scope is provided, granted scope will be available in the response body. It is important that an Authorizer must not protect instances of AuthController . The Authorization header is parsed and verified by AuthController . Once granted, an access token can be used to pass Authorizer.bearer() s in the application channel.","title":"Issue, Refresh and Exchange Tokens with AuthController"},{"location":"auth/controllers/#issue-authorization-codes-with-authcodecontroller","text":"An AuthCodeController manages the OAuth 2.0 authorization code flow. The authorization code flow is used when a Conduit application allows third party applications access to authorized resources. Let's say you've built a Conduit application that allows people to store notes for themselves. Now, a friend approaches you with their application that is a to-do list. Instead of building their own note-taking feature, your friend wants users of their application to access the notes the user has stored in your application. While trustworthy, you don't want your friend to have access to the username and passwords of your subscribers. Your friend adds a link to their application that takes the user to an HTML page hosted by your server. The user enters their credentials in this page, which sends a POST request to your server. Your server responds by redirecting the user's browser back into your friend's application. An authorization code is included in the query string of the redirect URL. Your friend's application parses the code from the URL and sends it to their server. Behind the scenes, their server exchanges this code with your server for an access token. An AuthCodeController responds to both GET and POST requests. When issued a GET , it serves up a HTML page with a login form. This login form's submit action sends a POST to the same endpoint with the username and password of the user. Upon success, the response from the POST is a 302 redirect with an authorization code. Setting up an AuthCodeController is nearly as simple as setting up an AuthController , but requires a function that renders the HTML login form. Here's an example: @override Controller get entryPoint { final router = Router(); router .route(\"/auth/code\") .link(() => AuthCodeController( authServer, renderAuthorizationPageHTML: renderLogin)); return router; } Future<String> renderLogin( AuthCodeController requestingController, URI requestURI, Map<String, String> queryParameters) { var html = HTMLRenderer.templateWithSubstitutions( \"web/login.html\", requestURI, queryParameters); return html; } It is important that all values passed to HTML rendering function are sent in the form's query parameters - they contain necessary security components and scope information. When your friend's application links to your login page - GET /auth/code - they must include three query parameters: state , client_id , response_type . They may optionally include scope . https://conduit.dart.com/auth/code?client_id=friend.app&response_type=code&state=87uijn3rkja The value of client_id must be created specifically for your friend's application and stored in your database. (See more on generating client identifiers with conduit auth in Conduit Auth CLI .) The response_type must always be code . The state must be a value your friend's application creates - it is often some random value like a session cookie. When a user of your friend's application goes through this process, they are redirected back into your friend's application. Both the generated authorization code and the value for state will be query parameters in the URL. That redirect URL will look like: https://friends.app/code_callback?code=abcd672kk&state=87uijn3rkja The redirect URL is pre-determined when generating the client identifier with conduit auth . Your friend's application verifies that state matches the state they sent in GET /auth/code . They then send the code to their server. The server then exchanges this code with your server by issuing a POST to an AuthController - NOT the AuthCodeController - with the following application/x-www-form-urlencoded body: grant_type=authorization_code&code=abcd672kk An access token will be returned to the server which your friend then stores in their database. Whenever one of their users makes a request that requires accessing your application's data, they will execute requests with that access token.","title":"Issue Authorization Codes with AuthCodeController"},{"location":"auth/server/","text":"Creating AuthServers to Authenticate and Authorize An AuthServer is a service that handles creating, verifying and refreshing authorization tokens. You create an AuthServer in your application channel and inject into types that deal with authorization. This types include: Authorizer : middleware controller that protects endpoint controllers from unauthorized access AuthController : endpoint controller that grants access tokens AuthCodeController : endpoint controller that grants authorization codes to be exchanged for access tokens An AuthServer must persist the data it uses and creates - like client identifiers and access tokens. Storage is often performed by a database, but it can be in memory, a cache or some other medium. Because of the many different storage mediums, an AuthServer doesn't perform any storage itself - it relies on an instance of AuthServerDelegate specific to your application. This allows storage to be independent of verification logic. Creating Instances of AuthServer and AuthServerDelegate AuthServerDelegate is an interface that an AuthServer uses to handle storage of client identifiers, tokens and other authorization artifacts. An AuthServer must be created with a concrete implementation of AuthServerDelegate . Conduit contains a concrete implementation of AuthServerDelegate that uses the ORM. It is highly recommended to use this implementation instead of implementing your own storage because it has been thoroughly tested and handles cleaning up expired data correctly. This concrete implementation is named ManagedAuthDelegate<T> . It exists in a sub-package of Conduit and must be explicitly imported. Here's an example of creating an AuthServer and ManagedAuthDelegate<T> : import 'package:conduit/conduit.dart'; import 'package:conduit/managed_auth.dart'; class MyApplicationChannel extends ApplicationChannel { AuthServer authServer; @override Future prepare() async { final context = ManagedContext(...); final delegate = ManagedAuthDelegate<User>(context); authServer = AuthServer(delegate); } ... } (Notice that ManagedAuthDelegate has a type argument - this will be covered in the next section.) While AuthServer has methods for handling authorization tasks, it is rarely used directly. Instead, AuthCodeController and AuthController are hooked up to routes to grant authorization tokens through your application's HTTP API. Instances of Authorizer secure routes in channels. All of these types invoke the appropriate methods on the AuthServer . Here's an example ApplicationChannel subclass that sets up and uses authorization: import 'package:conduit/conduit.dart'; import 'package:conduit/managed_auth.dart'; class MyApplicationChannel extends ApplicationChannel { AuthServer authServer; ManagedContext context; @override Future prepare() async { context = ManagedContext(...); final delegate = ManagedAuthDelegate<User>(context); authServer = AuthServer(delegate); } @override Controller get entryPoint { final router = Router(); // Set up auth token route- this grants and refresh tokens router.route(\"/auth/token\").link(() => AuthController(authServer)); // Set up auth code route- this grants temporary access codes that can be exchanged for token router.route(\"/auth/code\").link(() => AuthCodeController(authServer)); // Set up protected route router .route(\"/protected\") .link(() => Authorizer.bearer(authServer)) .link(() => ProtectedController()); return router; } } For more details on authorization controllers like AuthController , see Authorization Controllers . For more details on securing routes, see Authorizers . Using ManagedAuthDelegate ManagedAuthDelegate<T> is a concrete implementation of AuthServerDelegate , providing storage of authorization tokens and clients for an AuthServer . Storage is accomplished by Conduit's ORM. ManagedAuthDelegate<T> , by default, is not part of the standard conduit library. To use this class, an application must import package:conduit/managed_auth.dart . The type argument to ManagedAuthDelegate<T> represents the application's concept of a 'user' or 'account' - OAuth 2.0 terminology would refer to this type as a resource owner . A resource owner must be a ManagedObject<T> subclass that is specific to your application. Its table definition must extend ResourceOwnerTableDefinition and the instance type must implement ManagedAuthResourceOwner<T> , where T is the table definition. A basic definition may look like this: class User extends ManagedObject<_User> implements _User, ManagedAuthResourceOwner<_User> { } class _User extends ResourceOwnerTableDefinition { @Column(unique: true) String email; } By extending ResourceOwnerTableDefinition in the table definition, the database table has the following four columns: an integer primary key named id a unique string username a password hash a salt used to generate the password hash A ResourceOwnerTableDefinition also has a ManagedSet of tokens for each token that has been granted on its behalf. The interface ManagedAuthResourceOwner<T> is a requirement that ensures the type argument is both a ManagedObject<T> and ResourceOwnerTableDefinition , and serves no other purpose than to restrict ManagedAuthDelegate<T> 's type parameter. This structure allows an application to declare its own 'user' type while still enforcing the needs of Conduit's OAuth 2.0 implementation. The managed_auth library also declares two ManagedObject<T> subclasses. ManagedAuthToken represents instances of authorization tokens and codes, and ManagedAuthClient represents instances of OAuth 2.0 clients. This means that a Conduit application that uses ManagedAuthDelegate<T> has a minimum of three database tables: users, tokens and clients. ManagedAuthDelegate<T> will delete authorization tokens and codes when they are no longer in use. This is determined by how many tokens a resource owner has and the tokens expiration dates. Once a resource owner acquires more than 40 tokens/codes, the oldest tokens/codes (determined by expiration date) are deleted. Effectively, the resource owner is limited to 40 tokens. This number can be changed when instantiating ManagedAuthDelegate<T> : final delegate = ManagedAuthDelegate(context, tokenLimit: 20); Configuring the Database ManagedAuthDelegate<T> requires database tables for its users, tokens and clients. Use the database command-line tool on your project to generate migration scripts and execute them against a database. This tool will see the declarations for your user type, ManagedAuthToken and ManagedAuthClient and create the appropriate tables.","title":"Setting up Authorization"},{"location":"auth/server/#creating-authservers-to-authenticate-and-authorize","text":"An AuthServer is a service that handles creating, verifying and refreshing authorization tokens. You create an AuthServer in your application channel and inject into types that deal with authorization. This types include: Authorizer : middleware controller that protects endpoint controllers from unauthorized access AuthController : endpoint controller that grants access tokens AuthCodeController : endpoint controller that grants authorization codes to be exchanged for access tokens An AuthServer must persist the data it uses and creates - like client identifiers and access tokens. Storage is often performed by a database, but it can be in memory, a cache or some other medium. Because of the many different storage mediums, an AuthServer doesn't perform any storage itself - it relies on an instance of AuthServerDelegate specific to your application. This allows storage to be independent of verification logic.","title":"Creating AuthServers to Authenticate and Authorize"},{"location":"auth/server/#creating-instances-of-authserver-and-authserverdelegate","text":"AuthServerDelegate is an interface that an AuthServer uses to handle storage of client identifiers, tokens and other authorization artifacts. An AuthServer must be created with a concrete implementation of AuthServerDelegate . Conduit contains a concrete implementation of AuthServerDelegate that uses the ORM. It is highly recommended to use this implementation instead of implementing your own storage because it has been thoroughly tested and handles cleaning up expired data correctly. This concrete implementation is named ManagedAuthDelegate<T> . It exists in a sub-package of Conduit and must be explicitly imported. Here's an example of creating an AuthServer and ManagedAuthDelegate<T> : import 'package:conduit/conduit.dart'; import 'package:conduit/managed_auth.dart'; class MyApplicationChannel extends ApplicationChannel { AuthServer authServer; @override Future prepare() async { final context = ManagedContext(...); final delegate = ManagedAuthDelegate<User>(context); authServer = AuthServer(delegate); } ... } (Notice that ManagedAuthDelegate has a type argument - this will be covered in the next section.) While AuthServer has methods for handling authorization tasks, it is rarely used directly. Instead, AuthCodeController and AuthController are hooked up to routes to grant authorization tokens through your application's HTTP API. Instances of Authorizer secure routes in channels. All of these types invoke the appropriate methods on the AuthServer . Here's an example ApplicationChannel subclass that sets up and uses authorization: import 'package:conduit/conduit.dart'; import 'package:conduit/managed_auth.dart'; class MyApplicationChannel extends ApplicationChannel { AuthServer authServer; ManagedContext context; @override Future prepare() async { context = ManagedContext(...); final delegate = ManagedAuthDelegate<User>(context); authServer = AuthServer(delegate); } @override Controller get entryPoint { final router = Router(); // Set up auth token route- this grants and refresh tokens router.route(\"/auth/token\").link(() => AuthController(authServer)); // Set up auth code route- this grants temporary access codes that can be exchanged for token router.route(\"/auth/code\").link(() => AuthCodeController(authServer)); // Set up protected route router .route(\"/protected\") .link(() => Authorizer.bearer(authServer)) .link(() => ProtectedController()); return router; } } For more details on authorization controllers like AuthController , see Authorization Controllers . For more details on securing routes, see Authorizers .","title":"Creating Instances of AuthServer and AuthServerDelegate"},{"location":"auth/server/#using-managedauthdelegate","text":"ManagedAuthDelegate<T> is a concrete implementation of AuthServerDelegate , providing storage of authorization tokens and clients for an AuthServer . Storage is accomplished by Conduit's ORM. ManagedAuthDelegate<T> , by default, is not part of the standard conduit library. To use this class, an application must import package:conduit/managed_auth.dart . The type argument to ManagedAuthDelegate<T> represents the application's concept of a 'user' or 'account' - OAuth 2.0 terminology would refer to this type as a resource owner . A resource owner must be a ManagedObject<T> subclass that is specific to your application. Its table definition must extend ResourceOwnerTableDefinition and the instance type must implement ManagedAuthResourceOwner<T> , where T is the table definition. A basic definition may look like this: class User extends ManagedObject<_User> implements _User, ManagedAuthResourceOwner<_User> { } class _User extends ResourceOwnerTableDefinition { @Column(unique: true) String email; } By extending ResourceOwnerTableDefinition in the table definition, the database table has the following four columns: an integer primary key named id a unique string username a password hash a salt used to generate the password hash A ResourceOwnerTableDefinition also has a ManagedSet of tokens for each token that has been granted on its behalf. The interface ManagedAuthResourceOwner<T> is a requirement that ensures the type argument is both a ManagedObject<T> and ResourceOwnerTableDefinition , and serves no other purpose than to restrict ManagedAuthDelegate<T> 's type parameter. This structure allows an application to declare its own 'user' type while still enforcing the needs of Conduit's OAuth 2.0 implementation. The managed_auth library also declares two ManagedObject<T> subclasses. ManagedAuthToken represents instances of authorization tokens and codes, and ManagedAuthClient represents instances of OAuth 2.0 clients. This means that a Conduit application that uses ManagedAuthDelegate<T> has a minimum of three database tables: users, tokens and clients. ManagedAuthDelegate<T> will delete authorization tokens and codes when they are no longer in use. This is determined by how many tokens a resource owner has and the tokens expiration dates. Once a resource owner acquires more than 40 tokens/codes, the oldest tokens/codes (determined by expiration date) are deleted. Effectively, the resource owner is limited to 40 tokens. This number can be changed when instantiating ManagedAuthDelegate<T> : final delegate = ManagedAuthDelegate(context, tokenLimit: 20);","title":"Using ManagedAuthDelegate"},{"location":"auth/server/#configuring-the-database","text":"ManagedAuthDelegate<T> requires database tables for its users, tokens and clients. Use the database command-line tool on your project to generate migration scripts and execute them against a database. This tool will see the declarations for your user type, ManagedAuthToken and ManagedAuthClient and create the appropriate tables.","title":"Configuring the Database"},{"location":"auth/what_is_oauth/","text":"What is OAuth 2.0? Most applications have the concept of a user. To prevent just anyone from saying they are this user, the user has a password. When a user wants to use your application, they send their username and password to the server so it can ensure they are who they say they are. The simple way to do this is to send the username and password in an Authorization header for every request. Two reasons this is bad: first, every time the user wants to do something, their password is sent in every request and that can be unsafe. Second, any application that wants to keep the user logged in has to store that password - and that is unsafe. In OAuth 2.0, the user gives their username and password to a client application once. The application sends those credentials to a server, and the server gives the application back an access token. A access token is a long, random string that no one can guess. When the user wants to do more stuff, the application sends the token with every request, instead of the user's password. The server checks the token, makes sure its not expired, and then lets the application's request go through. The application doesn't have to store the password and doesn't have to ask the user for their password again. This credential-for-token exchange happens by sending a POST request to some endpoint, where the username and password are sent in the request body. Typically, a Conduit application's route for this is /auth/token and handled by an instance of AuthController . OAuth 2.0 makes a subtle distinction: a user and the application they are using are not the same thing. It's intuitive to think of a user as \"making a request to the server\", but in reality, the user makes a request to an application and the application makes the request to the server. The server grants the application access on behalf of the user. In other words, when a user enters their credentials into an application, the application goes to the server and says \"Hey, this user said I can do stuff for them. Look, this is their secret password!\" This is an important distinction, because an OAuth 2.0 server doesn't just verify users: it also verifies applications. An application has a identifier that has been registered with the server. So, for an ecosystem that has a web client, an Android and an iOS app there would likely be three identifiers - one for each. The client application usually stores that identifier in a database. This identifier is called a client identifier . Client identifiers are added to Conduit applications with the conduit auth tool (see Conduit Auth CLI ). When the user is logging in through an application, they submit their username and password. The user doesn't provide the client identifier - in fact, the user doesn't know it. The application sends a request with the user's username and password in the request body, and the client identifier in the Authorization header. All three have to check out for the server to give the application back a token. The full request in pseudo-code looks something like: var request = HTTPRequest(\"/auth/token\"); request.method = \"POST\"; request.contentType = \"application/x-www-form-urlencoded\"; request.authorization = Base64.encode(\"$clientID:\"); request.body = { \"username\" : \"bob@conduit.dart.com\", \"password\" : \"supersecretstuff\", \"grant_type\" : \"password\" }; An access token can expire. How long it takes to expire is up to the server - Conduit defaults to 24 hours. At first glance, this means that the application would have to ask the user for a password again. But, tokens can also be refreshed. Refreshing a token grants a brand new access token, but without having to ask for the password. This is possible because an access token comes with a refresh token . The refresh token is another long, random string. So, the JSON the server sends back when granting a token looks like this: { \"access_token\" : \"Abca09zzzza2o2kelmzlli3ijlka\", \"token_type\" : \"bearer\", \"refresh_token\" : \"lkmLIAmooa898nm20jannnnnxaww\", \"expire_in\" : 3600 } The application hangs on to both an access token and a refresh token. When the token expires, it will send the refresh token back to the server to get a replacement access token. This is done through the same route that the access token came from - /auth/token - except the parameters are a bit different: var request = HTTPRequest(\"/auth/token\"); request.method = \"POST\"; request.contentType = \"application/x-www-form-urlencoded\"; request.authorization = Base64.encode(\"$clientID:\"); request.body = { \"refresh_token\" : \"lkmLIAmooa898nm20jannnnnxaww\", \"grant_type\" : \"refresh_token\" }; Exchanging a refresh token has the same response as the initial exchange for username and password - except a few values will have changed. The verification and storage of authorization and authentication information is managed by an AuthServer . Other Methods for Obtaining Authorization The method of getting a token above - sending a username and password to /auth/token - is just one of four possible methods OAuth 2.0 uses to authenticate a user. This particular one is called the resource owner password credentials grant . A resource owner is a fancy word for a 'user'. We can shorten it up to just the 'password flow'. It's probably the most common flow - mobiles applications and front-end web applications often use this flow. When you enter your credentials, the client application sends them directly to the server. The other commonly used flow prevents the client application from ever seeing the user's credentials. For example, you might sign into Pivotal Tracker with your Google account. Your account on Pivotal Tracker doesn't have a password. Instead, it is linked to your Google account - which does. Pivotal Tracker never sees your Google password. When you login to Pivotal Tracker in this way, it takes you to Google's authentication page - owned and operated by Google. When you login successfully, Google gives Pivotal Tracker your token. Pivotal Tracker is now an application that can do things on your behalf. This is called the authorization code grant - or just 'auth code flow'. An instance of AuthCodeController handles granting authorization codes. Once a code is received, it can be exchanged for a token via an AuthController .","title":"What is OAuth 2.0?"},{"location":"auth/what_is_oauth/#what-is-oauth-20","text":"Most applications have the concept of a user. To prevent just anyone from saying they are this user, the user has a password. When a user wants to use your application, they send their username and password to the server so it can ensure they are who they say they are. The simple way to do this is to send the username and password in an Authorization header for every request. Two reasons this is bad: first, every time the user wants to do something, their password is sent in every request and that can be unsafe. Second, any application that wants to keep the user logged in has to store that password - and that is unsafe. In OAuth 2.0, the user gives their username and password to a client application once. The application sends those credentials to a server, and the server gives the application back an access token. A access token is a long, random string that no one can guess. When the user wants to do more stuff, the application sends the token with every request, instead of the user's password. The server checks the token, makes sure its not expired, and then lets the application's request go through. The application doesn't have to store the password and doesn't have to ask the user for their password again. This credential-for-token exchange happens by sending a POST request to some endpoint, where the username and password are sent in the request body. Typically, a Conduit application's route for this is /auth/token and handled by an instance of AuthController . OAuth 2.0 makes a subtle distinction: a user and the application they are using are not the same thing. It's intuitive to think of a user as \"making a request to the server\", but in reality, the user makes a request to an application and the application makes the request to the server. The server grants the application access on behalf of the user. In other words, when a user enters their credentials into an application, the application goes to the server and says \"Hey, this user said I can do stuff for them. Look, this is their secret password!\" This is an important distinction, because an OAuth 2.0 server doesn't just verify users: it also verifies applications. An application has a identifier that has been registered with the server. So, for an ecosystem that has a web client, an Android and an iOS app there would likely be three identifiers - one for each. The client application usually stores that identifier in a database. This identifier is called a client identifier . Client identifiers are added to Conduit applications with the conduit auth tool (see Conduit Auth CLI ). When the user is logging in through an application, they submit their username and password. The user doesn't provide the client identifier - in fact, the user doesn't know it. The application sends a request with the user's username and password in the request body, and the client identifier in the Authorization header. All three have to check out for the server to give the application back a token. The full request in pseudo-code looks something like: var request = HTTPRequest(\"/auth/token\"); request.method = \"POST\"; request.contentType = \"application/x-www-form-urlencoded\"; request.authorization = Base64.encode(\"$clientID:\"); request.body = { \"username\" : \"bob@conduit.dart.com\", \"password\" : \"supersecretstuff\", \"grant_type\" : \"password\" }; An access token can expire. How long it takes to expire is up to the server - Conduit defaults to 24 hours. At first glance, this means that the application would have to ask the user for a password again. But, tokens can also be refreshed. Refreshing a token grants a brand new access token, but without having to ask for the password. This is possible because an access token comes with a refresh token . The refresh token is another long, random string. So, the JSON the server sends back when granting a token looks like this: { \"access_token\" : \"Abca09zzzza2o2kelmzlli3ijlka\", \"token_type\" : \"bearer\", \"refresh_token\" : \"lkmLIAmooa898nm20jannnnnxaww\", \"expire_in\" : 3600 } The application hangs on to both an access token and a refresh token. When the token expires, it will send the refresh token back to the server to get a replacement access token. This is done through the same route that the access token came from - /auth/token - except the parameters are a bit different: var request = HTTPRequest(\"/auth/token\"); request.method = \"POST\"; request.contentType = \"application/x-www-form-urlencoded\"; request.authorization = Base64.encode(\"$clientID:\"); request.body = { \"refresh_token\" : \"lkmLIAmooa898nm20jannnnnxaww\", \"grant_type\" : \"refresh_token\" }; Exchanging a refresh token has the same response as the initial exchange for username and password - except a few values will have changed. The verification and storage of authorization and authentication information is managed by an AuthServer .","title":"What is OAuth 2.0?"},{"location":"auth/what_is_oauth/#other-methods-for-obtaining-authorization","text":"The method of getting a token above - sending a username and password to /auth/token - is just one of four possible methods OAuth 2.0 uses to authenticate a user. This particular one is called the resource owner password credentials grant . A resource owner is a fancy word for a 'user'. We can shorten it up to just the 'password flow'. It's probably the most common flow - mobiles applications and front-end web applications often use this flow. When you enter your credentials, the client application sends them directly to the server. The other commonly used flow prevents the client application from ever seeing the user's credentials. For example, you might sign into Pivotal Tracker with your Google account. Your account on Pivotal Tracker doesn't have a password. Instead, it is linked to your Google account - which does. Pivotal Tracker never sees your Google password. When you login to Pivotal Tracker in this way, it takes you to Google's authentication page - owned and operated by Google. When you login successfully, Google gives Pivotal Tracker your token. Pivotal Tracker is now an application that can do things on your behalf. This is called the authorization code grant - or just 'auth code flow'. An instance of AuthCodeController handles granting authorization codes. Once a code is received, it can be exchanged for a token via an AuthController .","title":"Other Methods for Obtaining Authorization"},{"location":"cli/","text":"CLI The Conduit command-line utility creates projects, runs applications, manages database schemas and other tasks. This tool is installed through pub : pub global activate conduit The above command updates the tool if a new version is available. You should ensure that conduit and your application use the same version of Conduit. All command-line tools have a --help option to show their options. Guides Creating Applications Running Applications Managing a Database Managing OAuth 2.0 Clients and Scopes Documenting an API","title":"CLI"},{"location":"cli/#cli","text":"The Conduit command-line utility creates projects, runs applications, manages database schemas and other tasks. This tool is installed through pub : pub global activate conduit The above command updates the tool if a new version is available. You should ensure that conduit and your application use the same version of Conduit. All command-line tools have a --help option to show their options.","title":"CLI"},{"location":"cli/#guides","text":"Creating Applications Running Applications Managing a Database Managing OAuth 2.0 Clients and Scopes Documenting an API","title":"Guides"},{"location":"cli/create/","text":"Creating Conduit Applications The conduit create command-line tool creates applications from a template. The usage is: conduit create app_name The application name must be snake_case - all lower case, no spaces, no symbols other than `_`. By default, a generated project is fairly empty - it has the minimal content, but the structure of a complete application. For applications that use Conduit's ORM or OAuth 2.0 behavior, extended templates exist. These can be listed with the following: conduit create list-templates To pick a template, add the -t option to conduit create . For example, the following uses the db template: conduit create -t db app_name The templates are located in the Conduit package under examples/templates . When creating a new project from a template, the tool copies the contents of one of the template directories into your current working directory and substitutes some names with your project name.","title":"Creating Applications"},{"location":"cli/create/#creating-conduit-applications","text":"The conduit create command-line tool creates applications from a template. The usage is: conduit create app_name The application name must be snake_case - all lower case, no spaces, no symbols other than `_`. By default, a generated project is fairly empty - it has the minimal content, but the structure of a complete application. For applications that use Conduit's ORM or OAuth 2.0 behavior, extended templates exist. These can be listed with the following: conduit create list-templates To pick a template, add the -t option to conduit create . For example, the following uses the db template: conduit create -t db app_name The templates are located in the Conduit package under examples/templates . When creating a new project from a template, the tool copies the contents of one of the template directories into your current working directory and substitutes some names with your project name.","title":"Creating Conduit Applications"},{"location":"cli/document/","text":"Documenting Conduit Applications The conduit document tool generates an OpenAPI (formerly Swagger) specification by reflecting on your application's code. This command is run in a project directory and will emit the JSON specification to stdout. You can redirect this to a file: conduit document > swagger.json The file config.src.yaml must exist in your project directory so that the application can be initialized in 'test' mode for the documentation to be generated.","title":"Generating an OpenAPI/Swagger Specification"},{"location":"cli/document/#documenting-conduit-applications","text":"The conduit document tool generates an OpenAPI (formerly Swagger) specification by reflecting on your application's code. This command is run in a project directory and will emit the JSON specification to stdout. You can redirect this to a file: conduit document > swagger.json The file config.src.yaml must exist in your project directory so that the application can be initialized in 'test' mode for the documentation to be generated.","title":"Documenting Conduit Applications"},{"location":"cli/running/","text":"Running Applications with Conduit Serve The conduit serve command-line tool runs applications. This tool is run in a project directory and it generates a Dart script that bootstraps your application. The structure of the project does matter - if you are creating a project from the template, the appropriate structure already exists. Otherwise, you must ensure you have a library file with the same name as your application (as defined in pubspec.yaml ). For example, an application named todo must have a lib/todo.dart file. This file must import the file that declares your application's ApplicationChannel . You may specify options like the number of isolates to run the application on and which port to listen for requests on. See more details with conduit serve --help . Hot Reload In Flutter, a hot reload restarts an application after a code change, but keeps the state of the application intact - such as which screen the user is on and what data is available in memory. This is an incredible feature for faster development cycles in an environment that can often be difficult to test efficiently. Hot reload is often requested as a feature of Conduit, but it doesn't quite make sense in an HTTP API which is not supposed to retain state. Truth be told, our team rarely uses a development cycle that involves making frequent code changes to a locally running instance. Instead, we use package:conduit_test to ensure all of our testing efforts are captured in automated tests that continually run over the course of the project. A shortcut to restart the locally running application after a change is admittedly useful in some scenarios. However, this is already an existing feature of most IDEs and should not be implemented by conduit . In IntelliJ, this feature is called 'Rerun' and the default keyboard shortcut is ^F5 in macOS. To use this shortcut, instead of running with conduit serve , right-click on the bin/main.dart script that is generated when you create a new project and select Run . Once this process is running, you can rerun it with ^F5 or with the Rerun button on the Run panel.","title":"Running Applications"},{"location":"cli/running/#running-applications-with-conduit-serve","text":"The conduit serve command-line tool runs applications. This tool is run in a project directory and it generates a Dart script that bootstraps your application. The structure of the project does matter - if you are creating a project from the template, the appropriate structure already exists. Otherwise, you must ensure you have a library file with the same name as your application (as defined in pubspec.yaml ). For example, an application named todo must have a lib/todo.dart file. This file must import the file that declares your application's ApplicationChannel . You may specify options like the number of isolates to run the application on and which port to listen for requests on. See more details with conduit serve --help .","title":"Running Applications with Conduit Serve"},{"location":"cli/running/#hot-reload","text":"In Flutter, a hot reload restarts an application after a code change, but keeps the state of the application intact - such as which screen the user is on and what data is available in memory. This is an incredible feature for faster development cycles in an environment that can often be difficult to test efficiently. Hot reload is often requested as a feature of Conduit, but it doesn't quite make sense in an HTTP API which is not supposed to retain state. Truth be told, our team rarely uses a development cycle that involves making frequent code changes to a locally running instance. Instead, we use package:conduit_test to ensure all of our testing efforts are captured in automated tests that continually run over the course of the project. A shortcut to restart the locally running application after a change is admittedly useful in some scenarios. However, this is already an existing feature of most IDEs and should not be implemented by conduit . In IntelliJ, this feature is called 'Rerun' and the default keyboard shortcut is ^F5 in macOS. To use this shortcut, instead of running with conduit serve , right-click on the bin/main.dart script that is generated when you create a new project and select Run . Once this process is running, you can rerun it with ^F5 or with the Rerun button on the Run panel.","title":"Hot Reload"},{"location":"core_concepts/","text":"Core Concepts Resources Resources are the things your application exposes through its HTTP API. A resource can be anything - a user profile in an application, a temperature sensor in Antarctica, or a high score for a game. For example, the GitHub API exposes organization, repository, issue and pull request resources; a social network API has profiles, posts, and user relationships. Resources are organized into collections (e.g., all of the posts), for which individual resources within that collection can be uniquely identified (e.g., a single post). Requests are made to an application to retrieve the state of a resource or to provide the desired state of a resource. Most often, resources are represented as JSON arrays and objects. When retrieving a resource, its JSON representation is encoded into the response body. When providing the desired state of a resource, a client sends the JSON representation of the desired resource state in the request body. For more details on the concept of a resource, see the RFC Specification for HTTP/1.1 . Routing Resources are identified by the path of an HTTP request. For example, the URL http://example.com/organizations identifies the collection of organization resources on the server http://example.com . The URL http://example.com/organizations/1 identifies a single organization. An application exposes routes for each resource it manages. A route is a string that matches the path of a request. When a request's path matches a route, the associated handler is invoked to handle the request. Routes look like paths, but have some additional syntax. For example, the route /organizations will match requests with the path /organizations . The route /organizations/:id will match the paths /organizations/1 , /organizations/2 , and so on. Complex routes can be formed with additional syntax. See the guide on routing for usage details. Controllers Controllers are objects that handle requests. For example, a controller might fetch rows from a database and send them to the client in the response body. Another controller might verify the username and password of a request's Authorization header are valid. Controllers are linked together to form a series of actions to take for a request. These linked together controllers are called a channel . If the above examples were linked together, the channel would check if a request were authorized before it sent a response containing database rows. There are two flavors of controllers. An endpoint controller performs operations on a resource or resource collection, and always sends a response. Endpoint controllers fulfill requests by returning the state of a resource or by changing the state of a resource. You write most of your application-specific logic endpoint controllers. A middleware controller takes an action for a request, but isn't responsible for fulfilling the request. Middleware controllers can do many different things and are often reusable in many channels. Most often, a middleware controller validates something about a request before it reaches an endpoint controller. Middleware controllers can send a response for a request, and doing so prevents any other controller in that channel from handling the request. A channel must have exactly one endpoint controller. It can be preceded by zero or more middleware controllers. See the guides on Controllers and ResourceControllers for usage details. The Application Channel The application channel is an object that contains all of the controllers in an application. It designates one controller as the first controller to receive every request called its entry point . Controllers are linked to the entry point (directly or transitively) to form the entire application channel. In nearly every application, the entry point is a router; this controller splits the channel into sub-channels for a given route. The application channel is also responsible for initializing the application's services, reading configuration files and other startup related tasks. See the guide on the Application Channel for more details. Services A service is an object that encapsulates complex tasks or algorithms, external communication or tasks that will be reused across an application. The purpose of a service object is to provide a simple interface to more detailed behavior. For example, a database connection is a service object; a user of a database connection doesn't know the details of how the connection is made or how to encode the query onto the wire, but it can still execute queries. The primary user of service objects are controllers. Services are injected into controllers by passing them as arguments to the controller's constructor. The controller keeps a reference to the service, so that it can use it when handling a request. For more details on injecting services, see the guide on the Application Channel . Isolates Isolates are memory-isolated threads; an object created on one isolate can't be referenced by another isolate. When an application starts, one or more isolates containing replicas of your application code are spawned. This behavior effectively 'load balances' your application across multiple threads. A benefit to this structure is that each isolate has its own set of services, like database connections. This eliminates the need for techniques like 'database connection pooling', because the entire application is effectively 'pooled'. Bindings A request might contain headers, query parameters, a body and path parameters that need to be parsed, validated and used in controller code. Bindings are annotations added to variables that perform this parsing and validation automatically. Appropriate error responses are sent when a bound value can't be parsed into expected type or validation fails. Bindings cut down on boiler plate code and reduce testing surface, making development faster and code easier to reason about. For more information on bindings, see the guide on Resource Controllers . Queries and Data Models Application store information in databases for persistence. Writing database queries by hand is error-prone and doesn't leverage static analysis tools that are so valuable in a Dart application. Conduit's ORM (Object-Relational Mapping) provides statically-typed queries that are easy to write and test. Your application's data model is defined by creating Dart classes. Each class is mapped to a database table, and each property of that class is mapped to a column in that table. Conduit's command-line tool generates database migration files that detect changes in your data model that can be applied to a live, versioned database. A data model can also be represented as a JSON object to build tools on top of your application. For more details, see the guide on Databases . Authorization OAuth 2.0 is a standardized authorization framework. Conduit contains a specification-compliant implementation of an OAuth 2.0 server that can be integrated directly into your application, or stood up alone to provide an authorization server for federated services. This implementation is easily customizable - it can store authorization artifacts - like tokens and client identifiers - in different types of databases or use stateless authorization mechanisms like JWT. The default implementation leverages the Conduit ORM to store artifacts in PostgreSQL. For more details, see the guide on Authorization . Documentation OpenAPI 3.0 is a standardized documentation format for HTTP APIs. Many built-in Conduit objects support 'automatic' documentation. Objects that are specific to your application can build on top of this to immediately document your application for every change you make. For more details, see the guide on OpenAPI Documentation .","title":"Core Concepts"},{"location":"core_concepts/#core-concepts","text":"","title":"Core Concepts"},{"location":"core_concepts/#resources","text":"Resources are the things your application exposes through its HTTP API. A resource can be anything - a user profile in an application, a temperature sensor in Antarctica, or a high score for a game. For example, the GitHub API exposes organization, repository, issue and pull request resources; a social network API has profiles, posts, and user relationships. Resources are organized into collections (e.g., all of the posts), for which individual resources within that collection can be uniquely identified (e.g., a single post). Requests are made to an application to retrieve the state of a resource or to provide the desired state of a resource. Most often, resources are represented as JSON arrays and objects. When retrieving a resource, its JSON representation is encoded into the response body. When providing the desired state of a resource, a client sends the JSON representation of the desired resource state in the request body. For more details on the concept of a resource, see the RFC Specification for HTTP/1.1 .","title":"Resources"},{"location":"core_concepts/#routing","text":"Resources are identified by the path of an HTTP request. For example, the URL http://example.com/organizations identifies the collection of organization resources on the server http://example.com . The URL http://example.com/organizations/1 identifies a single organization. An application exposes routes for each resource it manages. A route is a string that matches the path of a request. When a request's path matches a route, the associated handler is invoked to handle the request. Routes look like paths, but have some additional syntax. For example, the route /organizations will match requests with the path /organizations . The route /organizations/:id will match the paths /organizations/1 , /organizations/2 , and so on. Complex routes can be formed with additional syntax. See the guide on routing for usage details.","title":"Routing"},{"location":"core_concepts/#controllers","text":"Controllers are objects that handle requests. For example, a controller might fetch rows from a database and send them to the client in the response body. Another controller might verify the username and password of a request's Authorization header are valid. Controllers are linked together to form a series of actions to take for a request. These linked together controllers are called a channel . If the above examples were linked together, the channel would check if a request were authorized before it sent a response containing database rows. There are two flavors of controllers. An endpoint controller performs operations on a resource or resource collection, and always sends a response. Endpoint controllers fulfill requests by returning the state of a resource or by changing the state of a resource. You write most of your application-specific logic endpoint controllers. A middleware controller takes an action for a request, but isn't responsible for fulfilling the request. Middleware controllers can do many different things and are often reusable in many channels. Most often, a middleware controller validates something about a request before it reaches an endpoint controller. Middleware controllers can send a response for a request, and doing so prevents any other controller in that channel from handling the request. A channel must have exactly one endpoint controller. It can be preceded by zero or more middleware controllers. See the guides on Controllers and ResourceControllers for usage details.","title":"Controllers"},{"location":"core_concepts/#the-application-channel","text":"The application channel is an object that contains all of the controllers in an application. It designates one controller as the first controller to receive every request called its entry point . Controllers are linked to the entry point (directly or transitively) to form the entire application channel. In nearly every application, the entry point is a router; this controller splits the channel into sub-channels for a given route. The application channel is also responsible for initializing the application's services, reading configuration files and other startup related tasks. See the guide on the Application Channel for more details.","title":"The Application Channel"},{"location":"core_concepts/#services","text":"A service is an object that encapsulates complex tasks or algorithms, external communication or tasks that will be reused across an application. The purpose of a service object is to provide a simple interface to more detailed behavior. For example, a database connection is a service object; a user of a database connection doesn't know the details of how the connection is made or how to encode the query onto the wire, but it can still execute queries. The primary user of service objects are controllers. Services are injected into controllers by passing them as arguments to the controller's constructor. The controller keeps a reference to the service, so that it can use it when handling a request. For more details on injecting services, see the guide on the Application Channel .","title":"Services"},{"location":"core_concepts/#isolates","text":"Isolates are memory-isolated threads; an object created on one isolate can't be referenced by another isolate. When an application starts, one or more isolates containing replicas of your application code are spawned. This behavior effectively 'load balances' your application across multiple threads. A benefit to this structure is that each isolate has its own set of services, like database connections. This eliminates the need for techniques like 'database connection pooling', because the entire application is effectively 'pooled'.","title":"Isolates"},{"location":"core_concepts/#bindings","text":"A request might contain headers, query parameters, a body and path parameters that need to be parsed, validated and used in controller code. Bindings are annotations added to variables that perform this parsing and validation automatically. Appropriate error responses are sent when a bound value can't be parsed into expected type or validation fails. Bindings cut down on boiler plate code and reduce testing surface, making development faster and code easier to reason about. For more information on bindings, see the guide on Resource Controllers .","title":"Bindings"},{"location":"core_concepts/#queries-and-data-models","text":"Application store information in databases for persistence. Writing database queries by hand is error-prone and doesn't leverage static analysis tools that are so valuable in a Dart application. Conduit's ORM (Object-Relational Mapping) provides statically-typed queries that are easy to write and test. Your application's data model is defined by creating Dart classes. Each class is mapped to a database table, and each property of that class is mapped to a column in that table. Conduit's command-line tool generates database migration files that detect changes in your data model that can be applied to a live, versioned database. A data model can also be represented as a JSON object to build tools on top of your application. For more details, see the guide on Databases .","title":"Queries and Data Models"},{"location":"core_concepts/#authorization","text":"OAuth 2.0 is a standardized authorization framework. Conduit contains a specification-compliant implementation of an OAuth 2.0 server that can be integrated directly into your application, or stood up alone to provide an authorization server for federated services. This implementation is easily customizable - it can store authorization artifacts - like tokens and client identifiers - in different types of databases or use stateless authorization mechanisms like JWT. The default implementation leverages the Conduit ORM to store artifacts in PostgreSQL. For more details, see the guide on Authorization .","title":"Authorization"},{"location":"core_concepts/#documentation","text":"OpenAPI 3.0 is a standardized documentation format for HTTP APIs. Many built-in Conduit objects support 'automatic' documentation. Objects that are specific to your application can build on top of this to immediately document your application for every change you make. For more details, see the guide on OpenAPI Documentation .","title":"Documentation"},{"location":"core_concepts/best_practices/","text":"Best Practices Keep Dart Projects Separate Because Dart is cross-platform, developers should avoid combining client application projects with Conduit projects. Instead, use a single repository with an independent project for each facet of the system. When there are opportunities for code sharing between platforms (typically between Flutter and AngularDart), shared code can live in a dependency project in the same repository. A typical directory structure for an multi-faceted application looks like this: application_name/ conduit/ flutter/ angular/ shared/ {% hint style=\"info\" %} \"Project Definition\" A project is a directory that contain a pubspec.yaml file and lib directory. {% endhint %} It is tempting to share your data model types between your server and client applications, but this falls apart for anything but the most simple of applications. There are enough behavioral differences between the four representations of your data model - in the database, on the server, on the wire (JSON), and on the client - that a single type will have a hard time encompassing. Instead, generate an OpenAPI specification with conduit document and use one of the many open-source tools for generating client data model types. Split discrete components into separate packages It can often be useful to split discrete code pieces into separate packages with their own sub-repo. Non-trivial Flutter widgets are a good example. Having the code in a separate package facilitate allocating a single owner to the package. Packages with a single owner have much less management overhead and cleaner commit logs. It also stops developers treading on each others toes. Remember a component isn't just a flutter widget. It can be a collection of classes/functions that provide a specific service, this could be something like permission management or formating/parsing monetary amounts. Any collection of code that together delivers a singular 'concern' is a good candidate. Use Test Driven Development (or something close to it) In Conduit, testing is a first-class citizen. The conduit_test package has classes and methods for initializing and running an application for testing, making requests to that application, and verifying the responses. There is value to using tools like Postman or CURL to test proof of concept code, but the conduit_test package is geared specifically for replacing these tools while retaining automated tests as the project grows. An example test suite looks like this: void main() { final harness = new Harness()..install(); test(\"GET /endpoint returns 200 and a simple object\", () async { final response = await harness.agent.get(\"/endpoint\"); expectResponse(response, 200, body: {\"key\": \"value\"}); }); } Use a bin Script to Verify Assumptions Keep a simple Dart script file in the bin/ directory that imports your project. Use this file as a scratchpad to test exploratory code before committing to a test suite. Don't check this file into source control. import 'package:myapp/myapp.dart'; Future main() async { var whatIsThis = await someYetToBeNamedUsefullyMethod(); print(\"$whatIsThis\"); } Create New Projects from a Template Use conduit create to create applications with the appropriate structure and boilerplate. There are templates for different kinds of applications; view these templates with conduit create list-templates . Use a Debugger A debugger allows you to stop execution of a running application at a particular line of code to verify variable values, and then continue to step through that code line by line. It can be used when running test suites or when running the application through the bin/main.dart script. In IntelliJ IDEA, right-click on any file with a main function (which includes test suites) and select Debug option. Use breakpoints (by clicking on the gutter area to the left of the text editing area) to stop execution at a particular line before it is executed. Use the Suggested Project Directory Structure See Conduit Project Structure . Pass Services to Controllers in entryPoint Pass service objects to controllers in entryPoint and only pass the services the controller will use. class AppChannel extends ApplicationChannel { GitHub githubService; PostgreSQLConnection databaseConnection; @override Future prepare() async { databaseConnection = new PostgreSQLConnection(); githubService = new GitHub(); } @override Controller get entryPoint { final router = new Router(); router .route(\"/data\") .link(() => new DBController(databaseConnection)); router .route(\"/github\") .link(() => new GitHubController(githubService)); return router; } } Passing references like this allows for injecting dependencies that depend on the environment; e.g. in production, development or during tests. It also avoids tight coupling between the objects in your application. Minimize the access a controller has to its dependencies; e.g. don't pass it a StreamController when it only needs Sink or a Stream . Use a Test Harness A test harness initializes your application in a test suite. It has built in behavior that you can add to for things that are specific to your application. Documentation for using a test harness in your application is located here . Use config.src.yaml Use the convention of config.src.yaml file to prevent configuration errors and inject test dependencies. Understand how Conduit Uses Isolates See more in Application Structure . Use ResourceController Subclasses Subclassing ResourceController provides significant conveniences, safeties and behaviors used by the majority of an application's request handling logic. Prefer to use this class for non-middleware controllers. Keep ApplicationChannel Tidy A ApplicationChannel should handle initialization, routing and nothing more. Consider moving non-initialization behavior into a service object in a separate file. Avoid Raw SQL Queries Prefer to use the Conduit ORM. It sends appropriate HTTP responses for different kinds of errors, validates input data and is ensures the queries match up with your data model. Use API Reference Conduit is an object oriented framework - behaviors are implemented by instances of some type. The types of objects, their properties and their behaviors all follow similar naming conventions to make the API more discoverable. Many types in Conduit have a prefix in common with related types. For example, types like AuthServer , AuthServerDelegate and AuthCode are all related because they deal with authentication and authorization. Methods are named consistently across classes (e.g, asMap is a common method name). When looking for a solution, look at the API reference for the objects you have access to. These objects may already have the behavior you wish to implement or have a reference to an object with that behavior. Use try-catch Sparingly All request handling code is wrapped in a try-catch block that will interpret exceptions and errors and return meaningful HTTP responses. Unknown exceptions will yield a 500 Server Error response. In general, you do not need to use try-catch unless you want a different HTTP response than the one being returned for the exception. Code that throws an exception during initialization should not be caught if the error is fatal to the application launching successfully.","title":"Best Practices"},{"location":"core_concepts/best_practices/#best-practices","text":"","title":"Best Practices"},{"location":"core_concepts/best_practices/#keep-dart-projects-separate","text":"Because Dart is cross-platform, developers should avoid combining client application projects with Conduit projects. Instead, use a single repository with an independent project for each facet of the system. When there are opportunities for code sharing between platforms (typically between Flutter and AngularDart), shared code can live in a dependency project in the same repository. A typical directory structure for an multi-faceted application looks like this: application_name/ conduit/ flutter/ angular/ shared/ {% hint style=\"info\" %} \"Project Definition\" A project is a directory that contain a pubspec.yaml file and lib directory. {% endhint %} It is tempting to share your data model types between your server and client applications, but this falls apart for anything but the most simple of applications. There are enough behavioral differences between the four representations of your data model - in the database, on the server, on the wire (JSON), and on the client - that a single type will have a hard time encompassing. Instead, generate an OpenAPI specification with conduit document and use one of the many open-source tools for generating client data model types.","title":"Keep Dart Projects Separate"},{"location":"core_concepts/best_practices/#split-discrete-components-into-separate-packages","text":"It can often be useful to split discrete code pieces into separate packages with their own sub-repo. Non-trivial Flutter widgets are a good example. Having the code in a separate package facilitate allocating a single owner to the package. Packages with a single owner have much less management overhead and cleaner commit logs. It also stops developers treading on each others toes. Remember a component isn't just a flutter widget. It can be a collection of classes/functions that provide a specific service, this could be something like permission management or formating/parsing monetary amounts. Any collection of code that together delivers a singular 'concern' is a good candidate.","title":"Split discrete components into separate packages"},{"location":"core_concepts/best_practices/#use-test-driven-development-or-something-close-to-it","text":"In Conduit, testing is a first-class citizen. The conduit_test package has classes and methods for initializing and running an application for testing, making requests to that application, and verifying the responses. There is value to using tools like Postman or CURL to test proof of concept code, but the conduit_test package is geared specifically for replacing these tools while retaining automated tests as the project grows. An example test suite looks like this: void main() { final harness = new Harness()..install(); test(\"GET /endpoint returns 200 and a simple object\", () async { final response = await harness.agent.get(\"/endpoint\"); expectResponse(response, 200, body: {\"key\": \"value\"}); }); }","title":"Use Test Driven Development (or something close to it)"},{"location":"core_concepts/best_practices/#use-a-bin-script-to-verify-assumptions","text":"Keep a simple Dart script file in the bin/ directory that imports your project. Use this file as a scratchpad to test exploratory code before committing to a test suite. Don't check this file into source control. import 'package:myapp/myapp.dart'; Future main() async { var whatIsThis = await someYetToBeNamedUsefullyMethod(); print(\"$whatIsThis\"); }","title":"Use a bin Script to Verify Assumptions"},{"location":"core_concepts/best_practices/#create-new-projects-from-a-template","text":"Use conduit create to create applications with the appropriate structure and boilerplate. There are templates for different kinds of applications; view these templates with conduit create list-templates .","title":"Create New Projects from a Template"},{"location":"core_concepts/best_practices/#use-a-debugger","text":"A debugger allows you to stop execution of a running application at a particular line of code to verify variable values, and then continue to step through that code line by line. It can be used when running test suites or when running the application through the bin/main.dart script. In IntelliJ IDEA, right-click on any file with a main function (which includes test suites) and select Debug option. Use breakpoints (by clicking on the gutter area to the left of the text editing area) to stop execution at a particular line before it is executed.","title":"Use a Debugger"},{"location":"core_concepts/best_practices/#use-the-suggested-project-directory-structure","text":"See Conduit Project Structure .","title":"Use the Suggested Project Directory Structure"},{"location":"core_concepts/best_practices/#pass-services-to-controllers-in-entrypoint","text":"Pass service objects to controllers in entryPoint and only pass the services the controller will use. class AppChannel extends ApplicationChannel { GitHub githubService; PostgreSQLConnection databaseConnection; @override Future prepare() async { databaseConnection = new PostgreSQLConnection(); githubService = new GitHub(); } @override Controller get entryPoint { final router = new Router(); router .route(\"/data\") .link(() => new DBController(databaseConnection)); router .route(\"/github\") .link(() => new GitHubController(githubService)); return router; } } Passing references like this allows for injecting dependencies that depend on the environment; e.g. in production, development or during tests. It also avoids tight coupling between the objects in your application. Minimize the access a controller has to its dependencies; e.g. don't pass it a StreamController when it only needs Sink or a Stream .","title":"Pass Services to Controllers in entryPoint"},{"location":"core_concepts/best_practices/#use-a-test-harness","text":"A test harness initializes your application in a test suite. It has built in behavior that you can add to for things that are specific to your application. Documentation for using a test harness in your application is located here .","title":"Use a Test Harness"},{"location":"core_concepts/best_practices/#use-configsrcyaml","text":"Use the convention of config.src.yaml file to prevent configuration errors and inject test dependencies.","title":"Use config.src.yaml"},{"location":"core_concepts/best_practices/#understand-how-conduit-uses-isolates","text":"See more in Application Structure .","title":"Understand how Conduit Uses Isolates"},{"location":"core_concepts/best_practices/#use-resourcecontroller-subclasses","text":"Subclassing ResourceController provides significant conveniences, safeties and behaviors used by the majority of an application's request handling logic. Prefer to use this class for non-middleware controllers.","title":"Use ResourceController Subclasses"},{"location":"core_concepts/best_practices/#keep-applicationchannel-tidy","text":"A ApplicationChannel should handle initialization, routing and nothing more. Consider moving non-initialization behavior into a service object in a separate file.","title":"Keep ApplicationChannel Tidy"},{"location":"core_concepts/best_practices/#avoid-raw-sql-queries","text":"Prefer to use the Conduit ORM. It sends appropriate HTTP responses for different kinds of errors, validates input data and is ensures the queries match up with your data model.","title":"Avoid Raw SQL Queries"},{"location":"core_concepts/best_practices/#use-api-reference","text":"Conduit is an object oriented framework - behaviors are implemented by instances of some type. The types of objects, their properties and their behaviors all follow similar naming conventions to make the API more discoverable. Many types in Conduit have a prefix in common with related types. For example, types like AuthServer , AuthServerDelegate and AuthCode are all related because they deal with authentication and authorization. Methods are named consistently across classes (e.g, asMap is a common method name). When looking for a solution, look at the API reference for the objects you have access to. These objects may already have the behavior you wish to implement or have a reference to an object with that behavior.","title":"Use API Reference"},{"location":"core_concepts/best_practices/#use-try-catch-sparingly","text":"All request handling code is wrapped in a try-catch block that will interpret exceptions and errors and return meaningful HTTP responses. Unknown exceptions will yield a 500 Server Error response. In general, you do not need to use try-catch unless you want a different HTTP response than the one being returned for the exception. Code that throws an exception during initialization should not be caught if the error is fatal to the application launching successfully.","title":"Use try-catch Sparingly"},{"location":"core_concepts/tour/","text":"In-depth The tour demonstrates many of Conduit's features. Command-Line Interface (CLI) The conduit command line tool creates, runs and documents Conduit applications; manages database migrations; and manages OAuth client identifiers. Install by running pub global activate conduit on a machine with Dart installed. Create and run an application: conduit create my_app cd my_app/ conduit serve Initialization A Conduit application starts at an ApplicationChannel . You subclass it once per application to handle initialization tasks like setting up routes and database connections. An example application looks like this: import 'package:conduit/conduit.dart'; class TodoApp extends ApplicationChannel { ManagedContext context; @override Future prepare() async { context = ManagedContext(...); } @override Controller get entryPoint { final router = Router(); router .route(\"/projects/[:id]\") .link(() => ProjectController(context)); return router; } } Routing A router determines which controller object should handle a request. The route specification syntax is a concise syntax to construct routes with variables and optional segments in a single statement. @override Controller get entryPoint { final router = Router(); // Handles /users, /users/1, /users/2, etc. router .route(\"/projects/[:id]\") .link(() => ProjectController()); // Handles any route that starts with /file/ router .route(\"/file/*\") .link(() => FileController()); // Handles the specific route /health router .route(\"/health\") .linkFunction((req) async => Response.ok(null)); return router; } Controllers Controllers handle requests. A controller handles a request by overriding its handle method. This method either returns a response or a request. If a response is returned, that response is sent to the client. If the request is returned, the linked controller handles the request. class SecretKeyAuthorizer extends Controller { @override Future<RequestOrResponse> handle(Request request) async { if (request.raw.headers.value(\"x-secret-key\") == \"secret!\") { return request; } return Response.badRequest(); } } This behavior allows for middleware controllers to be linked together, such that a request goes through a number of steps before it is finally handled. All controllers execute their code in an exception handler. If an exception is thrown in your controller code, a response with an appropriate error code is returned. You subclass HandlerException to provide error response customization for application-specific exceptions. ResourceControllers ResourceControllers are the most often used controller. Each operation - e.g. POST /projects , GET /projects and GET /projects/1 - is mapped to methods in a subclass. Parameters of those methods are annotated to bind the values of the request when the method is invoked. import 'package:conduit/conduit.dart' class ProjectController extends ResourceController { @Operation.get('id') Future<Response> getProjectById(@Bind.path(\"id\") int id) async { // GET /projects/:id return Response.ok(...); } @Operation.post() Future<Response> createProject(@Bind.body() Project project) async { // POST /project final inserted = await insertProject(project); return Response.ok(inserted); } @Operation.get() Future<Response> getAllProjects( @Bind.header(\"x-client-id\") String clientId, {@Bind.query(\"limit\") int limit: 10}) async { // GET /projects return Response.ok(...); } } ManagedObjectControllers ManagedObjectController<T> s are ResourceController s that automatically map a REST interface to database queries; e.g. POST inserts a row, GET gets all row of a type. They do not need to be subclassed, but can be to provide customization. router .route(\"/users/[:id]\") .link(() => ManagedObjectController<Project>(context)); Configuration An application's configuration is written in a YAML file. Each environment your application runs in (e.g., locally, under test, production, development) has different values for things like the port to listen on and database connection credentials. The format of a configuration file is defined by your application. An example looks like: // config.yaml database: host: api.projects.com port: 5432 databaseName: project port: 8000 Subclass Configuration and declare a property for each key in your configuration file: class TodoConfig extends Configuration { TodoConfig(String path) : super.fromFile(File(path)); DatabaseConfiguration database; int port; } The default name of your configuration file is config.yaml , but can be changed at the command-line. You create an instance of your configuration from the configuration file path from your application options: import 'package:conduit/conduit.dart'; class TodoApp extends ApplicationChannel { @override Future prepare() async { var options = TodoConfig(options.configurationFilePath); ... } } Running and Concurrency Conduit applications are run with the conduit serve command line tool. You can attach debugging and instrumentation tools and specify how many threads the application should run on: conduit serve --observe --isolates 5 --port 8888 Conduit applications are multi-isolate (multi-threaded). Each isolate runs a replica of the same web server with its own set of services like database connections. This makes behavior like database connection pooling implicit. PostgreSQL ORM The Query<T> class configures and executes database queries. Its type argument determines what table is to be queried and the type of object you will work with in your code. import 'package:conduit/conduit.dart' class ProjectController extends ResourceController { ProjectController(this.context); final ManagedContext context; @Operation.get() Future<Response> getAllProjects() async { final query = Query<Project>(context); final results = await query.fetch(); return Response.ok(results); } } Configuration of the query - like its WHERE clause - are configured through a fluent, type-safe syntax. A property selector identifies which column of the table to apply an expression to. The following query fetches all project's due in the next week and includes their tasks by joining the related table. final nextWeek = DateTime.now().add(Duration(days: 7)); final query = Query<Project>(context) ..where((project) => project.dueDate).isLessThan(nextWeek) ..join(set: (project) => project.tasks); final projects = await query.fetch(); Rows are inserted or updated by setting the statically-typed values of a query. final insertQuery = Query<Project>(context) ..values.name = \"Build an conduit\" ..values.dueDate = DateTime(year, month); var newProject = await insertQuery.insert(); final updateQuery = Query<Project>(context) ..where((project) => project.id).equalTo(newProject.id) ..values.name = \"Build a miniature conduit\"; newProject = await updateQuery.updateOne(); Query<T> s can perform sorting, joining and paging queries. final overdueQuery = Query<Project>(context) ..where((project) => project.dueDate).lessThan(DateTime().now()) ..sortBy((project) => project.dueDate, QuerySortOrder.ascending) ..join(object: (project) => project.owner); final overdueProjectsAndTheirOwners = await query.fetch(); Controllers will interpret exceptions thrown by queries to return an appropriate error response to the client. For example, unique constraint conflicts return 409, missing required properties return 400 and database connection failure returns 503. Defining a Data Model To use the ORM, you declare your tables as Dart types and create a subclass of ManagedObject<T> . A subclass maps to a table in the database, each instance maps to a row, and each property is a column. The following declaration will map to a table named _project with columns id , name and dueDate . class Project extends ManagedObject<_Project> implements _Project { bool get isPastDue => dueDate.difference(DateTime.now()).inSeconds < 0; } class _Project { @primaryKey int id; @Column(indexed: true) String name; DateTime dueDate; } Managed objects have relationships to other managed objects. Relationships can be has-one, has-many and many-to-many. A relationship is always two-sided - the related types must declare a property that references each other. class Project extends ManagedObject<_Project> implements _Project {} class _Project { ... // Project has-many Tasks ManagedSet<Task> tasks; } class Task extends ManagedObject<_Task> implements _Task {} class _Task { ... // Task belongs to a project, maps to 'project_id' foreign key column @Relate(#tasks) Project project; } ManagedObject<T> s are serializable and can be directly read from a request body, or encoded as a response body. class ProjectController extends ResourceController { @Operation.put('id') Future<Response> updateProject(@Bind.path('id') int projectId, @Bind.body() Project project) async { final query = Query<Project>(context) ..where((project) => project.id).equalTo(projectId) ..values = project; return Response.ok(await query.updateOne()); } } Database Migrations The CLI will automatically generate database migration scripts by detecting changes to your managed objects. The following, when ran in a project directory, will generate and execute a database migration. conduit db generate conduit db upgrade --connect postgres://user:password@host:5432/database You can edit migration files by hand to alter any assumptions or enter required values, and run conduit db validate to ensure the changes still yield the same schema. Be sure to keep generated files in version control. OAuth 2.0 An OAuth 2.0 server implementation handles authentication and authorization for Conduit applications. You create an AuthServer and its delegate as services in your application. The delegate is configurable and manages how tokens are generated and stored. By default, access tokens are a random 32-byte string and client identifiers, tokens and access codes are stored in your database using the ORM. import 'package:conduit/conduit.dart'; import 'package:conduit/managed_auth.dart'; class AppApplicationChannel extends ApplicationChannel { AuthServer authServer; ManagedContext context; @override Future prepare() async { context = ManagedContext(...); final delegate = ManagedAuthDelegate<User>(context); authServer = AuthServer(delegate); } } Built-in authentication controllers for exchanging user credentials for access tokens are named AuthController and AuthCodeController . Authorizer s are middleware that require a valid access token to access their linked controller. Controller get entryPoint { final router = Router(); // POST /auth/token with username and password (or access code) to get access token router .route(\"/auth/token\") .link(() => AuthController(authServer)); // GET /auth/code returns login form, POST /auth/code grants access code router .route(\"/auth/code\") .link(() => AuthCodeController(authServer)); // ProjectController requires request to include access token router .route(\"/projects/[:id]\") .link(() => Authorizer.bearer(authServer)) .link(() => ProjectController(context)); return router; } The CLI has tools to manage OAuth 2.0 client identifiers and access scopes. conduit auth add-client \\ --id com.app.mobile \\ --secret foobar \\ --redirect-uri https://somewhereoutthere.com \\ --allowed-scopes \"users projects admin.readonly\" Logging All requests are logged to an application-wide logger. Set up a listener for the logger in ApplicationChannel to write log messages to the console or another medium. class WildfireChannel extends ApplicationChannel { @override Future prepare() async { logger.onRecord.listen((record) { print(\"$record\"); }); } } Testing Conduit tests start a local version of your application and execute requests. You write expectations on the responses. A TestHarness manages the starting and stopping of an application, and exposes a default Agent for executing requests. An Agent can be configured to have default headers, and multiple agents can be used within the same test. import 'harness/app.dart'; void main() { final harness = TestHarness<TodoApp>()..install(); test(\"GET /projects returns all projects\" , () async { var response = await harness.agent.get(\"/projects\"); expectResponse(response, 200, body: every(partial({ \"id\": greaterThan(0), \"name\": isNotNull, \"dueDate\": isNotNull }))); }); } Testing with a Database Conduit's ORM uses PostgreSQL as its database. Before your tests run, Conduit will create your application's database tables in a local PostgreSQL database. After the tests complete, it will delete those tables. This allows you to start with an empty database for each test suite as well as control exactly which records are in your database while testing, but without having to manage database schemas or use an mock implementation (e.g., SQLite). This behavior, and behavior for managing applications with an OAuth 2.0 provider, are available as harness mixins . Documentation OpenAPI documents describe your application's interface. These documents can be used to generate documentation and client code. A document can be generated by reflecting on your application's codebase, just run the conduit document command. The conduit document client command creates a web page that can be used to configure issue requests specific to your application.","title":"In-depth"},{"location":"core_concepts/tour/#in-depth","text":"The tour demonstrates many of Conduit's features.","title":"In-depth"},{"location":"core_concepts/tour/#command-line-interface-cli","text":"The conduit command line tool creates, runs and documents Conduit applications; manages database migrations; and manages OAuth client identifiers. Install by running pub global activate conduit on a machine with Dart installed. Create and run an application: conduit create my_app cd my_app/ conduit serve","title":"Command-Line Interface (CLI)"},{"location":"core_concepts/tour/#initialization","text":"A Conduit application starts at an ApplicationChannel . You subclass it once per application to handle initialization tasks like setting up routes and database connections. An example application looks like this: import 'package:conduit/conduit.dart'; class TodoApp extends ApplicationChannel { ManagedContext context; @override Future prepare() async { context = ManagedContext(...); } @override Controller get entryPoint { final router = Router(); router .route(\"/projects/[:id]\") .link(() => ProjectController(context)); return router; } }","title":"Initialization"},{"location":"core_concepts/tour/#routing","text":"A router determines which controller object should handle a request. The route specification syntax is a concise syntax to construct routes with variables and optional segments in a single statement. @override Controller get entryPoint { final router = Router(); // Handles /users, /users/1, /users/2, etc. router .route(\"/projects/[:id]\") .link(() => ProjectController()); // Handles any route that starts with /file/ router .route(\"/file/*\") .link(() => FileController()); // Handles the specific route /health router .route(\"/health\") .linkFunction((req) async => Response.ok(null)); return router; }","title":"Routing"},{"location":"core_concepts/tour/#controllers","text":"Controllers handle requests. A controller handles a request by overriding its handle method. This method either returns a response or a request. If a response is returned, that response is sent to the client. If the request is returned, the linked controller handles the request. class SecretKeyAuthorizer extends Controller { @override Future<RequestOrResponse> handle(Request request) async { if (request.raw.headers.value(\"x-secret-key\") == \"secret!\") { return request; } return Response.badRequest(); } } This behavior allows for middleware controllers to be linked together, such that a request goes through a number of steps before it is finally handled. All controllers execute their code in an exception handler. If an exception is thrown in your controller code, a response with an appropriate error code is returned. You subclass HandlerException to provide error response customization for application-specific exceptions.","title":"Controllers"},{"location":"core_concepts/tour/#resourcecontrollers","text":"ResourceControllers are the most often used controller. Each operation - e.g. POST /projects , GET /projects and GET /projects/1 - is mapped to methods in a subclass. Parameters of those methods are annotated to bind the values of the request when the method is invoked. import 'package:conduit/conduit.dart' class ProjectController extends ResourceController { @Operation.get('id') Future<Response> getProjectById(@Bind.path(\"id\") int id) async { // GET /projects/:id return Response.ok(...); } @Operation.post() Future<Response> createProject(@Bind.body() Project project) async { // POST /project final inserted = await insertProject(project); return Response.ok(inserted); } @Operation.get() Future<Response> getAllProjects( @Bind.header(\"x-client-id\") String clientId, {@Bind.query(\"limit\") int limit: 10}) async { // GET /projects return Response.ok(...); } }","title":"ResourceControllers"},{"location":"core_concepts/tour/#managedobjectcontrollers","text":"ManagedObjectController<T> s are ResourceController s that automatically map a REST interface to database queries; e.g. POST inserts a row, GET gets all row of a type. They do not need to be subclassed, but can be to provide customization. router .route(\"/users/[:id]\") .link(() => ManagedObjectController<Project>(context));","title":"ManagedObjectControllers"},{"location":"core_concepts/tour/#configuration","text":"An application's configuration is written in a YAML file. Each environment your application runs in (e.g., locally, under test, production, development) has different values for things like the port to listen on and database connection credentials. The format of a configuration file is defined by your application. An example looks like: // config.yaml database: host: api.projects.com port: 5432 databaseName: project port: 8000 Subclass Configuration and declare a property for each key in your configuration file: class TodoConfig extends Configuration { TodoConfig(String path) : super.fromFile(File(path)); DatabaseConfiguration database; int port; } The default name of your configuration file is config.yaml , but can be changed at the command-line. You create an instance of your configuration from the configuration file path from your application options: import 'package:conduit/conduit.dart'; class TodoApp extends ApplicationChannel { @override Future prepare() async { var options = TodoConfig(options.configurationFilePath); ... } }","title":"Configuration"},{"location":"core_concepts/tour/#running-and-concurrency","text":"Conduit applications are run with the conduit serve command line tool. You can attach debugging and instrumentation tools and specify how many threads the application should run on: conduit serve --observe --isolates 5 --port 8888 Conduit applications are multi-isolate (multi-threaded). Each isolate runs a replica of the same web server with its own set of services like database connections. This makes behavior like database connection pooling implicit.","title":"Running and Concurrency"},{"location":"core_concepts/tour/#postgresql-orm","text":"The Query<T> class configures and executes database queries. Its type argument determines what table is to be queried and the type of object you will work with in your code. import 'package:conduit/conduit.dart' class ProjectController extends ResourceController { ProjectController(this.context); final ManagedContext context; @Operation.get() Future<Response> getAllProjects() async { final query = Query<Project>(context); final results = await query.fetch(); return Response.ok(results); } } Configuration of the query - like its WHERE clause - are configured through a fluent, type-safe syntax. A property selector identifies which column of the table to apply an expression to. The following query fetches all project's due in the next week and includes their tasks by joining the related table. final nextWeek = DateTime.now().add(Duration(days: 7)); final query = Query<Project>(context) ..where((project) => project.dueDate).isLessThan(nextWeek) ..join(set: (project) => project.tasks); final projects = await query.fetch(); Rows are inserted or updated by setting the statically-typed values of a query. final insertQuery = Query<Project>(context) ..values.name = \"Build an conduit\" ..values.dueDate = DateTime(year, month); var newProject = await insertQuery.insert(); final updateQuery = Query<Project>(context) ..where((project) => project.id).equalTo(newProject.id) ..values.name = \"Build a miniature conduit\"; newProject = await updateQuery.updateOne(); Query<T> s can perform sorting, joining and paging queries. final overdueQuery = Query<Project>(context) ..where((project) => project.dueDate).lessThan(DateTime().now()) ..sortBy((project) => project.dueDate, QuerySortOrder.ascending) ..join(object: (project) => project.owner); final overdueProjectsAndTheirOwners = await query.fetch(); Controllers will interpret exceptions thrown by queries to return an appropriate error response to the client. For example, unique constraint conflicts return 409, missing required properties return 400 and database connection failure returns 503.","title":"PostgreSQL ORM"},{"location":"core_concepts/tour/#defining-a-data-model","text":"To use the ORM, you declare your tables as Dart types and create a subclass of ManagedObject<T> . A subclass maps to a table in the database, each instance maps to a row, and each property is a column. The following declaration will map to a table named _project with columns id , name and dueDate . class Project extends ManagedObject<_Project> implements _Project { bool get isPastDue => dueDate.difference(DateTime.now()).inSeconds < 0; } class _Project { @primaryKey int id; @Column(indexed: true) String name; DateTime dueDate; } Managed objects have relationships to other managed objects. Relationships can be has-one, has-many and many-to-many. A relationship is always two-sided - the related types must declare a property that references each other. class Project extends ManagedObject<_Project> implements _Project {} class _Project { ... // Project has-many Tasks ManagedSet<Task> tasks; } class Task extends ManagedObject<_Task> implements _Task {} class _Task { ... // Task belongs to a project, maps to 'project_id' foreign key column @Relate(#tasks) Project project; } ManagedObject<T> s are serializable and can be directly read from a request body, or encoded as a response body. class ProjectController extends ResourceController { @Operation.put('id') Future<Response> updateProject(@Bind.path('id') int projectId, @Bind.body() Project project) async { final query = Query<Project>(context) ..where((project) => project.id).equalTo(projectId) ..values = project; return Response.ok(await query.updateOne()); } }","title":"Defining a Data Model"},{"location":"core_concepts/tour/#database-migrations","text":"The CLI will automatically generate database migration scripts by detecting changes to your managed objects. The following, when ran in a project directory, will generate and execute a database migration. conduit db generate conduit db upgrade --connect postgres://user:password@host:5432/database You can edit migration files by hand to alter any assumptions or enter required values, and run conduit db validate to ensure the changes still yield the same schema. Be sure to keep generated files in version control.","title":"Database Migrations"},{"location":"core_concepts/tour/#oauth-20","text":"An OAuth 2.0 server implementation handles authentication and authorization for Conduit applications. You create an AuthServer and its delegate as services in your application. The delegate is configurable and manages how tokens are generated and stored. By default, access tokens are a random 32-byte string and client identifiers, tokens and access codes are stored in your database using the ORM. import 'package:conduit/conduit.dart'; import 'package:conduit/managed_auth.dart'; class AppApplicationChannel extends ApplicationChannel { AuthServer authServer; ManagedContext context; @override Future prepare() async { context = ManagedContext(...); final delegate = ManagedAuthDelegate<User>(context); authServer = AuthServer(delegate); } } Built-in authentication controllers for exchanging user credentials for access tokens are named AuthController and AuthCodeController . Authorizer s are middleware that require a valid access token to access their linked controller. Controller get entryPoint { final router = Router(); // POST /auth/token with username and password (or access code) to get access token router .route(\"/auth/token\") .link(() => AuthController(authServer)); // GET /auth/code returns login form, POST /auth/code grants access code router .route(\"/auth/code\") .link(() => AuthCodeController(authServer)); // ProjectController requires request to include access token router .route(\"/projects/[:id]\") .link(() => Authorizer.bearer(authServer)) .link(() => ProjectController(context)); return router; } The CLI has tools to manage OAuth 2.0 client identifiers and access scopes. conduit auth add-client \\ --id com.app.mobile \\ --secret foobar \\ --redirect-uri https://somewhereoutthere.com \\ --allowed-scopes \"users projects admin.readonly\"","title":"OAuth 2.0"},{"location":"core_concepts/tour/#logging","text":"All requests are logged to an application-wide logger. Set up a listener for the logger in ApplicationChannel to write log messages to the console or another medium. class WildfireChannel extends ApplicationChannel { @override Future prepare() async { logger.onRecord.listen((record) { print(\"$record\"); }); } }","title":"Logging"},{"location":"core_concepts/tour/#testing","text":"Conduit tests start a local version of your application and execute requests. You write expectations on the responses. A TestHarness manages the starting and stopping of an application, and exposes a default Agent for executing requests. An Agent can be configured to have default headers, and multiple agents can be used within the same test. import 'harness/app.dart'; void main() { final harness = TestHarness<TodoApp>()..install(); test(\"GET /projects returns all projects\" , () async { var response = await harness.agent.get(\"/projects\"); expectResponse(response, 200, body: every(partial({ \"id\": greaterThan(0), \"name\": isNotNull, \"dueDate\": isNotNull }))); }); }","title":"Testing"},{"location":"core_concepts/tour/#testing-with-a-database","text":"Conduit's ORM uses PostgreSQL as its database. Before your tests run, Conduit will create your application's database tables in a local PostgreSQL database. After the tests complete, it will delete those tables. This allows you to start with an empty database for each test suite as well as control exactly which records are in your database while testing, but without having to manage database schemas or use an mock implementation (e.g., SQLite). This behavior, and behavior for managing applications with an OAuth 2.0 provider, are available as harness mixins .","title":"Testing with a Database"},{"location":"core_concepts/tour/#documentation","text":"OpenAPI documents describe your application's interface. These documents can be used to generate documentation and client code. A document can be generated by reflecting on your application's codebase, just run the conduit document command. The conduit document client command creates a web page that can be used to configure issue requests specific to your application.","title":"Documentation"},{"location":"db/","text":"Database access Conduit's ORM stores data in database tables and maps table rows to Dart objects. You declare subclasses of ManagedObject<T> in your application code to define the database tables your application uses. The properties of these types have annotations like Column and Validate to customize the behavior of tables in your database. Your application creates a ManagedContext service object during initialization that manages database access for your application. This service is injected into controllers that make database queries. Instances of Query<T> are created to insert, update, read and delete data from a database. A Query<T> has many configurable options for filtering, joining, paging, sorting and performing aggregate functions on database rows. The conduit db command-line tool manages databases that your application connects. This tool creates and executes migration scripts that update the schema of a database to match the requirements of your application. The minimum version of PostgreSQL needed to work with Conduit is 9.6. Guides Connecting to a Database Modeling Data Storage, Serialization and Deserialization Executing Queries Joins, Filtering and Paging Executing Queries in a Transaction Adding Validations and Callbacks to ManagedObject Conduit Database Tool JSON Document Columns and Operations","title":"Database access"},{"location":"db/#database-access","text":"Conduit's ORM stores data in database tables and maps table rows to Dart objects. You declare subclasses of ManagedObject<T> in your application code to define the database tables your application uses. The properties of these types have annotations like Column and Validate to customize the behavior of tables in your database. Your application creates a ManagedContext service object during initialization that manages database access for your application. This service is injected into controllers that make database queries. Instances of Query<T> are created to insert, update, read and delete data from a database. A Query<T> has many configurable options for filtering, joining, paging, sorting and performing aggregate functions on database rows. The conduit db command-line tool manages databases that your application connects. This tool creates and executes migration scripts that update the schema of a database to match the requirements of your application. The minimum version of PostgreSQL needed to work with Conduit is 9.6.","title":"Database access"},{"location":"db/#guides","text":"Connecting to a Database Modeling Data Storage, Serialization and Deserialization Executing Queries Joins, Filtering and Paging Executing Queries in a Transaction Adding Validations and Callbacks to ManagedObject Conduit Database Tool JSON Document Columns and Operations","title":"Guides"},{"location":"db/advanced_queries/","text":"Advanced Queries: Filtering, Joins, Paging and Reduce Paging Fetched Result Sets The rows from a table can be sorted and fetched in contiguous chunks. This sorting can occur on most properties. For example, in a social media application, a user could have thousands of pieces of content they had created over many years. The likely use case for fetching their content would be to grab only the most recent content, and only grab earlier content as necessary. Conduit has two mechanisms in Query<T> for building queries that can fetch a subset of rows within a certain range. Naive paging can be accomplished using the fetchLimit and offset properties of a Query<T> . For example, if a table contains 100 rows, and you would like to grab 10 at a time, each query would have a value of 10 for its fetchLimit . The first query would have an offset of 0, then 10, then 20, and so on. Especially when using sortBy , this type of paging can be effective. One of the drawbacks to this type of paging is that it can skip or duplicate rows if rows are being added or deleted between fetches. For example, consider the seven objects above that are ordered by time. If we page by two objects at a time ( fetchLimit=2 ) starting at the first item ( offset=0 ), our first result set is the first two objects. The next page is the original offset plus the same limit - we grab the next two rows. But before the next page is fetched, a new object is inserted and its at an index that we already fetched. The next page would return 3:00pm again. A similar problem occurs if a row is deleted when paging in this way. It is really annoying for client applications to have to check for and merge duplicates. Another paging technique that doesn't suffer from this problem relies on the client sending a value from the last object in the previous page, instead of an offset. So in the above example, instead of asking for offset 2 in the second query, it'd send the value 1:30pm . The query filters out rows with a value less than the one it was sent, orders the remaining rows and then fetches the newest from the top. Query.pageBy uses this technique. Its usage is similar to sortBy : var firstQuery = Query<Post>(context) ..pageBy((p) => p.dateCreated, QuerySortOrder.descending) ..fetchLimit = 10; var firstQueryResults = await firstQuery.fetch(); var oldestPostWeGot = firstQueryResults.last.dateCreated; var nextQuery = Query<Post>(context) ..pageBy((p) => p.dateCreated, QuerySortOrder.descending, boundingValue: oldestPostWeGot) ..fetchLimit = 10; This query would fetch the newest 10 posts. Then, it fetches the next 10 after skipping past all of the ones newer than the oldest post it got in the first result set. When paging, the query must have a fetchLimit - otherwise you're just sorting and returning every row. You identify which property to page on by using a property selector. The second argument to pageBy defines the order the rows will be sorted in. When you first start paging, you don't have any results yet, so you can't specify a value from the last result set. In this case, the boundingValue of pageBy is null - meaning start from the beginning. Once the first set has been fetched, the boundingValue is the value of the paging property in the last object returned. This is often accomplished by adding a query parameter to an endpoint that takes in a bounding value. (See ManagedObjectController<T> as an example.) A pageBy query will return an empty list of objects when no more values are left. If the number of objects remaining in the last page are less than the fetchLimit , only those objects will be returned. For example, if there four more objects left and the fetchLimit is 10, the number of objects returned will be four. You should index properties that will be paged by: @Column(indexed: true) int pageableProperty; Filtering Results of a Fetch Operation Fetching every row of a table usually doesn't make sense. Instead, we want a specific object or a set of objects matching some criteria. A Query 's where method is a safe and elegant way to add this criteria to a query. This method allows you to assign boolean expressions to the properties of the object being queried. Each expression is added to the WHERE clause of the generated SQL query. Here's an example of a query that finds a User with an id equal to 1: var query = Query<User>(context) ..where((u) => u.id).equalTo(1); (The generated SQL here would be SELECT _user.id, _user.name, ... FROM _user WHERE _user.id = 1 .) There are many expression methods like equalTo - see the documentation for QueryExpression<T> for a complete list. You may add multiple criteria to a query by invoking where multiple times. Each criteria is combined together with a logical 'and'. For example, the following query will find all users whose name is \"Bob\" and email is not null: final query = Query<User>(context) ..where((u) => u.name).equalTo(\"Bob\") ..where((u) => u.email).isNotNull(); You may apply criteria to relationship properties, too. For nullable relationships, you can apply null/not null checks: var employedQuery = Query<Person>(context) ..where((p) => p.company).isNotNull(); More often, you use the identifiedBy expression for finding objects that belong to a specific object. For example, when finding all employees for a given company: var preferredQuery = Query<Employee>(context) ..where((e) => e.company).identifiedBy(23); The above will only return employees who work for company with a primary key value of 23. It is equivalent to the following, and both are acceptable: var sameQuery = Query<Employee>(context) ..where((e) => e.company.id).equalTo(23); Notice in the above that you may select properties of relationships when building a query. Since an employee 'belongs-to' a company, the employee table has a column to store the primary key of a company. This is called a foreign key column. When building a query that selects the primary key of a belongs-to relationship, Conduit can interpret this to use the foreign key column value. For selecting properties that are not backed by a foreign key column in the table being queried, see the next section on Joins. Including Relationships in a Fetch (aka, Joins) A Query<T> can also fetch relationship properties. This allows queries to fetch entire model graphs and reduces the number of round-trips to a database. By default, relationship properties are not fetched in a query and therefore aren't included in an object's asMap() . For example, consider the following definitions, where a User has-many Task s: class User extends ManagedObject<_User> implements _User {} class _User { @primaryKey int id; String name; ManagedSet<Task> tasks; } class Task extends ManagedObject<_Task> implements _Task {} class _Task { @primaryKey int id; @Relate(#tasks) User user; String contents; } A Query<User> will fetch the name and id of each User . A User 's tasks are not fetched, so the data returned looks like this: var q = Query<User>(context); var users = await q.fetch(); users.first.asMap() == { \"id\": 1, \"name\": \"Bob\" }; // yup The join() method will tell a query to also include related objects. The following shows a fetch that gets users and their tasks: var q = Query<User>(context) ..join(set: (u) => u.tasks); var users = await q.fetch(); users.first.asMap() == { \"id\": 1, \"name\": \"Bob\", \"tasks\": [ {\"id\": 1, \"contents\": \"Take out trash\", \"user\" : {\"id\": 1}}, ... ] }; // yup When joining a has-many relationship, the set: argument takes a property selector that must select a ManagedSet . (When fetching a has-one or belongs-to relationship, use the object: argument.) The method join() returns a new Query<T> , where T is the type of the joined object. That is, the above code could also be written as such: var q = Query<User>(context); // type annotation added for clarity Query<Task> taskSubQuery = q.join(set: (u) => u.tasks); Configuring Join Queries You do not execute a query created by a join, but you do configure it like any other query. (The parent query keeps track of the joined query and you execute the parent query.) For example, you may modify the properties that are returned for the joined objects: var q = Query<User>(context); q.join(set: (u) => u.tasks) ..returningProperties((t) => [t.id, t.contents]); final usersAndTasks = await q.fetch(); You may also apply filtering criteria to a join query. Consider a Parent that has-many Children . When fetching parents and joining their children, a where expression on the join query impacts which children are returned, but does not impact which parents are returned. For example, the following query would fetch every parent, but would only include children who are greater than 1 years old: final q = Query<Parent>(context); q.join(set: (p) => p.children) ..where((c) => c.age).greaterThan(1); final parentsAndTheirChildren = await q.fetch(); Filtering Objects by Their Relationships However, consider if we applied a similar expression to the parent query - it would only return parents who have children that are greater than 1 years old . final q = Query<Parent>(context) ..where((c) => c.children.haveAtLeastOneWhere.age).greaterThan(1); ..join(set: (p) => p.children); final parentsWithOlderChildren = await q.fetch(); The difference is where the expression is applied. When applying it to the child query, it removes child objects that don't meet the criteria. When applying it to the parent query, it removes parents that don't meet the criteria. The property haveAtLeastOneWhere is specific to has-many relationships. When selecting properties of a has-one or belongs-to relationship, you access the property directly: final q = Query<Child>(context) ..where((p) => p.parent.age).greaterThan(30) ..join(object: (p) => e.parent); final childrenWithParentsOver30 = await q.fetch(); Note that you may use relationship properties without explicitly joining the property. A SQL JOIN is still performed, but the related object is not included in the result set. final q = Query<Child>(context) ..where((p) => p.parent.age).greaterThan(30); final employeesWithManagersOver30YearsOld = await q.fetch(); Multiple Joins More than one join can be applied to a query, and subqueries can be nested. So, this is all valid, assuming the relationship properties exist: var q = Query<User>(context) ..join(object: (u) => u.address); q.join(set: (u) => u.tasks) ..join(object: (u) => u.location); This would fetch all users, their addresses, all of their tasks, and the location for each of their tasks. You'd get a nice sized tree of objects here. Reduce Functions (aka, Aggregate Functions) Queries can also be used to perform functions like count , sum , average , min and max . Here's an example: var query = Query<User>(context); var numberOfUsers = await query.reduce.count(); For reduce functions that use the value of some property, a property selector is used to identify that property. var averageSalary = await query.reduce.sum((u) => u.salary); Any values configured in a Query<T> also impact the reduce function. For example, applying a Query.where and then executing a sum function will only sum the rows that meet the criteria of the where clause: var query = Query<User>(context) ..where((u) => u.name.equalTo(\"Bob\"); var averageSalaryOfPeopleNamedBob = await query.reduce.sum((u) => u.salary); Fallbacks You may always execute arbitrary SQL with PersistentStore.execute . Note that the objects returned will be a List<List<dynamic>> - a list of rows, for each a list of columns. You may also provide raw WHERE clauses with Query.predicate . A QueryPredicate is a String that is set as the query's where clause. A QueryPredicate has two properties, a format string and a Map<String, dynamic> of parameter values. The format string can (and should) parameterize any input values. Parameters are indicated in the format string using the @ token: // Creates a predicate that would only include instances where some column \"id\" is less than 2 var predicate = QueryPredicate(\"id < @idVariable\", {\"idVariable\" : 2}); The text following the @ token may contain [A-Za-z0-9_] . The resulting where clause will be formed by replacing each token with the matching key in the parameters map. The value is not transformed in any way, so it must be the appropriate type for the column. If a key is not present in the Map , an exception will be thrown. Extra keys will be ignored.","title":"Advanced Queries"},{"location":"db/advanced_queries/#advanced-queries-filtering-joins-paging-and-reduce","text":"","title":"Advanced Queries: Filtering, Joins, Paging and Reduce"},{"location":"db/advanced_queries/#paging-fetched-result-sets","text":"The rows from a table can be sorted and fetched in contiguous chunks. This sorting can occur on most properties. For example, in a social media application, a user could have thousands of pieces of content they had created over many years. The likely use case for fetching their content would be to grab only the most recent content, and only grab earlier content as necessary. Conduit has two mechanisms in Query<T> for building queries that can fetch a subset of rows within a certain range. Naive paging can be accomplished using the fetchLimit and offset properties of a Query<T> . For example, if a table contains 100 rows, and you would like to grab 10 at a time, each query would have a value of 10 for its fetchLimit . The first query would have an offset of 0, then 10, then 20, and so on. Especially when using sortBy , this type of paging can be effective. One of the drawbacks to this type of paging is that it can skip or duplicate rows if rows are being added or deleted between fetches. For example, consider the seven objects above that are ordered by time. If we page by two objects at a time ( fetchLimit=2 ) starting at the first item ( offset=0 ), our first result set is the first two objects. The next page is the original offset plus the same limit - we grab the next two rows. But before the next page is fetched, a new object is inserted and its at an index that we already fetched. The next page would return 3:00pm again. A similar problem occurs if a row is deleted when paging in this way. It is really annoying for client applications to have to check for and merge duplicates. Another paging technique that doesn't suffer from this problem relies on the client sending a value from the last object in the previous page, instead of an offset. So in the above example, instead of asking for offset 2 in the second query, it'd send the value 1:30pm . The query filters out rows with a value less than the one it was sent, orders the remaining rows and then fetches the newest from the top. Query.pageBy uses this technique. Its usage is similar to sortBy : var firstQuery = Query<Post>(context) ..pageBy((p) => p.dateCreated, QuerySortOrder.descending) ..fetchLimit = 10; var firstQueryResults = await firstQuery.fetch(); var oldestPostWeGot = firstQueryResults.last.dateCreated; var nextQuery = Query<Post>(context) ..pageBy((p) => p.dateCreated, QuerySortOrder.descending, boundingValue: oldestPostWeGot) ..fetchLimit = 10; This query would fetch the newest 10 posts. Then, it fetches the next 10 after skipping past all of the ones newer than the oldest post it got in the first result set. When paging, the query must have a fetchLimit - otherwise you're just sorting and returning every row. You identify which property to page on by using a property selector. The second argument to pageBy defines the order the rows will be sorted in. When you first start paging, you don't have any results yet, so you can't specify a value from the last result set. In this case, the boundingValue of pageBy is null - meaning start from the beginning. Once the first set has been fetched, the boundingValue is the value of the paging property in the last object returned. This is often accomplished by adding a query parameter to an endpoint that takes in a bounding value. (See ManagedObjectController<T> as an example.) A pageBy query will return an empty list of objects when no more values are left. If the number of objects remaining in the last page are less than the fetchLimit , only those objects will be returned. For example, if there four more objects left and the fetchLimit is 10, the number of objects returned will be four. You should index properties that will be paged by: @Column(indexed: true) int pageableProperty;","title":"Paging Fetched Result Sets"},{"location":"db/advanced_queries/#filtering-results-of-a-fetch-operation","text":"Fetching every row of a table usually doesn't make sense. Instead, we want a specific object or a set of objects matching some criteria. A Query 's where method is a safe and elegant way to add this criteria to a query. This method allows you to assign boolean expressions to the properties of the object being queried. Each expression is added to the WHERE clause of the generated SQL query. Here's an example of a query that finds a User with an id equal to 1: var query = Query<User>(context) ..where((u) => u.id).equalTo(1); (The generated SQL here would be SELECT _user.id, _user.name, ... FROM _user WHERE _user.id = 1 .) There are many expression methods like equalTo - see the documentation for QueryExpression<T> for a complete list. You may add multiple criteria to a query by invoking where multiple times. Each criteria is combined together with a logical 'and'. For example, the following query will find all users whose name is \"Bob\" and email is not null: final query = Query<User>(context) ..where((u) => u.name).equalTo(\"Bob\") ..where((u) => u.email).isNotNull(); You may apply criteria to relationship properties, too. For nullable relationships, you can apply null/not null checks: var employedQuery = Query<Person>(context) ..where((p) => p.company).isNotNull(); More often, you use the identifiedBy expression for finding objects that belong to a specific object. For example, when finding all employees for a given company: var preferredQuery = Query<Employee>(context) ..where((e) => e.company).identifiedBy(23); The above will only return employees who work for company with a primary key value of 23. It is equivalent to the following, and both are acceptable: var sameQuery = Query<Employee>(context) ..where((e) => e.company.id).equalTo(23); Notice in the above that you may select properties of relationships when building a query. Since an employee 'belongs-to' a company, the employee table has a column to store the primary key of a company. This is called a foreign key column. When building a query that selects the primary key of a belongs-to relationship, Conduit can interpret this to use the foreign key column value. For selecting properties that are not backed by a foreign key column in the table being queried, see the next section on Joins.","title":"Filtering Results of a Fetch Operation"},{"location":"db/advanced_queries/#including-relationships-in-a-fetch-aka-joins","text":"A Query<T> can also fetch relationship properties. This allows queries to fetch entire model graphs and reduces the number of round-trips to a database. By default, relationship properties are not fetched in a query and therefore aren't included in an object's asMap() . For example, consider the following definitions, where a User has-many Task s: class User extends ManagedObject<_User> implements _User {} class _User { @primaryKey int id; String name; ManagedSet<Task> tasks; } class Task extends ManagedObject<_Task> implements _Task {} class _Task { @primaryKey int id; @Relate(#tasks) User user; String contents; } A Query<User> will fetch the name and id of each User . A User 's tasks are not fetched, so the data returned looks like this: var q = Query<User>(context); var users = await q.fetch(); users.first.asMap() == { \"id\": 1, \"name\": \"Bob\" }; // yup The join() method will tell a query to also include related objects. The following shows a fetch that gets users and their tasks: var q = Query<User>(context) ..join(set: (u) => u.tasks); var users = await q.fetch(); users.first.asMap() == { \"id\": 1, \"name\": \"Bob\", \"tasks\": [ {\"id\": 1, \"contents\": \"Take out trash\", \"user\" : {\"id\": 1}}, ... ] }; // yup When joining a has-many relationship, the set: argument takes a property selector that must select a ManagedSet . (When fetching a has-one or belongs-to relationship, use the object: argument.) The method join() returns a new Query<T> , where T is the type of the joined object. That is, the above code could also be written as such: var q = Query<User>(context); // type annotation added for clarity Query<Task> taskSubQuery = q.join(set: (u) => u.tasks);","title":"Including Relationships in a Fetch (aka, Joins)"},{"location":"db/advanced_queries/#configuring-join-queries","text":"You do not execute a query created by a join, but you do configure it like any other query. (The parent query keeps track of the joined query and you execute the parent query.) For example, you may modify the properties that are returned for the joined objects: var q = Query<User>(context); q.join(set: (u) => u.tasks) ..returningProperties((t) => [t.id, t.contents]); final usersAndTasks = await q.fetch(); You may also apply filtering criteria to a join query. Consider a Parent that has-many Children . When fetching parents and joining their children, a where expression on the join query impacts which children are returned, but does not impact which parents are returned. For example, the following query would fetch every parent, but would only include children who are greater than 1 years old: final q = Query<Parent>(context); q.join(set: (p) => p.children) ..where((c) => c.age).greaterThan(1); final parentsAndTheirChildren = await q.fetch();","title":"Configuring Join Queries"},{"location":"db/advanced_queries/#filtering-objects-by-their-relationships","text":"However, consider if we applied a similar expression to the parent query - it would only return parents who have children that are greater than 1 years old . final q = Query<Parent>(context) ..where((c) => c.children.haveAtLeastOneWhere.age).greaterThan(1); ..join(set: (p) => p.children); final parentsWithOlderChildren = await q.fetch(); The difference is where the expression is applied. When applying it to the child query, it removes child objects that don't meet the criteria. When applying it to the parent query, it removes parents that don't meet the criteria. The property haveAtLeastOneWhere is specific to has-many relationships. When selecting properties of a has-one or belongs-to relationship, you access the property directly: final q = Query<Child>(context) ..where((p) => p.parent.age).greaterThan(30) ..join(object: (p) => e.parent); final childrenWithParentsOver30 = await q.fetch(); Note that you may use relationship properties without explicitly joining the property. A SQL JOIN is still performed, but the related object is not included in the result set. final q = Query<Child>(context) ..where((p) => p.parent.age).greaterThan(30); final employeesWithManagersOver30YearsOld = await q.fetch();","title":"Filtering Objects by Their Relationships"},{"location":"db/advanced_queries/#multiple-joins","text":"More than one join can be applied to a query, and subqueries can be nested. So, this is all valid, assuming the relationship properties exist: var q = Query<User>(context) ..join(object: (u) => u.address); q.join(set: (u) => u.tasks) ..join(object: (u) => u.location); This would fetch all users, their addresses, all of their tasks, and the location for each of their tasks. You'd get a nice sized tree of objects here.","title":"Multiple Joins"},{"location":"db/advanced_queries/#reduce-functions-aka-aggregate-functions","text":"Queries can also be used to perform functions like count , sum , average , min and max . Here's an example: var query = Query<User>(context); var numberOfUsers = await query.reduce.count(); For reduce functions that use the value of some property, a property selector is used to identify that property. var averageSalary = await query.reduce.sum((u) => u.salary); Any values configured in a Query<T> also impact the reduce function. For example, applying a Query.where and then executing a sum function will only sum the rows that meet the criteria of the where clause: var query = Query<User>(context) ..where((u) => u.name.equalTo(\"Bob\"); var averageSalaryOfPeopleNamedBob = await query.reduce.sum((u) => u.salary);","title":"Reduce Functions (aka, Aggregate Functions)"},{"location":"db/advanced_queries/#fallbacks","text":"You may always execute arbitrary SQL with PersistentStore.execute . Note that the objects returned will be a List<List<dynamic>> - a list of rows, for each a list of columns. You may also provide raw WHERE clauses with Query.predicate . A QueryPredicate is a String that is set as the query's where clause. A QueryPredicate has two properties, a format string and a Map<String, dynamic> of parameter values. The format string can (and should) parameterize any input values. Parameters are indicated in the format string using the @ token: // Creates a predicate that would only include instances where some column \"id\" is less than 2 var predicate = QueryPredicate(\"id < @idVariable\", {\"idVariable\" : 2}); The text following the @ token may contain [A-Za-z0-9_] . The resulting where clause will be formed by replacing each token with the matching key in the parameters map. The value is not transformed in any way, so it must be the appropriate type for the column. If a key is not present in the Map , an exception will be thrown. Extra keys will be ignored.","title":"Fallbacks"},{"location":"db/connecting/","text":"Connecting to a Database from Conduit The purpose of this document is to guide you through creating a new PostgreSQL database and setting up a Conduit application that connects to it. Creating a Database To use the Conduit ORM, you must have a PostgreSQL database server and create a database for your application. When developing locally, use Postgres.app to set up a development database server quickly. After running this application, create or select a new database server from the left-hand menu, and then double-click any of the database icons to open the psql command-line tool. (If you are not using Postgres.app , make sure psql is in your $PATH and run it from the command-line.) Inside psql , enter the following commands to create a database and a database user for your application: CREATE DATABASE my_app_name; CREATE USER my_app_name_user WITH PASSWORD 'password'; GRANT ALL ON DATABASE my_app_name TO my_app_name_user; Using ManagedContext to Connect to a Database The interface to a database from Conduit is an instance of ManagedContext that contains the following two objects: a ManagedDataModel that describes your application's data model a PersistentStore that manages a connection to a single database A ManagedContext uses these two objects to coordinate moving data to and from your application and a database. A Query<T> object uses a context's persistent store to determine which database to send commands to, and a data model to map database rows to objects and vice versa. A context, like all service objects, is created in ApplicationChannel.prepare . class MyApplicationChannel extends ApplicationChannel { ManagedContext context; @override Future prepare() async { var dataModel = ManagedDataModel.fromCurrentMirrorSystem(); var psc = PostgreSQLPersistentStore.fromConnectionInfo( \"my_app_name_user\", \"password\", \"localhost\", 5432, \"my_app_name\"); context = ManagedContext(dataModel, psc); } } The ManagedDataModel.fromCurrentMirrorSystem finds every ManagedObject<T> subclass in your application's code. Optionally, you may specify an exact list: var dataModel = ManagedDataModel([User, Post, Friendship]); !!! note \"Finding ManagedObjects\" A managed object subclass must be directly or transitively imported into your application channel file. A file in your project directory that is not imported will not be found. There is typically no need to import a managed object subclass file directly: your application is initialized in your channel, which imports all of your controllers and services, which in turn import the managed object subclasses they use. As long as you are using your managed object declarations in your application, they'll be found. Controllers that need to execute database queries must have a reference to a context; this is typically accomplished by passing the context to a controller's constructor: class MyApplicationChannel extends ApplicationChannel { ManagedContext context; @override Future prepare() async { context = ManagedContext(...); } @override Controller get entryPoint { return Router() ..route(\"/users/[:id]\").link(() => UserController(context)); } } Using a Configuration File Connection information for a database is most often read from a configuration file. This allows you to create configurations for different environments (production, development, etc.), without having to modify code. This is very important for testing, because you will want to run your automated tests against an empty database. ( See more on configuration files. .) class MyConfiguration extends Configuration { MyConfiguration(String configPath) : super.fromFile(configPath); DatabaseConfiguration database; } class MyApplicationChannel extends ApplicationChannel { ManagedContext context; @override Future prepare() async { final config = MyConfiguration(options.configurationFilePath); final dataModel = ManagedDataModel.fromCurrentMirrorSystem(); final psc = PostgreSQLPersistentStore.fromConnectionInfo( config.database.username, config.database.password, config.database.host, config.database.port, config.database.databaseName); context = ManagedContext(dataModel, psc); } } The declaration of MyConfiguration requires that a YAML file must have the following structure: database: username: bob password: bobspassword host: localhost port: 5432 databaseName: my_app Connection Behavior A persistent store manages one database connection. This connection is automatically maintained - the first time a query is executed, the connection is opened. If the connection is lost, the next query will reopen the connection. If a connection fails to open, an exception is thrown when trying to execute a query. This connection will return a 503 response if left uncaught.","title":"Connecting to a Database"},{"location":"db/connecting/#connecting-to-a-database-from-conduit","text":"The purpose of this document is to guide you through creating a new PostgreSQL database and setting up a Conduit application that connects to it.","title":"Connecting to a Database from Conduit"},{"location":"db/connecting/#creating-a-database","text":"To use the Conduit ORM, you must have a PostgreSQL database server and create a database for your application. When developing locally, use Postgres.app to set up a development database server quickly. After running this application, create or select a new database server from the left-hand menu, and then double-click any of the database icons to open the psql command-line tool. (If you are not using Postgres.app , make sure psql is in your $PATH and run it from the command-line.) Inside psql , enter the following commands to create a database and a database user for your application: CREATE DATABASE my_app_name; CREATE USER my_app_name_user WITH PASSWORD 'password'; GRANT ALL ON DATABASE my_app_name TO my_app_name_user;","title":"Creating a Database"},{"location":"db/connecting/#using-managedcontext-to-connect-to-a-database","text":"The interface to a database from Conduit is an instance of ManagedContext that contains the following two objects: a ManagedDataModel that describes your application's data model a PersistentStore that manages a connection to a single database A ManagedContext uses these two objects to coordinate moving data to and from your application and a database. A Query<T> object uses a context's persistent store to determine which database to send commands to, and a data model to map database rows to objects and vice versa. A context, like all service objects, is created in ApplicationChannel.prepare . class MyApplicationChannel extends ApplicationChannel { ManagedContext context; @override Future prepare() async { var dataModel = ManagedDataModel.fromCurrentMirrorSystem(); var psc = PostgreSQLPersistentStore.fromConnectionInfo( \"my_app_name_user\", \"password\", \"localhost\", 5432, \"my_app_name\"); context = ManagedContext(dataModel, psc); } } The ManagedDataModel.fromCurrentMirrorSystem finds every ManagedObject<T> subclass in your application's code. Optionally, you may specify an exact list: var dataModel = ManagedDataModel([User, Post, Friendship]); !!! note \"Finding ManagedObjects\" A managed object subclass must be directly or transitively imported into your application channel file. A file in your project directory that is not imported will not be found. There is typically no need to import a managed object subclass file directly: your application is initialized in your channel, which imports all of your controllers and services, which in turn import the managed object subclasses they use. As long as you are using your managed object declarations in your application, they'll be found. Controllers that need to execute database queries must have a reference to a context; this is typically accomplished by passing the context to a controller's constructor: class MyApplicationChannel extends ApplicationChannel { ManagedContext context; @override Future prepare() async { context = ManagedContext(...); } @override Controller get entryPoint { return Router() ..route(\"/users/[:id]\").link(() => UserController(context)); } }","title":"Using ManagedContext to Connect to a Database"},{"location":"db/connecting/#using-a-configuration-file","text":"Connection information for a database is most often read from a configuration file. This allows you to create configurations for different environments (production, development, etc.), without having to modify code. This is very important for testing, because you will want to run your automated tests against an empty database. ( See more on configuration files. .) class MyConfiguration extends Configuration { MyConfiguration(String configPath) : super.fromFile(configPath); DatabaseConfiguration database; } class MyApplicationChannel extends ApplicationChannel { ManagedContext context; @override Future prepare() async { final config = MyConfiguration(options.configurationFilePath); final dataModel = ManagedDataModel.fromCurrentMirrorSystem(); final psc = PostgreSQLPersistentStore.fromConnectionInfo( config.database.username, config.database.password, config.database.host, config.database.port, config.database.databaseName); context = ManagedContext(dataModel, psc); } } The declaration of MyConfiguration requires that a YAML file must have the following structure: database: username: bob password: bobspassword host: localhost port: 5432 databaseName: my_app","title":"Using a Configuration File"},{"location":"db/connecting/#connection-behavior","text":"A persistent store manages one database connection. This connection is automatically maintained - the first time a query is executed, the connection is opened. If the connection is lost, the next query will reopen the connection. If a connection fails to open, an exception is thrown when trying to execute a query. This connection will return a 503 response if left uncaught.","title":"Connection Behavior"},{"location":"db/db_tools/","text":"Database Migration and Tooling The conduit db command line tool creates and executes migration files . A migration file contains Dart code that executes SQL commands to create and modify database tables. !!! warning \"PostgreSQL 9.6 and Greater\" The minimum version of PostgreSQL needed to work with Conduit is 9.6. Migration Files An application's data model is described by its ManagedObject<T> subclasses and their table definition . Migration files describe a series of database commands that will create or modify a database schema to match an application's data model. Migration files are executed on a database when an application is first deployed and when changes to the data model occur - like adding new ManagedObject<T> subclasses or adding an database index to a property. A migration file is automatically generated from your code. Each migration file contains only the changes made since the last migration file was generated. For example, if you began your application with a Author type and generated a migration file, the migration file would create the author table. If you then added a Book type and generated a new migration file, the new file would only create the book table. When a migration is used to upgrade a database schema, every migration file that has not yet been run will be run. Migration files must be stored in version control so that you can manage multiple databases for different environments. Generating Migration Files The conduit db generate command generates a new migration file. This tool finds all ManagedObject<T> subclasses - your data model - in your application and compares them to the data model the last time the tool was run. Any differences between the data models are represented as a command in the generated migration file. If the new migration file were to be used to upgrade a database, the database would match the current data model in your application. !!! note \"Finding ManagedObjects\" A managed object subclass must be directly or transitively imported into your application channel file. A file in your project directory that is not imported will not be found. There is typically no need to import a managed object subclass file directly: your application is initialized in your channel, where imports all of your controllers and services, which in turn import the managed object subclasses they use. As long as you are using your managed object declarations in your application, they'll be found. Migration files are stored in an project's migrations/ directory. Migration files are prefixed with a version number, a \"0\" padded eight digit number, ad suffixed with .migration.dart . For example, 00000001_initial.migration.dart is a migration filename. The version number portion of the filename is required, as is the .migration.dart suffix. The underscore and remainder of the filename are optional and have no effect, they are just a way to name the file. Here is an example of two migration file names: 00000001_initial.migration.dart 00000002_add_user_nickname.migration.dart The version number of migration files indicate the order in which they are applied. Leading zeros are stripped from the filenames before their version numbers are compared. Version numbers do not necessarily have to be continuous, but doing otherwise is not recommended. Migration files may be altered after they are generated (see seeding data ). Validating Migration Files The conduit db validate tool validates that the database schema after running all migration files matches the application's data model. The validate tool will display differences found between the schema in code and the schema created by migration files. Listing Migration Files Use conduit db list to list all database migration files and their resolved version number. Getting a Database's Version You can fetch a database's current version number with conduit db get-version . This command takes --connect or a database.yaml file as described in the next section to get connection info for the database. Upgrading a Database Schema by Executing Migration Files The tool conduit db upgrade will apply the commands of migration files to a running database. This tool is run in an application's directory and database connection info is provided with the --connect option. For example, the following would execute the current project directory's migration files on a PostgreSQL database: conduit db upgrade --connect postgres://username:password@localhost:5432/my_application Every migration file that has not yet been run on the targeted database will be run. This tool manages a version table in each database it upgrades that allows it to determine which migration files need to be run. Connection information can alternatively be stored in a database configuration file named database.yaml in the application directory. If this file exists with the following format, --connect can be omitted and connection information will be read from this file: username: \"user\" password: \"password\" host: \"host\" port: port databaseName: \"database\" When to Execute Migration Files During development, there is no need to create a migration file for each change. Execute migration files prior to deployment of a new version of an application. You may delete migration files (as long as you haven't run them on a production database!). When conduit db generate is run again, it will replay only the existing migration files before determining which commands to add to the new migration file. For example, if you have 10 migration files over time and delete them all - the next generated migration file will contain commands to recreate the entire database schema. Seeding Data You may insert, delete, or edit rows during a database migration by overriding its seed method. You must run SQL queries instead of using Query<T> when seeding data. The Migration base class that all of your migrations extends have a property for a PersistentStore connected to the database the migration is being run on. class Migration2 extends Migration { @override Future upgrade() async { ... } @override Future downgrade() async { ... } @override Future seed() async { await store.executeQuery(\"INSERT IN _mytable (a) VALUES (1)\"); } } Seeding is run after a migration's ugprade method has completed. Seeding data also occurs in the same transaction as upgrade . Handling Non-nullable Additions Some database upgrades can fail depending on the data currently in the database. A common scenario is adding a property to an existing managed object that is not-nullable. If the database table already has rows, those rows would not have a value for the new column and the migration would fail. If the database does not have any rows, the migration will succeed correctly. If the property has a default value attribute or is auto-incrementing, the migration will always succeed and the existing rows will have the default value for the new column. You may also provide a value just for the existing rows to make the migration succeed. This is added as an argument to the schema-altering command that would violate non-nullability: @override Future upgrade() async { database.addColumn(\"_mytable\", SchemaColumn(...), unencodedInitialValue: \"'text'\") } The unencoded initial value is inserted directly into a SQL command. This requires that the value be a SQL value literal as shown in the table: Type Unencoded Initial Value Value int \"1\" 1 String \"'string'\" 'string' double \"2.0\" 2.0 DateTime \"'1900-01-02T00:00:00.000Z'\" 1/2/1900","title":"Migration and Tooling"},{"location":"db/db_tools/#database-migration-and-tooling","text":"The conduit db command line tool creates and executes migration files . A migration file contains Dart code that executes SQL commands to create and modify database tables. !!! warning \"PostgreSQL 9.6 and Greater\" The minimum version of PostgreSQL needed to work with Conduit is 9.6.","title":"Database Migration and Tooling"},{"location":"db/db_tools/#migration-files","text":"An application's data model is described by its ManagedObject<T> subclasses and their table definition . Migration files describe a series of database commands that will create or modify a database schema to match an application's data model. Migration files are executed on a database when an application is first deployed and when changes to the data model occur - like adding new ManagedObject<T> subclasses or adding an database index to a property. A migration file is automatically generated from your code. Each migration file contains only the changes made since the last migration file was generated. For example, if you began your application with a Author type and generated a migration file, the migration file would create the author table. If you then added a Book type and generated a new migration file, the new file would only create the book table. When a migration is used to upgrade a database schema, every migration file that has not yet been run will be run. Migration files must be stored in version control so that you can manage multiple databases for different environments.","title":"Migration Files"},{"location":"db/db_tools/#generating-migration-files","text":"The conduit db generate command generates a new migration file. This tool finds all ManagedObject<T> subclasses - your data model - in your application and compares them to the data model the last time the tool was run. Any differences between the data models are represented as a command in the generated migration file. If the new migration file were to be used to upgrade a database, the database would match the current data model in your application. !!! note \"Finding ManagedObjects\" A managed object subclass must be directly or transitively imported into your application channel file. A file in your project directory that is not imported will not be found. There is typically no need to import a managed object subclass file directly: your application is initialized in your channel, where imports all of your controllers and services, which in turn import the managed object subclasses they use. As long as you are using your managed object declarations in your application, they'll be found. Migration files are stored in an project's migrations/ directory. Migration files are prefixed with a version number, a \"0\" padded eight digit number, ad suffixed with .migration.dart . For example, 00000001_initial.migration.dart is a migration filename. The version number portion of the filename is required, as is the .migration.dart suffix. The underscore and remainder of the filename are optional and have no effect, they are just a way to name the file. Here is an example of two migration file names: 00000001_initial.migration.dart 00000002_add_user_nickname.migration.dart The version number of migration files indicate the order in which they are applied. Leading zeros are stripped from the filenames before their version numbers are compared. Version numbers do not necessarily have to be continuous, but doing otherwise is not recommended. Migration files may be altered after they are generated (see seeding data ).","title":"Generating Migration Files"},{"location":"db/db_tools/#validating-migration-files","text":"The conduit db validate tool validates that the database schema after running all migration files matches the application's data model. The validate tool will display differences found between the schema in code and the schema created by migration files.","title":"Validating Migration Files"},{"location":"db/db_tools/#listing-migration-files","text":"Use conduit db list to list all database migration files and their resolved version number.","title":"Listing Migration Files"},{"location":"db/db_tools/#getting-a-databases-version","text":"You can fetch a database's current version number with conduit db get-version . This command takes --connect or a database.yaml file as described in the next section to get connection info for the database.","title":"Getting a Database's Version"},{"location":"db/db_tools/#upgrading-a-database-schema-by-executing-migration-files","text":"The tool conduit db upgrade will apply the commands of migration files to a running database. This tool is run in an application's directory and database connection info is provided with the --connect option. For example, the following would execute the current project directory's migration files on a PostgreSQL database: conduit db upgrade --connect postgres://username:password@localhost:5432/my_application Every migration file that has not yet been run on the targeted database will be run. This tool manages a version table in each database it upgrades that allows it to determine which migration files need to be run. Connection information can alternatively be stored in a database configuration file named database.yaml in the application directory. If this file exists with the following format, --connect can be omitted and connection information will be read from this file: username: \"user\" password: \"password\" host: \"host\" port: port databaseName: \"database\"","title":"Upgrading a Database Schema by Executing Migration Files"},{"location":"db/db_tools/#when-to-execute-migration-files","text":"During development, there is no need to create a migration file for each change. Execute migration files prior to deployment of a new version of an application. You may delete migration files (as long as you haven't run them on a production database!). When conduit db generate is run again, it will replay only the existing migration files before determining which commands to add to the new migration file. For example, if you have 10 migration files over time and delete them all - the next generated migration file will contain commands to recreate the entire database schema.","title":"When to Execute Migration Files"},{"location":"db/db_tools/#seeding-data","text":"You may insert, delete, or edit rows during a database migration by overriding its seed method. You must run SQL queries instead of using Query<T> when seeding data. The Migration base class that all of your migrations extends have a property for a PersistentStore connected to the database the migration is being run on. class Migration2 extends Migration { @override Future upgrade() async { ... } @override Future downgrade() async { ... } @override Future seed() async { await store.executeQuery(\"INSERT IN _mytable (a) VALUES (1)\"); } } Seeding is run after a migration's ugprade method has completed. Seeding data also occurs in the same transaction as upgrade .","title":"Seeding Data"},{"location":"db/db_tools/#handling-non-nullable-additions","text":"Some database upgrades can fail depending on the data currently in the database. A common scenario is adding a property to an existing managed object that is not-nullable. If the database table already has rows, those rows would not have a value for the new column and the migration would fail. If the database does not have any rows, the migration will succeed correctly. If the property has a default value attribute or is auto-incrementing, the migration will always succeed and the existing rows will have the default value for the new column. You may also provide a value just for the existing rows to make the migration succeed. This is added as an argument to the schema-altering command that would violate non-nullability: @override Future upgrade() async { database.addColumn(\"_mytable\", SchemaColumn(...), unencodedInitialValue: \"'text'\") } The unencoded initial value is inserted directly into a SQL command. This requires that the value be a SQL value literal as shown in the table: Type Unencoded Initial Value Value int \"1\" 1 String \"'string'\" 'string' double \"2.0\" 2.0 DateTime \"'1900-01-02T00:00:00.000Z'\" 1/2/1900","title":"Handling Non-nullable Additions"},{"location":"db/executing_queries/","text":"Inserting, Updating, Deleting and Fetching Objects To send commands to a database - whether to fetch, insert, delete or update objects - you will create, configure and execute instances of Query<T> . The type argument must be a subclass of ManagedObject , which determines the table the query will operate on. A query compiles and executes a SQL query and requires a ManagedContext to determine the database to connect to. Here's an example of a Query<T> that fetches all instances of User : final query = Query<User>(context); final allUsers = await query.fetch(); A Query<T> has four basic execution methods: fetch , update , insert , delete . fetch will retrieve data from a database (it is equivalent to the SQL operation SELECT ). update will modify existing data in a database (it is equivalent to the SQL operation UPDATE ). insert will add new data to a database (it is equivalent to the SQL operation INSERT ). delete will remove data from a database (it is equivalent to the SQL operation DELETE ). A Query<T> has many configurable properties. These properties will impact which objects get fetched, the data that gets sent to the database, the order that data is returned in, and so on. In the following sections, assume that a User managed object subclass exists that is declared like so: class User extends ManagedObject<_User> implements _User {} class _User { @primaryKey int id; @Column(indexed: true) String email; String name; } Inserting Data with a Query To insert data with a query, you create a new Query<T> object, configure its values property and then call its insert() method. final query = Query<User>(context) ..values.name = \"Bob\" ..values.email = \"bob@conduit.dart.com\"; final user = await query.insert(); The values of a Query<T> is an instance of T (the managed object type you are inserting). You can configure individual properties of values , or you can assign values to an instance you have created elsewhere: final userValues = User() ..name = \"Bob\" ..email = \"bob@conduit.dart.com\"; final query = Query<User>(context)..values = userValues; final user = await query.insert(); Either way, this query is translated into the following SQL: INSERT INTO _user (name, email) VALUES ('Bob', 'bob@conduit.dart.com') RETURNING id, name, email; Notice that only the values set on the values object are included in the SQL INSERT query. In this example, both name and email were set, but not id and therefore only name and email were included in the query. (In this case, the primary key is auto-incrementing and the database will generate it.) Values that are explicitly set to null will be sent as NULL . For example, consider the following Query<T> and its SQL: var query = Query<User>(context) ..values.name = null ..email = \"bob@conduit.dart.com\"; // INSERT INTO _user (name, email) VALUES (NULL, 'bob@conduit.dart.com') RETURNING id, name, email; await query.insert(); An insert query will return a managed object that represents the row that is inserted. !!! warning \"Prefer the Inserted Object\" After you insert an object, you should prefer to use the object returned by an insert query rather than the values you used to populate the query. The object returned from the query will be an accurate representation of the database row, while the object used to build the query may be incomplete or different. For example, an auto-incrementing primary key won't be available in your query-building instance, but will in the object returned from the successful query. There is one difference to note when choosing between assigning an instance to values , or configuring the properties of values . In an instance you create, a relationship property must be instantiated before accessing its properties. When accessing the relationship properties of values , an empty instance of the related object is created immediately upon access. final employee = Employee() ..manager.id = 1; // this is a null pointer exception because manager is null final query = Query<Employee>(context) ..values.manager.id = 1; // this is OK because of special behavior of Query Once you assign an object to values , it will adopt the behavior of values and instantiate relationships when accessed. Also note that after assigning an object to values , changes to the original object are not reflected in values . In other words, the object is copied instead of referenced. For simple insertions and for inserting more than one object, you can use the methods on the context: final context = ManagedContext(...); final bob = User()..name = \"Bob\"; final jay = User()..name = \"Jay\"; final insertedObject = await context.insertObject(bob); final insertedObjects = await context.insertObjects([bob, jay]); Updating Data with a Query Updating rows with a Query<T> is similar to inserting data: you set the Query.values for properties you want to change. The type parameter for the Query<T> indicates which database table will get updated when the query is executed. An update query can - and likely should - be restricted to a single row or subset of rows. This is done by configuring the Query.where property - which gets translated into the where clause of the SQL command. Here's an example: // A Query that will change any user's whose name is 'Bob' to 'Fred' var query = Query<User>(context) ..values.name = \"Fred\" ..where((u) => u.name).equalTo(\"Bob\"); List<User> bobsThatAreNowFreds = await query.update(); Like values , where is also the same managed object type the query is being executed on. In the above example, then, both values and where and instances of User . This query executes the following SQL: UPDATE _user SET name='Fred' WHERE name='Bob'; The where property is a very powerful and flexible, and so there is an entire section dedicated to it later in this guide. For now, we'll stick to some of the things specific to update() . Like insert() , only the values set in the values property of a query get updated when executing update() . Values that are omitted are not included. Values that need to be set to null must explicitly be set to null in the query: // A Query that will remove names from anyone currently named Bob. var query = Query<User>(context) ..values.name = null ..where((u) => u.name).equalTo(\"Bob\"); An update query returns every modified row as a result. If no rows are updated, the return value is an empty list. There is a variant to Query<T>.update named updateOne . The updateOne method will build and execute a SQL query in the same way a normal update does, however, it will only return the single instance that was updated instead of a list. This is convenience method for the caller to get back a single instance instead of a list: // Update user with id = 1 to have the name 'Fred' var query = Query<User>(context) ..values.name = \"Fred\" ..where((u) => u.id).equalTo(1); var updatedUser = await query.updateOne(); The updateOne method will return null if no rows were updated. It is important to note that if updateOne is used and more than one row is updated, updateOne will throw an exception and the changes to the data are not reversible . Because this is likely a mistake, this is considered an error, hence the exception is thrown. It is up to the programmer to recognize whether or not a particular updateOne query would impact multiple rows. Update queries have a safety feature that prevents you from accidentally updating every row. If you try to execute a Query<T> to do an update without configuring where , an exception is thrown prior to carrying out the request. If you actually want to update every row of a table, you must set the Query.canModifyAllInstances to true prior to execution. (This property defaults to false .) Deleting Data with a Query A Query<T> will delete rows from a database when using delete() . Like update queries, you should specify a row or rows using where properties of the Query<T> . The result of a delete operation will be a Future<int> with the number of rows deleted. var query = Query<User>(context) ..where((u) => u.id).equalTo(1); int usersDeleted = await query.delete(); Also like update queries, delete queries have a safety feature that prevents you from accidentally deleting every row in a table with canModifyAllInstances . Any properties set in the query's values are ignored when executing a delete. Fetching Data with a Query Of the four basic operations of a Query<T> , fetching data is the most configurable. A simple Query<T> that would fetch every instance of some entity looks like this: var query = Query<User>(context); List<User> allUsers = await query.fetch(); Fetch queries can be limited to a number of instances with the fetchLimit property. You may also set the offset of a Query<T> to skip the first offset number of rows. Between fetchLimit and offset , you can implement naive paging. However, this type of paging suffers from a number of problems and so there is another paging mechanism covered in later sections. A fetch Query<T> uses its where property to filter the result set, just like delete and update queries. The values of a query are ignored when fetching objects. You may also fetch a single instance with fetchOne . If no instance is found, null is returned. Only use this method when the search criteria is guaranteed to be unique. var query = Query<User>(context) ..where((u) => u.id).equalTo(1); User oneUser = await query.fetchOne(); When you are fetching an object by its primary key, you can use a shorthand method ManagedContext.fetchObjectWithID . The method must be able to infer the type of the object, or you must provide it: final object = await context.fetchObjectWithID<User>(1); Sorting Results of a fetch can be sorted using the sortBy method of a Query<T> . Here's an example: var q = Query<User>(context) ..sortBy((u) => u.dateCreated, QuerySortOrder.ascending); sortBy takes two arguments: a closure that returns which property to sort by and the order of the sort. A Query<T> results can be sorted by multiple properties. When multiple sortBy s are invoked on a Query<T> , later sortBy s are used to break ties in previous sortBy s. For example, the following query will sort by last name, then by first name: var q = Query<User>(context) ..sortBy((u) => u.lastName, QuerySortOrder.ascending) ..sortBy((u) => u.firstName, QuerySortOrder.ascending); Thus, the following three names would be ordered like so: 'Sally Smith', 'John Wu', 'Sally Wu'. Property Selectors In the section on sorting, you saw the use of a property selector to select the property of the user to sort by. This syntax is used for many other query manipulations, like filtering and joining. A property selector is a closure that gives you an object of the type you are querying and must return a property of that object. The selector (u) => u.lastName in the previous section is a property selector that selects the last name of a user. The Dart analyzer will infer that the argument of a property selector, and it is always the same type as the object being queried. This enables IDE auto-completion, static error checking, and other tools like project-wide renaming. !!! tip \"Live Templates\" To speed up query building, create a Live Template in IntelliJ that generates a property selector when typing 'ps'. The source of the template is (o) => o.$END$ . A downloadable settings configuration for IntelliJ exists here that includes this shortcut. Specifying Result Properties When executing queries that return managed objects (i.e., insert() , update() and fetch() ), the default properties for each object are fetched. The default properties of a managed object are properties that correspond to a database column - attributes declared in the table definition. A managed object's default properties can be modified when declaring its table definition: class _User { @Column(omitByDefault: true) String hashedPassword; } Any property with omitByDefault set to true will not be fetched by default. A property that is omitByDefault can still be fetched. Likewise, a property that is in the defaults can still be omitted. Each Query<T> has a returningProperties method to adjust which properties do get returned from the query. Its usage looks like this: var query = Query<User>(context) ..returningProperties((user) => [user.id, user.name]); returningProperties is a multiple property selector - instead of returning just one property, it returns a list of properties. You may include 'belongs-to' relationships in returningProperties , but you may not include 'has-many' or 'has-one' relationships. An exception will be thrown if you attempt to. To include properties from relationships like these, see join in Advanced Queries . Note that if you omit the primary key of a managed object from returningProperties , it will automatically be added. The primary key is necessary to transform the rows into instances of their ManagedObject<T> subclass. Exceptions and Errors When executing a query, it may fail for any number of reasons: the query is invalid, a database couldn't be reached, constraints were violated, etc. In many cases, this exception originates from the underlying database driver. When thrown in a controller, these exceptions will trigger a 500 Server Error response. Exceptions that are thrown in response to user input (e.g., violating a database constraint, invalid data type) are re-interpreted into a QueryException or ValidationException . Both of these exception types have an associated Response object that is sent instead of the default 500 Server error. For this reason, you don't need to catch database query exceptions in a controller; an appropriate response will be sent on your behalf. Statement Reuse Conduit will parameterize and reuse queries when possible. This allows for significant speed and security improvements. Note that you do not have to do anything special to take advantage of this feature. However, currently at this time, you may not disable this feature.","title":"Basic Queries"},{"location":"db/executing_queries/#inserting-updating-deleting-and-fetching-objects","text":"To send commands to a database - whether to fetch, insert, delete or update objects - you will create, configure and execute instances of Query<T> . The type argument must be a subclass of ManagedObject , which determines the table the query will operate on. A query compiles and executes a SQL query and requires a ManagedContext to determine the database to connect to. Here's an example of a Query<T> that fetches all instances of User : final query = Query<User>(context); final allUsers = await query.fetch(); A Query<T> has four basic execution methods: fetch , update , insert , delete . fetch will retrieve data from a database (it is equivalent to the SQL operation SELECT ). update will modify existing data in a database (it is equivalent to the SQL operation UPDATE ). insert will add new data to a database (it is equivalent to the SQL operation INSERT ). delete will remove data from a database (it is equivalent to the SQL operation DELETE ). A Query<T> has many configurable properties. These properties will impact which objects get fetched, the data that gets sent to the database, the order that data is returned in, and so on. In the following sections, assume that a User managed object subclass exists that is declared like so: class User extends ManagedObject<_User> implements _User {} class _User { @primaryKey int id; @Column(indexed: true) String email; String name; }","title":"Inserting, Updating, Deleting and Fetching Objects"},{"location":"db/executing_queries/#inserting-data-with-a-query","text":"To insert data with a query, you create a new Query<T> object, configure its values property and then call its insert() method. final query = Query<User>(context) ..values.name = \"Bob\" ..values.email = \"bob@conduit.dart.com\"; final user = await query.insert(); The values of a Query<T> is an instance of T (the managed object type you are inserting). You can configure individual properties of values , or you can assign values to an instance you have created elsewhere: final userValues = User() ..name = \"Bob\" ..email = \"bob@conduit.dart.com\"; final query = Query<User>(context)..values = userValues; final user = await query.insert(); Either way, this query is translated into the following SQL: INSERT INTO _user (name, email) VALUES ('Bob', 'bob@conduit.dart.com') RETURNING id, name, email; Notice that only the values set on the values object are included in the SQL INSERT query. In this example, both name and email were set, but not id and therefore only name and email were included in the query. (In this case, the primary key is auto-incrementing and the database will generate it.) Values that are explicitly set to null will be sent as NULL . For example, consider the following Query<T> and its SQL: var query = Query<User>(context) ..values.name = null ..email = \"bob@conduit.dart.com\"; // INSERT INTO _user (name, email) VALUES (NULL, 'bob@conduit.dart.com') RETURNING id, name, email; await query.insert(); An insert query will return a managed object that represents the row that is inserted. !!! warning \"Prefer the Inserted Object\" After you insert an object, you should prefer to use the object returned by an insert query rather than the values you used to populate the query. The object returned from the query will be an accurate representation of the database row, while the object used to build the query may be incomplete or different. For example, an auto-incrementing primary key won't be available in your query-building instance, but will in the object returned from the successful query. There is one difference to note when choosing between assigning an instance to values , or configuring the properties of values . In an instance you create, a relationship property must be instantiated before accessing its properties. When accessing the relationship properties of values , an empty instance of the related object is created immediately upon access. final employee = Employee() ..manager.id = 1; // this is a null pointer exception because manager is null final query = Query<Employee>(context) ..values.manager.id = 1; // this is OK because of special behavior of Query Once you assign an object to values , it will adopt the behavior of values and instantiate relationships when accessed. Also note that after assigning an object to values , changes to the original object are not reflected in values . In other words, the object is copied instead of referenced. For simple insertions and for inserting more than one object, you can use the methods on the context: final context = ManagedContext(...); final bob = User()..name = \"Bob\"; final jay = User()..name = \"Jay\"; final insertedObject = await context.insertObject(bob); final insertedObjects = await context.insertObjects([bob, jay]);","title":"Inserting Data with a Query"},{"location":"db/executing_queries/#updating-data-with-a-query","text":"Updating rows with a Query<T> is similar to inserting data: you set the Query.values for properties you want to change. The type parameter for the Query<T> indicates which database table will get updated when the query is executed. An update query can - and likely should - be restricted to a single row or subset of rows. This is done by configuring the Query.where property - which gets translated into the where clause of the SQL command. Here's an example: // A Query that will change any user's whose name is 'Bob' to 'Fred' var query = Query<User>(context) ..values.name = \"Fred\" ..where((u) => u.name).equalTo(\"Bob\"); List<User> bobsThatAreNowFreds = await query.update(); Like values , where is also the same managed object type the query is being executed on. In the above example, then, both values and where and instances of User . This query executes the following SQL: UPDATE _user SET name='Fred' WHERE name='Bob'; The where property is a very powerful and flexible, and so there is an entire section dedicated to it later in this guide. For now, we'll stick to some of the things specific to update() . Like insert() , only the values set in the values property of a query get updated when executing update() . Values that are omitted are not included. Values that need to be set to null must explicitly be set to null in the query: // A Query that will remove names from anyone currently named Bob. var query = Query<User>(context) ..values.name = null ..where((u) => u.name).equalTo(\"Bob\"); An update query returns every modified row as a result. If no rows are updated, the return value is an empty list. There is a variant to Query<T>.update named updateOne . The updateOne method will build and execute a SQL query in the same way a normal update does, however, it will only return the single instance that was updated instead of a list. This is convenience method for the caller to get back a single instance instead of a list: // Update user with id = 1 to have the name 'Fred' var query = Query<User>(context) ..values.name = \"Fred\" ..where((u) => u.id).equalTo(1); var updatedUser = await query.updateOne(); The updateOne method will return null if no rows were updated. It is important to note that if updateOne is used and more than one row is updated, updateOne will throw an exception and the changes to the data are not reversible . Because this is likely a mistake, this is considered an error, hence the exception is thrown. It is up to the programmer to recognize whether or not a particular updateOne query would impact multiple rows. Update queries have a safety feature that prevents you from accidentally updating every row. If you try to execute a Query<T> to do an update without configuring where , an exception is thrown prior to carrying out the request. If you actually want to update every row of a table, you must set the Query.canModifyAllInstances to true prior to execution. (This property defaults to false .)","title":"Updating Data with a Query"},{"location":"db/executing_queries/#deleting-data-with-a-query","text":"A Query<T> will delete rows from a database when using delete() . Like update queries, you should specify a row or rows using where properties of the Query<T> . The result of a delete operation will be a Future<int> with the number of rows deleted. var query = Query<User>(context) ..where((u) => u.id).equalTo(1); int usersDeleted = await query.delete(); Also like update queries, delete queries have a safety feature that prevents you from accidentally deleting every row in a table with canModifyAllInstances . Any properties set in the query's values are ignored when executing a delete.","title":"Deleting Data with a Query"},{"location":"db/executing_queries/#fetching-data-with-a-query","text":"Of the four basic operations of a Query<T> , fetching data is the most configurable. A simple Query<T> that would fetch every instance of some entity looks like this: var query = Query<User>(context); List<User> allUsers = await query.fetch(); Fetch queries can be limited to a number of instances with the fetchLimit property. You may also set the offset of a Query<T> to skip the first offset number of rows. Between fetchLimit and offset , you can implement naive paging. However, this type of paging suffers from a number of problems and so there is another paging mechanism covered in later sections. A fetch Query<T> uses its where property to filter the result set, just like delete and update queries. The values of a query are ignored when fetching objects. You may also fetch a single instance with fetchOne . If no instance is found, null is returned. Only use this method when the search criteria is guaranteed to be unique. var query = Query<User>(context) ..where((u) => u.id).equalTo(1); User oneUser = await query.fetchOne(); When you are fetching an object by its primary key, you can use a shorthand method ManagedContext.fetchObjectWithID . The method must be able to infer the type of the object, or you must provide it: final object = await context.fetchObjectWithID<User>(1);","title":"Fetching Data with a Query"},{"location":"db/executing_queries/#sorting","text":"Results of a fetch can be sorted using the sortBy method of a Query<T> . Here's an example: var q = Query<User>(context) ..sortBy((u) => u.dateCreated, QuerySortOrder.ascending); sortBy takes two arguments: a closure that returns which property to sort by and the order of the sort. A Query<T> results can be sorted by multiple properties. When multiple sortBy s are invoked on a Query<T> , later sortBy s are used to break ties in previous sortBy s. For example, the following query will sort by last name, then by first name: var q = Query<User>(context) ..sortBy((u) => u.lastName, QuerySortOrder.ascending) ..sortBy((u) => u.firstName, QuerySortOrder.ascending); Thus, the following three names would be ordered like so: 'Sally Smith', 'John Wu', 'Sally Wu'.","title":"Sorting"},{"location":"db/executing_queries/#property-selectors","text":"In the section on sorting, you saw the use of a property selector to select the property of the user to sort by. This syntax is used for many other query manipulations, like filtering and joining. A property selector is a closure that gives you an object of the type you are querying and must return a property of that object. The selector (u) => u.lastName in the previous section is a property selector that selects the last name of a user. The Dart analyzer will infer that the argument of a property selector, and it is always the same type as the object being queried. This enables IDE auto-completion, static error checking, and other tools like project-wide renaming. !!! tip \"Live Templates\" To speed up query building, create a Live Template in IntelliJ that generates a property selector when typing 'ps'. The source of the template is (o) => o.$END$ . A downloadable settings configuration for IntelliJ exists here that includes this shortcut.","title":"Property Selectors"},{"location":"db/executing_queries/#specifying-result-properties","text":"When executing queries that return managed objects (i.e., insert() , update() and fetch() ), the default properties for each object are fetched. The default properties of a managed object are properties that correspond to a database column - attributes declared in the table definition. A managed object's default properties can be modified when declaring its table definition: class _User { @Column(omitByDefault: true) String hashedPassword; } Any property with omitByDefault set to true will not be fetched by default. A property that is omitByDefault can still be fetched. Likewise, a property that is in the defaults can still be omitted. Each Query<T> has a returningProperties method to adjust which properties do get returned from the query. Its usage looks like this: var query = Query<User>(context) ..returningProperties((user) => [user.id, user.name]); returningProperties is a multiple property selector - instead of returning just one property, it returns a list of properties. You may include 'belongs-to' relationships in returningProperties , but you may not include 'has-many' or 'has-one' relationships. An exception will be thrown if you attempt to. To include properties from relationships like these, see join in Advanced Queries . Note that if you omit the primary key of a managed object from returningProperties , it will automatically be added. The primary key is necessary to transform the rows into instances of their ManagedObject<T> subclass.","title":"Specifying Result Properties"},{"location":"db/executing_queries/#exceptions-and-errors","text":"When executing a query, it may fail for any number of reasons: the query is invalid, a database couldn't be reached, constraints were violated, etc. In many cases, this exception originates from the underlying database driver. When thrown in a controller, these exceptions will trigger a 500 Server Error response. Exceptions that are thrown in response to user input (e.g., violating a database constraint, invalid data type) are re-interpreted into a QueryException or ValidationException . Both of these exception types have an associated Response object that is sent instead of the default 500 Server error. For this reason, you don't need to catch database query exceptions in a controller; an appropriate response will be sent on your behalf.","title":"Exceptions and Errors"},{"location":"db/executing_queries/#statement-reuse","text":"Conduit will parameterize and reuse queries when possible. This allows for significant speed and security improvements. Note that you do not have to do anything special to take advantage of this feature. However, currently at this time, you may not disable this feature.","title":"Statement Reuse"},{"location":"db/json_columns/","text":"JSON Document Storage Learn how to store unstructured, binary JSON data in ManagedObject<T> properties. JSON Columns in Relational Databases PostgreSQL supports many column data types like integers, strings, booleans and dates. A column may also be JSON data. This allows for storing unstructured data and simple objects in a table column. The data from JSON columns can be fetched all at once, or in pieces. Elements of JSON data can be used to filter the results of a query. The Document Data Type JSON document columns are added to a database table by declaring a Document property in a ManagedObject<T> 's table definition. In PostgreSQL, a Document column data type is jsonb . A document column can only contain JSON-encodable data. This data is typically a Map or List that contains only JSON-encodable data. The following ManagedObject<T> declaration will have a contents column of type jsonb . class Event extends ManagedObject<_Event> implements _Event {} class _Event { @primaryKey int id; @Column(indexed: true) DateTime timestamp; Document contents; } A Document object has a data property to hold its JSON-encodable data. When instantiating Document , this property defaults to null unless a value has been provided to the optional, ordered parameter in its constructor. final doc = new Document(); assert(doc.data == null); final doc = new Document({\"key\": \"value\"}); assert(doc.data is Map); final doc = new Document([0]); assert(doc.data is List); The data in a document can be accessed through its data property, or through its subscript operator. Document 's subscript operator forwards the invocation to its data property. final doc = new Document({\"key\": \"value\"}); assert(doc[\"key\"] == doc.data[\"key\"]); The argument to the subscript operator may be a string (if data is a map) or an integer (if data is a list). Basic Operations on Document Properties Document columns are like any other type of column, and can therefore be set during an insert or update, and read during a fetch. Inserting Rows with Document Properties A Document property is first set when inserting with a Query<T> . The values property of the query is set to a Document object initialized with a JSON-encodable value. final query = Query<Event>(context) ..values.timestamp = DateTime.now() ..values.contents = Document({ \"type\": \"push\", \"user\": \"bob\", \"tags\": [\"v1\"] }); final event = await query.insert(); In the above, the argument to Document will be JSON-encoded and stored in the database for column contents . If the object can't be encoded as JSON, an exception will be thrown. Fetching Rows with Document Properties When fetching an object with Document properties with a Query<T> , you access the column's value through the document's data property. final query = Query<Event>(context) ..where((e) => e.id).equalTo(1); final event1 = await query.fetchOne(); event1.contents.data == { \"type\": \"push\", \"user\": \"bob\", \"tags\": [\"v1\"] }; When fetching Document properties, the JSON data is decoded into the appropriate type. This is likely a Map or List , but can be any JSON-encodable object. Because the data stored in a Document property is unstructured, the type of data is dynamic . It is good practice to store consistent data structures in a column; i.e., always storing a Map or always storing a List . Updating Rows with Document Properties Updating a row with Document properties works the same as inserting rows. final query = Query<Event>(context) ..where((e) => e.id).equalTo(1) ..values.contents = Document({ \"type\": \"push\", \"user\": \"bob\", \"tags\": [\"v1\", \"new\"] }); final event = await query.updateOne(); When updating in this way, the document stored in the column is replaced entirely. Accessing Document Values The type of Document.data is dynamic - it can be any valid JSON type and may be casted to the expected type when used. This data can also be nested - a List of Maps , for example. When accessing object keys or list indices, you may use the subscript operator directly on Document . // Object Access by key final doc = Document({\"key\": \"value\"}); final value = doc[\"key\"] == \"value\"; // List Access by index final doc = Document([\"v1\", \"v2\"]); final value = doc[0] == \"v1\"; You can access nested elements with the same syntax: final doc = Document([ {\"id\": 1}, {\"id\": 2} ]); final obj1 = doc[0][\"id\"]; // == 1 final obj2 = doc[1][\"id\"]; // == 2 Note that using the subscript operator on a Document simply invokes it on its data property. Therefore, any subscript values must be valid for Dart List and Map types. Fetching Sub-documents When fetching a Document property, the default behavior is to return the entire JSON document as it is stored in the database column. You may fetch parts of the document you need by using Query.returningProperties and the subscript operator. final query = Query<Event>(context) ..returningProperties((e) => [e.id, e.contents[\"tags\"]]); final eventsWithTags = query.fetch(); When using the subscript operator on a returned Document property, only the value for that key is returned. For example, if the above query were executed and the stored column's value were: { \"type\": \"push\", \"user\": \"bob\", \"tags\": [\"v1\"] } The value of Event.contents would only contain the array for the key \"tags\": [\"v1\"] You may also index arrays in a JSON column using the same subscript operator, and the subscript operator can also be nested. For example, the following query would fetch the \"tags\" array, and then fetch the string at index 0 from it: final query = Query<Event>(context) ..returningProperties((e) => [e.id, e.contents[\"tags\"][0]]); final eventsWithFirstTag = await query.fetchOne(); eventsWithFirstTag.contents.data == \"v1\"; If a key or index does not exist in the JSON document, the value of the returned property will be null. For this reason, you should use null-aware operators when accessing Document.data : final query = Query<Event>(context) ..returningProperties((e) => [e.id, e.contents[\"tags\"][7]]); // 7 is out of bounds final eventsWithFirstTag = await query.fetchOne(); if (eventsWithFirstTag.contents?.data == \"v1\") { ... } When fetching elements from a JSON array, you may use negative indices to specify a index from the end of the array. final query = Query<Event>(context) ..returningProperties((e) => [e.id, e.contents[\"tags\"][-1]]); final eventsWithLastTag = await query.fetchOne(); Note that you can only fetch a single sub-structure from a Document column per query. That is, you may not do the following: // Invalid final query = Query<Event>(context) ..returningProperties((e) => [e.id, e.contents[\"type\"], e.contents[\"user\"]]); For operations not supported by Query<T> , you may use SQL directly: final eventTagCounts = await context.persistentStore.execute(\"SELECT jsonb_array_length(contents->'tags') from _Event\");","title":"JSON Document Storage"},{"location":"db/json_columns/#json-document-storage","text":"Learn how to store unstructured, binary JSON data in ManagedObject<T> properties.","title":"JSON Document Storage"},{"location":"db/json_columns/#json-columns-in-relational-databases","text":"PostgreSQL supports many column data types like integers, strings, booleans and dates. A column may also be JSON data. This allows for storing unstructured data and simple objects in a table column. The data from JSON columns can be fetched all at once, or in pieces. Elements of JSON data can be used to filter the results of a query.","title":"JSON Columns in Relational Databases"},{"location":"db/json_columns/#the-document-data-type","text":"JSON document columns are added to a database table by declaring a Document property in a ManagedObject<T> 's table definition. In PostgreSQL, a Document column data type is jsonb . A document column can only contain JSON-encodable data. This data is typically a Map or List that contains only JSON-encodable data. The following ManagedObject<T> declaration will have a contents column of type jsonb . class Event extends ManagedObject<_Event> implements _Event {} class _Event { @primaryKey int id; @Column(indexed: true) DateTime timestamp; Document contents; } A Document object has a data property to hold its JSON-encodable data. When instantiating Document , this property defaults to null unless a value has been provided to the optional, ordered parameter in its constructor. final doc = new Document(); assert(doc.data == null); final doc = new Document({\"key\": \"value\"}); assert(doc.data is Map); final doc = new Document([0]); assert(doc.data is List); The data in a document can be accessed through its data property, or through its subscript operator. Document 's subscript operator forwards the invocation to its data property. final doc = new Document({\"key\": \"value\"}); assert(doc[\"key\"] == doc.data[\"key\"]); The argument to the subscript operator may be a string (if data is a map) or an integer (if data is a list).","title":"The Document Data Type"},{"location":"db/json_columns/#basic-operations-on-document-properties","text":"Document columns are like any other type of column, and can therefore be set during an insert or update, and read during a fetch.","title":"Basic Operations on Document Properties"},{"location":"db/json_columns/#inserting-rows-with-document-properties","text":"A Document property is first set when inserting with a Query<T> . The values property of the query is set to a Document object initialized with a JSON-encodable value. final query = Query<Event>(context) ..values.timestamp = DateTime.now() ..values.contents = Document({ \"type\": \"push\", \"user\": \"bob\", \"tags\": [\"v1\"] }); final event = await query.insert(); In the above, the argument to Document will be JSON-encoded and stored in the database for column contents . If the object can't be encoded as JSON, an exception will be thrown.","title":"Inserting Rows with Document Properties"},{"location":"db/json_columns/#fetching-rows-with-document-properties","text":"When fetching an object with Document properties with a Query<T> , you access the column's value through the document's data property. final query = Query<Event>(context) ..where((e) => e.id).equalTo(1); final event1 = await query.fetchOne(); event1.contents.data == { \"type\": \"push\", \"user\": \"bob\", \"tags\": [\"v1\"] }; When fetching Document properties, the JSON data is decoded into the appropriate type. This is likely a Map or List , but can be any JSON-encodable object. Because the data stored in a Document property is unstructured, the type of data is dynamic . It is good practice to store consistent data structures in a column; i.e., always storing a Map or always storing a List .","title":"Fetching Rows with Document Properties"},{"location":"db/json_columns/#updating-rows-with-document-properties","text":"Updating a row with Document properties works the same as inserting rows. final query = Query<Event>(context) ..where((e) => e.id).equalTo(1) ..values.contents = Document({ \"type\": \"push\", \"user\": \"bob\", \"tags\": [\"v1\", \"new\"] }); final event = await query.updateOne(); When updating in this way, the document stored in the column is replaced entirely.","title":"Updating Rows with Document Properties"},{"location":"db/json_columns/#accessing-document-values","text":"The type of Document.data is dynamic - it can be any valid JSON type and may be casted to the expected type when used. This data can also be nested - a List of Maps , for example. When accessing object keys or list indices, you may use the subscript operator directly on Document . // Object Access by key final doc = Document({\"key\": \"value\"}); final value = doc[\"key\"] == \"value\"; // List Access by index final doc = Document([\"v1\", \"v2\"]); final value = doc[0] == \"v1\"; You can access nested elements with the same syntax: final doc = Document([ {\"id\": 1}, {\"id\": 2} ]); final obj1 = doc[0][\"id\"]; // == 1 final obj2 = doc[1][\"id\"]; // == 2 Note that using the subscript operator on a Document simply invokes it on its data property. Therefore, any subscript values must be valid for Dart List and Map types.","title":"Accessing Document Values"},{"location":"db/json_columns/#fetching-sub-documents","text":"When fetching a Document property, the default behavior is to return the entire JSON document as it is stored in the database column. You may fetch parts of the document you need by using Query.returningProperties and the subscript operator. final query = Query<Event>(context) ..returningProperties((e) => [e.id, e.contents[\"tags\"]]); final eventsWithTags = query.fetch(); When using the subscript operator on a returned Document property, only the value for that key is returned. For example, if the above query were executed and the stored column's value were: { \"type\": \"push\", \"user\": \"bob\", \"tags\": [\"v1\"] } The value of Event.contents would only contain the array for the key \"tags\": [\"v1\"] You may also index arrays in a JSON column using the same subscript operator, and the subscript operator can also be nested. For example, the following query would fetch the \"tags\" array, and then fetch the string at index 0 from it: final query = Query<Event>(context) ..returningProperties((e) => [e.id, e.contents[\"tags\"][0]]); final eventsWithFirstTag = await query.fetchOne(); eventsWithFirstTag.contents.data == \"v1\"; If a key or index does not exist in the JSON document, the value of the returned property will be null. For this reason, you should use null-aware operators when accessing Document.data : final query = Query<Event>(context) ..returningProperties((e) => [e.id, e.contents[\"tags\"][7]]); // 7 is out of bounds final eventsWithFirstTag = await query.fetchOne(); if (eventsWithFirstTag.contents?.data == \"v1\") { ... } When fetching elements from a JSON array, you may use negative indices to specify a index from the end of the array. final query = Query<Event>(context) ..returningProperties((e) => [e.id, e.contents[\"tags\"][-1]]); final eventsWithLastTag = await query.fetchOne(); Note that you can only fetch a single sub-structure from a Document column per query. That is, you may not do the following: // Invalid final query = Query<Event>(context) ..returningProperties((e) => [e.id, e.contents[\"type\"], e.contents[\"user\"]]); For operations not supported by Query<T> , you may use SQL directly: final eventTagCounts = await context.persistentStore.execute(\"SELECT jsonb_array_length(contents->'tags') from _Event\");","title":"Fetching Sub-documents"},{"location":"db/modeling_data/","text":"Modeling Data In this guide, you will learn how to create types that are mapped to database tables. At the end of this guide are additional examples of data model types. Defining a Table In your application, you declare types whose instances are stored in a database. Each of these types is mapped to a database table, where each property of the type is a column of the table. For example, consider modeling newspaper articles, where each article has a unique identifier, text contents and published date: // This is a table definition of an 'article' class _Article { @Column(primaryKey: true) int id; String contents; @Column(indexed: true) DateTime publishedDate; } This plain Dart class is called a table definition because it defines a database table named _Article . The table has three columns, id , contents , publishedDate . An example of the data stored in this table might look like this: id contents publishedDate 1 Today, the local... 2018-02-01 00:00:00.000 2 In other news, ... 2018-03-01 04:30:00.000 A property in a table definition can optionally have a Column annotation. This annotation configures the behavior of the associated database column. If a property doesn't have an annotation, the column has default behavior. These behaviors are shown in the table below: Option Type Behavior Default primaryKey bool sets primary key column false (not primary key) databaseType ManagedPropertyType sets underlying column type inferred from Dart type nullable bool toggles whether column can be null false (not nullable) unique bool toggles whether column is unique across all rows false (not unique) defaultValue String provides default value for new rows when value is undefined null indexed bool whether an index should be created for the column false (no index) omitByDefault bool whether this column should be left out by default false (fetch column value) autoincrement bool whether this column's value is automatically generated from a series false (not generated) You must use either zero or one Column annotation per property, and you must set all behaviors in one annotation, e.g.: @Column(nullable: true, unique: true, indexed: true) int field; The data type of a column is inferred from the Dart type of the property as shown by the following table. Dart Type General Column Type PostgreSQL Column Type int integer number INT or SERIAL double floating point number DOUBLE PRECISION String text TEXT DateTime timestamp TIMESTAMP bool boolean BOOLEAN Document a JSON object or array JSONB Any enum text, restricted to enum cases TEXT Some types can be represented by many database types; for example, an integer can be stored as 2, 4 or 8 bytes. Use the databaseType of a Column annotation to specify: @Column(databaseType: ManagedPropertyType.bigInteger) int bigNumber; The only requirement of a table definition type is that it has exactly one primary key property. A primary key is an indexed, unique identifier for a database row and is set through the Column annotation. @Column(primaryKey: true) int id; A primary key can be any supported data type, and it is always unique and indexed. It is common for primary keys to be 64-bit, auto-incrementing integers. The primaryKey constant exists as a convenience for a Column with these behaviors. class _Article { @primaryKey // equivalent to @Column(primaryKey: true, databaseType: ManagedPropertyType.bigInteger, autoincrement: true) int id; ... } !!! note \"Creating Tables\" Tables are created in a database by using the conduit command line tool to generate and execute migration scripts. The tool inspects your database types and automatically synchronizes a databases schema to match your them. By default, the name of the table definition is the name of the database table. You can configure this with the Table annotation. @Table(name: \"ArticleTable\") class _Article { @primaryKey int id; String contents; @Column(indexed: true) DateTime publishedDate; } It is convention that table definitions are private classes , that is, their name is prefixed with an underscore ( _ ). This convention is discussed later in this guide. Defining a Managed Object Subclass A table definition by itself is just a plain Dart class. You must also declare a ManagedObject subclass to bring your table definition to life. Here's an example: class Article extends ManagedObject<_Article> implements _Article {} A managed object subclass, also called the instance type , is the object type that you work with in your application code. For example, when you fetch rows from a database, you will get a list of managed objects. A managed object subclass declares its table definition in two places: once as the type argument of its superclass, and again as an interface it implements. A managed object subclass inherits all of the properties from its table definition; i.e., an Article has an id , contents and publishedDate because _Article declares those properties. You create and use instances of a managed object subclass like any other object: final article = new Article(); article.text = \"Today, ...\"; article.publishedDate = DateTime.now(); !!! warning \"Managed Object Constructors\" You can add new constructors to a managed object subclass, but you must always have a default, no-argument constructor. This default constructor is used when the ORM creates instances from rows in your database. Modeling Relationships A managed object can have relationships to other managed objects. For example, an author can have many books, an article can belong to a newspaper, and an employee can have a manager. In a relational database, relationships between tables are established by storing the primary key of a table row in a column of the related table. This column is a foreign key reference to the related table. When a table has a foreign key reference, it is said to belong to the related table. In the example of an employee and manager, the employee belongs to the manager and therefore the employee table has a foreign key reference to the manager table. The inverse of this statement is also true: a manager has employees. A manager has-many employees - this is called a has-many relationship . There are also has-one relationships - for example, a country has-one capital. The following is an example of a country and a has-one relationship to a capital city: class City extends ManagedObject<_City> implements _City {} class _City { @primaryKey int id; @Relate(#capital) Country country; } class Country extends ManagedObject<_Country> implements _Country {} class _Country { @primaryKey int id; City capital; } A relationship is formed between two tables by declaring properties in both table definition types. The type of those properties is the related managed object subclass - so a Country has a property of type City , and a City has a property of type Country . Exactly one of those properties must have a Relate annotation. The Relate annotation designates the underlying column as a foreign key column. In this example, the city table has a foreign key column to the country table. Conceptually, then, a city belongs to a country and a country has-one capital city. A city can only belong to one country through this relationship, and that is true of all belongs-to relationship properties. !!! note \"Foreign Key Column Names\" A foreign key column in the database is named by joining the name of the relationship property and the primary key of the related table with an underscore. For example, the column in the city table is named country_id . The property without Relate is the inverse of the relationship and is conceptually either a has-one or has-many relationship property. In this example, a country's relationship to its capital is has-one. A relationship is has-many when the type of the inverse property is a ManagedSet . For example, if we wanted to model a relationship between a country and all of its cities, we'd declare a ManagedSet<City> property in the country: class City extends ManagedObject<_City> implements _City {} class _City { ... @Relate(#cities) Country country; } class Country extends ManagedObject<_Country> implements _Country {} class _Country { ... ManagedSet<City> cities; } !!! note \"ManagedSet Behavior\" A Relate property can never be a ManagedSet . A ManagedSet is a List , and therefore can be used in the same way a list is used. Notice that the Relate annotation takes at least one argument: a symbol that matches the name of the inverse property. This is what links two relationship properties to each other. In the first example, this argument was #capital because the name of the inverse property is capital ; likewise, #cities and cities . This pairing name must match or an error will be thrown. !!! note \"Symbols\" A symbol is a name identifier in Dart; a symbol can refer to a class, method, or property. The #name syntax is a symbol literal . The Relate annotation has optional arguments to further define the relationship. Like Column , these are optional arguments, e.g.: @Relate(#cities, isRequired: true, onDelete: DeleteRule.cascade) A relationship may be be required or optional. For example, if City.country were required, then a City must always have a Country . By default, relationships are optional. A relationship has a delete rule. When an object is deleted, any objects that belong to its relationships are subject to this rule. The following table shows the rules and their behavior: Rule Behavior Example nullify (default) inverse is set to null When deleting an author, its articles' author becomes null cascade related objects are also deleted When deleting an author, its articles are deleted restrict delete fails When attempting to delete an author with articles, the delete operation fails default inverse set to a default value When deleting an author, its articles author is set to the default value of the column Special Behaviors Enum Types Enums types can be used to declare properties in a table definition. The database will store the column as a string representation of the enumeration. Here's an example where a user can be an administrator or a normal user: enum UserType { admin, user } class User extends ManagedObject<_User> implements _User {} class _User { @primaryKey int id; String name; UserType role; } var query = Query<User>(context) ..values.name = \"Bob\" ..values.role = UserType.admin; final bob = await query.insert(); query = Query<User>(context) ..where((u) => u.role).equalTo(UserType.admin); final allAdmins = await query.fetch(); In the database, the role column is stored as a string. Its value is either \"admin\" or \"user\". Private Variables A private variable in a table definition removes it from the serialized representation of an object. A private variable is always fetched when making a database query, but it is not read when invoking read and is not written when invoking asMap . Both of these methods are invoked when reading a managed object from a request body, or writing it to a response body. Transient Properties Properties declared in a managed object subclass are called transient because they are not stored in a database. For example, consider an Author type that stores first and last name as separate columns. Instead of redundantly storing a 'full name' in the database, a transient property can combine the first and last name: class Author extends ManagedObject<_Author> implements _Author { String get name => \"$firstName $lastName\"; set name(String fullName) { firstName = fullName.split(\" \").first; lastName = fullName.split(\" \").last; } } class _Author { @primaryKey int id; String firstName; String lastName; } By default, a transient property is ignored when reading an object from a request body or writing the object to a response body (see the guide on serialization for more details). You can annotate a transient property with Serialize so that it is able to be read from a request body, written to a response body, or both. For example: class Author extends ManagedObject<_Author> implements _Author { @Serialize() String get name => \"$firstName $lastName\"; @Serialize() set name(String fullName) { firstName = fullName.split(\" \").first; lastName = fullName.split(\" \").last; } } You may declare getters, setters and properties to be serialized in this way. When declaring a property, you can control it with arguments to Serialize : class Author extends ManagedObject<_Author> implements _Author { @Serialize(input: false, output: true) bool isCurrentlyPromoted; } Project File Structure A managed object subclass and its table definition together are called an entity . Each entity should be declared in the same file, and the table definition should be prefixed with an _ to prevent it from being used elsewhere in the project. It is preferable to declare one entity per file, and store all entities in the lib/model/ directory of your project. The files your model definitions are declared in must be visible to Conduit tooling. In normal circumstances, this happens automatically because of the following: Conduit tooling can find any file that is imported (directly or transitively) from your library file. Your library file, by default, can see the file your ApplicationChannel is declared in. Your application channel file must import any controller that it links. Your controllers must import any model file they use. When you use the conduit CLI to generate database migration scripts, it will report all of the ManagedObject s in your application that it was able to find. If a particular type is not listed, it may reveal that you aren't using that type. If you need to ensure that the tooling can see a particular model file that it is not locating, you may import it in your channel.dart file. Examples Example: One-to-Many Relationship An author has many books: class Author extends ManagedObject<_Author> implements _Author {} class _Author { @primaryKey int id; String name; ManagedSet<Book> books; } class Book extends ManagedObject<_Book> implements _Book {} class _Book { @primaryKey int id; String name; @Relate(#books) Author author; } To insert an author and a book associated with that author: final authorQuery = Query<Author>(context) ..values.name = \"Fred\"; final author = await authorQuery.insert(); final bookQuery = Query<Book>(context) ..values.name = \"Title\" ..values.author.id = author.id; final book = await bookQuery.insert(); To fetch authors and their books: final query = Query<Author>(context) ..join(set: (a) => a.books); final authors = await query.fetch(); To fetch a book and their full author object: final query = Query<Book>(context) ..where((b) => b.id).equalTo(1) ..join(object: (a) => a.author); final books = await query.fetch(); Example: One-to-One Relationship class Country extends ManagedObject<_Country> implements _Country {} class _Country { @primaryKey int id; String name; City capital; } class City extends ManagedObject<_City> implements _City {} class _City { @primaryKey int id; String name; @Relate(#capital) Country country; } To fetch a country and its capital: final query = Query<Country>(context) ..where((c) => c.id).equalTo(1) ..join(object: (a) => a.capital); final countries = await query.fetch(); Example: Many-to-Many Relationship class Team extends ManagedObject<_Team> implements _Team {} class _Team { @primaryKey int id; String name; ManagedSet<TeamPlayer> teamPlayers; } // This type is a join table class TeamPlayer extends ManagedObject<_TeamPlayer> implements _TeamPlayer {} class _TeamPlayer { @primaryKey int id; @Relate(#teamPlayers) Team team; @Relate(#teamPlayers) Player player; } class Player extends ManagedObject<_Player> implements _Player {} class _Player { @primaryKey int id; String name; ManagedSet<TeamPlayer> teamPlayers; } To fetch a team and its players: // Note that the final join is not cascaded from the Team query, // but from the Query created by joining with TeamPlayer final query = Query<Team>(context) ..where((t) => t.id).equalTo(1) ..join(set: (t) => t.teamPlayers).join(object: (tp) => tp.player); final team = await query.fetchOne(); The structure of this object is: { \"id\": 1, \"name\": \"Badgers\", \"teamPlayers\": [ { \"id\": 1, \"team\": { \"id\": 1 }, \"player\": { \"id\": 1, \"name\": \"Fred\" } } ] } You can flatten this structure in a number of ways. In the simplest form, add a Serialize -annotated transient property to the ManagedObject subclass, and each time you fetch, remove the join table from the object and place the players in the transient property. class Team extends ManagedObject<_Team> implements _Team { @Serialize(input: false, output: true) List<Map<String, dynamic>> players; } final team = ...; team.players = team.teamPlayers.map((t) => t.player.asMap()).toList(); // Remove teamPlayers; it is redundant team.backing.removeProperty(\"teamPlayers\"); Example: Hierarchical Relationships (Self Referencing) Hierarchical relationships follow the same rules as all other relationship, but declare the foreign key property and the inverse in the same type. class Person extends ManagedObject<_Person> implements _Person {} class _Person { @primaryKey int id; String name; ManagedSet<Person> children; @Relate(#children) Person parent; }","title":"Modeling Data and Relationships"},{"location":"db/modeling_data/#modeling-data","text":"In this guide, you will learn how to create types that are mapped to database tables. At the end of this guide are additional examples of data model types.","title":"Modeling Data"},{"location":"db/modeling_data/#defining-a-table","text":"In your application, you declare types whose instances are stored in a database. Each of these types is mapped to a database table, where each property of the type is a column of the table. For example, consider modeling newspaper articles, where each article has a unique identifier, text contents and published date: // This is a table definition of an 'article' class _Article { @Column(primaryKey: true) int id; String contents; @Column(indexed: true) DateTime publishedDate; } This plain Dart class is called a table definition because it defines a database table named _Article . The table has three columns, id , contents , publishedDate . An example of the data stored in this table might look like this: id contents publishedDate 1 Today, the local... 2018-02-01 00:00:00.000 2 In other news, ... 2018-03-01 04:30:00.000 A property in a table definition can optionally have a Column annotation. This annotation configures the behavior of the associated database column. If a property doesn't have an annotation, the column has default behavior. These behaviors are shown in the table below: Option Type Behavior Default primaryKey bool sets primary key column false (not primary key) databaseType ManagedPropertyType sets underlying column type inferred from Dart type nullable bool toggles whether column can be null false (not nullable) unique bool toggles whether column is unique across all rows false (not unique) defaultValue String provides default value for new rows when value is undefined null indexed bool whether an index should be created for the column false (no index) omitByDefault bool whether this column should be left out by default false (fetch column value) autoincrement bool whether this column's value is automatically generated from a series false (not generated) You must use either zero or one Column annotation per property, and you must set all behaviors in one annotation, e.g.: @Column(nullable: true, unique: true, indexed: true) int field; The data type of a column is inferred from the Dart type of the property as shown by the following table. Dart Type General Column Type PostgreSQL Column Type int integer number INT or SERIAL double floating point number DOUBLE PRECISION String text TEXT DateTime timestamp TIMESTAMP bool boolean BOOLEAN Document a JSON object or array JSONB Any enum text, restricted to enum cases TEXT Some types can be represented by many database types; for example, an integer can be stored as 2, 4 or 8 bytes. Use the databaseType of a Column annotation to specify: @Column(databaseType: ManagedPropertyType.bigInteger) int bigNumber; The only requirement of a table definition type is that it has exactly one primary key property. A primary key is an indexed, unique identifier for a database row and is set through the Column annotation. @Column(primaryKey: true) int id; A primary key can be any supported data type, and it is always unique and indexed. It is common for primary keys to be 64-bit, auto-incrementing integers. The primaryKey constant exists as a convenience for a Column with these behaviors. class _Article { @primaryKey // equivalent to @Column(primaryKey: true, databaseType: ManagedPropertyType.bigInteger, autoincrement: true) int id; ... } !!! note \"Creating Tables\" Tables are created in a database by using the conduit command line tool to generate and execute migration scripts. The tool inspects your database types and automatically synchronizes a databases schema to match your them. By default, the name of the table definition is the name of the database table. You can configure this with the Table annotation. @Table(name: \"ArticleTable\") class _Article { @primaryKey int id; String contents; @Column(indexed: true) DateTime publishedDate; } It is convention that table definitions are private classes , that is, their name is prefixed with an underscore ( _ ). This convention is discussed later in this guide.","title":"Defining a Table"},{"location":"db/modeling_data/#defining-a-managed-object-subclass","text":"A table definition by itself is just a plain Dart class. You must also declare a ManagedObject subclass to bring your table definition to life. Here's an example: class Article extends ManagedObject<_Article> implements _Article {} A managed object subclass, also called the instance type , is the object type that you work with in your application code. For example, when you fetch rows from a database, you will get a list of managed objects. A managed object subclass declares its table definition in two places: once as the type argument of its superclass, and again as an interface it implements. A managed object subclass inherits all of the properties from its table definition; i.e., an Article has an id , contents and publishedDate because _Article declares those properties. You create and use instances of a managed object subclass like any other object: final article = new Article(); article.text = \"Today, ...\"; article.publishedDate = DateTime.now(); !!! warning \"Managed Object Constructors\" You can add new constructors to a managed object subclass, but you must always have a default, no-argument constructor. This default constructor is used when the ORM creates instances from rows in your database.","title":"Defining a Managed Object Subclass"},{"location":"db/modeling_data/#modeling-relationships","text":"A managed object can have relationships to other managed objects. For example, an author can have many books, an article can belong to a newspaper, and an employee can have a manager. In a relational database, relationships between tables are established by storing the primary key of a table row in a column of the related table. This column is a foreign key reference to the related table. When a table has a foreign key reference, it is said to belong to the related table. In the example of an employee and manager, the employee belongs to the manager and therefore the employee table has a foreign key reference to the manager table. The inverse of this statement is also true: a manager has employees. A manager has-many employees - this is called a has-many relationship . There are also has-one relationships - for example, a country has-one capital. The following is an example of a country and a has-one relationship to a capital city: class City extends ManagedObject<_City> implements _City {} class _City { @primaryKey int id; @Relate(#capital) Country country; } class Country extends ManagedObject<_Country> implements _Country {} class _Country { @primaryKey int id; City capital; } A relationship is formed between two tables by declaring properties in both table definition types. The type of those properties is the related managed object subclass - so a Country has a property of type City , and a City has a property of type Country . Exactly one of those properties must have a Relate annotation. The Relate annotation designates the underlying column as a foreign key column. In this example, the city table has a foreign key column to the country table. Conceptually, then, a city belongs to a country and a country has-one capital city. A city can only belong to one country through this relationship, and that is true of all belongs-to relationship properties. !!! note \"Foreign Key Column Names\" A foreign key column in the database is named by joining the name of the relationship property and the primary key of the related table with an underscore. For example, the column in the city table is named country_id . The property without Relate is the inverse of the relationship and is conceptually either a has-one or has-many relationship property. In this example, a country's relationship to its capital is has-one. A relationship is has-many when the type of the inverse property is a ManagedSet . For example, if we wanted to model a relationship between a country and all of its cities, we'd declare a ManagedSet<City> property in the country: class City extends ManagedObject<_City> implements _City {} class _City { ... @Relate(#cities) Country country; } class Country extends ManagedObject<_Country> implements _Country {} class _Country { ... ManagedSet<City> cities; } !!! note \"ManagedSet Behavior\" A Relate property can never be a ManagedSet . A ManagedSet is a List , and therefore can be used in the same way a list is used. Notice that the Relate annotation takes at least one argument: a symbol that matches the name of the inverse property. This is what links two relationship properties to each other. In the first example, this argument was #capital because the name of the inverse property is capital ; likewise, #cities and cities . This pairing name must match or an error will be thrown. !!! note \"Symbols\" A symbol is a name identifier in Dart; a symbol can refer to a class, method, or property. The #name syntax is a symbol literal . The Relate annotation has optional arguments to further define the relationship. Like Column , these are optional arguments, e.g.: @Relate(#cities, isRequired: true, onDelete: DeleteRule.cascade) A relationship may be be required or optional. For example, if City.country were required, then a City must always have a Country . By default, relationships are optional. A relationship has a delete rule. When an object is deleted, any objects that belong to its relationships are subject to this rule. The following table shows the rules and their behavior: Rule Behavior Example nullify (default) inverse is set to null When deleting an author, its articles' author becomes null cascade related objects are also deleted When deleting an author, its articles are deleted restrict delete fails When attempting to delete an author with articles, the delete operation fails default inverse set to a default value When deleting an author, its articles author is set to the default value of the column","title":"Modeling Relationships"},{"location":"db/modeling_data/#special-behaviors","text":"","title":"Special Behaviors"},{"location":"db/modeling_data/#enum-types","text":"Enums types can be used to declare properties in a table definition. The database will store the column as a string representation of the enumeration. Here's an example where a user can be an administrator or a normal user: enum UserType { admin, user } class User extends ManagedObject<_User> implements _User {} class _User { @primaryKey int id; String name; UserType role; } var query = Query<User>(context) ..values.name = \"Bob\" ..values.role = UserType.admin; final bob = await query.insert(); query = Query<User>(context) ..where((u) => u.role).equalTo(UserType.admin); final allAdmins = await query.fetch(); In the database, the role column is stored as a string. Its value is either \"admin\" or \"user\".","title":"Enum Types"},{"location":"db/modeling_data/#private-variables","text":"A private variable in a table definition removes it from the serialized representation of an object. A private variable is always fetched when making a database query, but it is not read when invoking read and is not written when invoking asMap . Both of these methods are invoked when reading a managed object from a request body, or writing it to a response body.","title":"Private Variables"},{"location":"db/modeling_data/#transient-properties","text":"Properties declared in a managed object subclass are called transient because they are not stored in a database. For example, consider an Author type that stores first and last name as separate columns. Instead of redundantly storing a 'full name' in the database, a transient property can combine the first and last name: class Author extends ManagedObject<_Author> implements _Author { String get name => \"$firstName $lastName\"; set name(String fullName) { firstName = fullName.split(\" \").first; lastName = fullName.split(\" \").last; } } class _Author { @primaryKey int id; String firstName; String lastName; } By default, a transient property is ignored when reading an object from a request body or writing the object to a response body (see the guide on serialization for more details). You can annotate a transient property with Serialize so that it is able to be read from a request body, written to a response body, or both. For example: class Author extends ManagedObject<_Author> implements _Author { @Serialize() String get name => \"$firstName $lastName\"; @Serialize() set name(String fullName) { firstName = fullName.split(\" \").first; lastName = fullName.split(\" \").last; } } You may declare getters, setters and properties to be serialized in this way. When declaring a property, you can control it with arguments to Serialize : class Author extends ManagedObject<_Author> implements _Author { @Serialize(input: false, output: true) bool isCurrentlyPromoted; }","title":"Transient Properties"},{"location":"db/modeling_data/#project-file-structure","text":"A managed object subclass and its table definition together are called an entity . Each entity should be declared in the same file, and the table definition should be prefixed with an _ to prevent it from being used elsewhere in the project. It is preferable to declare one entity per file, and store all entities in the lib/model/ directory of your project. The files your model definitions are declared in must be visible to Conduit tooling. In normal circumstances, this happens automatically because of the following: Conduit tooling can find any file that is imported (directly or transitively) from your library file. Your library file, by default, can see the file your ApplicationChannel is declared in. Your application channel file must import any controller that it links. Your controllers must import any model file they use. When you use the conduit CLI to generate database migration scripts, it will report all of the ManagedObject s in your application that it was able to find. If a particular type is not listed, it may reveal that you aren't using that type. If you need to ensure that the tooling can see a particular model file that it is not locating, you may import it in your channel.dart file.","title":"Project File Structure"},{"location":"db/modeling_data/#examples","text":"","title":"Examples"},{"location":"db/modeling_data/#example-one-to-many-relationship","text":"An author has many books: class Author extends ManagedObject<_Author> implements _Author {} class _Author { @primaryKey int id; String name; ManagedSet<Book> books; } class Book extends ManagedObject<_Book> implements _Book {} class _Book { @primaryKey int id; String name; @Relate(#books) Author author; } To insert an author and a book associated with that author: final authorQuery = Query<Author>(context) ..values.name = \"Fred\"; final author = await authorQuery.insert(); final bookQuery = Query<Book>(context) ..values.name = \"Title\" ..values.author.id = author.id; final book = await bookQuery.insert(); To fetch authors and their books: final query = Query<Author>(context) ..join(set: (a) => a.books); final authors = await query.fetch(); To fetch a book and their full author object: final query = Query<Book>(context) ..where((b) => b.id).equalTo(1) ..join(object: (a) => a.author); final books = await query.fetch();","title":"Example: One-to-Many Relationship"},{"location":"db/modeling_data/#example-one-to-one-relationship","text":"class Country extends ManagedObject<_Country> implements _Country {} class _Country { @primaryKey int id; String name; City capital; } class City extends ManagedObject<_City> implements _City {} class _City { @primaryKey int id; String name; @Relate(#capital) Country country; } To fetch a country and its capital: final query = Query<Country>(context) ..where((c) => c.id).equalTo(1) ..join(object: (a) => a.capital); final countries = await query.fetch();","title":"Example: One-to-One Relationship"},{"location":"db/modeling_data/#example-many-to-many-relationship","text":"class Team extends ManagedObject<_Team> implements _Team {} class _Team { @primaryKey int id; String name; ManagedSet<TeamPlayer> teamPlayers; } // This type is a join table class TeamPlayer extends ManagedObject<_TeamPlayer> implements _TeamPlayer {} class _TeamPlayer { @primaryKey int id; @Relate(#teamPlayers) Team team; @Relate(#teamPlayers) Player player; } class Player extends ManagedObject<_Player> implements _Player {} class _Player { @primaryKey int id; String name; ManagedSet<TeamPlayer> teamPlayers; } To fetch a team and its players: // Note that the final join is not cascaded from the Team query, // but from the Query created by joining with TeamPlayer final query = Query<Team>(context) ..where((t) => t.id).equalTo(1) ..join(set: (t) => t.teamPlayers).join(object: (tp) => tp.player); final team = await query.fetchOne(); The structure of this object is: { \"id\": 1, \"name\": \"Badgers\", \"teamPlayers\": [ { \"id\": 1, \"team\": { \"id\": 1 }, \"player\": { \"id\": 1, \"name\": \"Fred\" } } ] } You can flatten this structure in a number of ways. In the simplest form, add a Serialize -annotated transient property to the ManagedObject subclass, and each time you fetch, remove the join table from the object and place the players in the transient property. class Team extends ManagedObject<_Team> implements _Team { @Serialize(input: false, output: true) List<Map<String, dynamic>> players; } final team = ...; team.players = team.teamPlayers.map((t) => t.player.asMap()).toList(); // Remove teamPlayers; it is redundant team.backing.removeProperty(\"teamPlayers\");","title":"Example: Many-to-Many Relationship"},{"location":"db/modeling_data/#example-hierarchical-relationships-self-referencing","text":"Hierarchical relationships follow the same rules as all other relationship, but declare the foreign key property and the inverse in the same type. class Person extends ManagedObject<_Person> implements _Person {} class _Person { @primaryKey int id; String name; ManagedSet<Person> children; @Relate(#children) Person parent; }","title":"Example: Hierarchical Relationships (Self Referencing)"},{"location":"db/mysql/","text":"MySql Note: this is not as yet a released feature. example: aqueduct db upgrade --connect mysql://username:password@host:port/databaseName or setting database.yaml : schema: postgres|mysql host: host port: port username: username password: password databaseName: databaseName MySqlPersistentStore : final MySqlPersistentStore persistentStore = MySqlPersistentStore( _config.database.username, _config.database.password, _config.database.host, _config.database.port, _config.database.databaseName); context = ManagedContext(dataModel, persistentStore); /// ...... final query = Query<User>(context,values: user) ..where((o) => o.username).equalTo(user.username); final res = await query.delete(); /// ...... Support setting field size class _User extends ResourceOwnerTableDefinition { @Column(size: 11) String mobile; @override @Column(unique: true, indexed: true, size: 20) String username; }","title":"MySql"},{"location":"db/mysql/#mysql","text":"Note: this is not as yet a released feature. example: aqueduct db upgrade --connect mysql://username:password@host:port/databaseName or setting database.yaml : schema: postgres|mysql host: host port: port username: username password: password databaseName: databaseName MySqlPersistentStore : final MySqlPersistentStore persistentStore = MySqlPersistentStore( _config.database.username, _config.database.password, _config.database.host, _config.database.port, _config.database.databaseName); context = ManagedContext(dataModel, persistentStore); /// ...... final query = Query<User>(context,values: user) ..where((o) => o.username).equalTo(user.username); final res = await query.delete(); /// ...... Support setting field size class _User extends ResourceOwnerTableDefinition { @Column(size: 11) String mobile; @override @Column(unique: true, indexed: true, size: 20) String username; }","title":"MySql"},{"location":"db/serialization/","text":"ManagedObject Serialization and Deserialization In this guide, you will learn how ManagedObject<T> s are read from HTTP request bodies and written to HTTP response bodies. Basic Conversion A ManagedObject<T> can be converted to and from Map<String, dynamic> objects. Each key is the name of a property in the object. To decode a ManagedObject into a Map , call its read method: final object = MyManagedObject(); object.read({ \"key\": \"value\" }); // object.key == \"value\" Validation exceptions (status code: 400) are thrown is the input data is invalid: if a key doesn't have a corresponding property, the type of a value does not match the expected type or some constraint of the managed object is violated. Filters can be applied to keys of the object being read. Filters can ignore keys, require keys or throw an exception if a key is present. Here is an example, where the read will throw an exception because 'id' is required but not provided: object.read({ \"key\": \"value\" }, require: [\"id\"]); !!! tip \"ManagedObjects inherit Serializable\" The read method and its filters are inherited from Serializable and are discussed in more detail here . Managed objects, like serializables, can be bound to operation method parameters. Managed objects have a list of default keys that can be used as a base filter set: object.read({}, require: object.entity.defaultProperties); To serialize a managed object into a map, use the instance method asMap : final object = MyManagedObject(); Map<String, dynamic> map = object.asMap(); If a property has not been set on the object, it will not be written to the map. The values of a Map equivalent of a managed object are always primitive values that can be encoded as JSON, sent across an isolate, etc. The following shows a table of the serialization format: Dart Type Serialized Type int number ( int ) double number ( double ) String string ( String ) DateTime ISO 8601 Timestamp ( String ) bool boolean ( bool ) Document map or list ( Map<String, dynamic> or List<dynamic> ) Any enum string ( String ) Belongs-To or Has-One Relationship map ( Map<String, dynamic> ) Has-Many Relationship list of maps ( List<Map<String, dynamic>> ) Behavior of Null Values A property of a managed object can be null for two reasons: the value is actually null, or the value is not available. For example, when you create a new instance of a managed object, none of its values are available (the object is empty). When encoding an object into a map, only the available values are included and the keys for any unavailable properties are omitted: final myObject = MyManagedObject(); // empty object myObject.asMap() == {}; // true myObject.id = 1; myObject.asMap() == { \"id\": 1 }; // true A value in managed object's asMap will only be null if the property value truly is null: myObject.id = null; myObject.asMap() == { \"id\": null }; // true A property value becomes available when it is set through an accessor, when using read , or when returning objects from a query. Behavior of Transient Properties By default, transient properties - those declared in the managed object subclass, not the table definition - are not included in an object's asMap() . The Serialize annotation allows a transient property to be included in this map. class Employee extends ManagedObject<_Employee> implements _Employee { int a; // NOT included in asMap, NOT read in read @Serialize() int b; // included in asMap, read in read @Serialize(input: true, output: false) int c; // NOT included in asMap, read in read @Serialize(input: false, output: true) int d; // included in asMap, NOT read in read } class _Employee { @primaryKey int id; } A separate getter and setter may exist instead of a property. With this annotation, getters are added to asMap and setters will be input for read . class User extends ManagedObject<_User> implements _User { @Serialize() set transientValue(String s) { ... } @Serialize() String get transientValue => ...; } A transient property's key will not be present in asMap() if its value is null. Behavior of Relationship Properties When a managed object is encoded, relationship properties are represented as maps (for belongs-to or has-one relationships) or a list of maps (for has-many relationships). The same rules for property availability apply to relationship properties. The following shows an example map that mirrors a managed object with aptly named relationship properties: { \"id\": 1, \"belongsTo\": { \"id\": 1 }, \"hasOne\": { \"id\": 2, \"name\": \"Fred\" }, \"hasMany\": [ {\"id\": 3, \"name\": \"Bob\"}, {\"id\": 4, \"name\": \"Joe\"}, ] } A belongs-to relationship is always a map. This is important for client applications that will often create or update an object's belongs-to relationships. For example, a client wishing to create a child named Timmy with the parent that has id == 1 would send the following JSON: { \"name\": \"Timmy\", \"parent\": { \"id\": 1 } } This is different from some frameworks that would flatten this structure, e.g.: { \"name\": \"Timmy\", \"parent_id\": 1 }","title":"Serialization and Deserialization"},{"location":"db/serialization/#managedobject-serialization-and-deserialization","text":"In this guide, you will learn how ManagedObject<T> s are read from HTTP request bodies and written to HTTP response bodies.","title":"ManagedObject Serialization and Deserialization"},{"location":"db/serialization/#basic-conversion","text":"A ManagedObject<T> can be converted to and from Map<String, dynamic> objects. Each key is the name of a property in the object. To decode a ManagedObject into a Map , call its read method: final object = MyManagedObject(); object.read({ \"key\": \"value\" }); // object.key == \"value\" Validation exceptions (status code: 400) are thrown is the input data is invalid: if a key doesn't have a corresponding property, the type of a value does not match the expected type or some constraint of the managed object is violated. Filters can be applied to keys of the object being read. Filters can ignore keys, require keys or throw an exception if a key is present. Here is an example, where the read will throw an exception because 'id' is required but not provided: object.read({ \"key\": \"value\" }, require: [\"id\"]); !!! tip \"ManagedObjects inherit Serializable\" The read method and its filters are inherited from Serializable and are discussed in more detail here . Managed objects, like serializables, can be bound to operation method parameters. Managed objects have a list of default keys that can be used as a base filter set: object.read({}, require: object.entity.defaultProperties); To serialize a managed object into a map, use the instance method asMap : final object = MyManagedObject(); Map<String, dynamic> map = object.asMap(); If a property has not been set on the object, it will not be written to the map. The values of a Map equivalent of a managed object are always primitive values that can be encoded as JSON, sent across an isolate, etc. The following shows a table of the serialization format: Dart Type Serialized Type int number ( int ) double number ( double ) String string ( String ) DateTime ISO 8601 Timestamp ( String ) bool boolean ( bool ) Document map or list ( Map<String, dynamic> or List<dynamic> ) Any enum string ( String ) Belongs-To or Has-One Relationship map ( Map<String, dynamic> ) Has-Many Relationship list of maps ( List<Map<String, dynamic>> )","title":"Basic Conversion"},{"location":"db/serialization/#behavior-of-null-values","text":"A property of a managed object can be null for two reasons: the value is actually null, or the value is not available. For example, when you create a new instance of a managed object, none of its values are available (the object is empty). When encoding an object into a map, only the available values are included and the keys for any unavailable properties are omitted: final myObject = MyManagedObject(); // empty object myObject.asMap() == {}; // true myObject.id = 1; myObject.asMap() == { \"id\": 1 }; // true A value in managed object's asMap will only be null if the property value truly is null: myObject.id = null; myObject.asMap() == { \"id\": null }; // true A property value becomes available when it is set through an accessor, when using read , or when returning objects from a query.","title":"Behavior of Null Values"},{"location":"db/serialization/#behavior-of-transient-properties","text":"By default, transient properties - those declared in the managed object subclass, not the table definition - are not included in an object's asMap() . The Serialize annotation allows a transient property to be included in this map. class Employee extends ManagedObject<_Employee> implements _Employee { int a; // NOT included in asMap, NOT read in read @Serialize() int b; // included in asMap, read in read @Serialize(input: true, output: false) int c; // NOT included in asMap, read in read @Serialize(input: false, output: true) int d; // included in asMap, NOT read in read } class _Employee { @primaryKey int id; } A separate getter and setter may exist instead of a property. With this annotation, getters are added to asMap and setters will be input for read . class User extends ManagedObject<_User> implements _User { @Serialize() set transientValue(String s) { ... } @Serialize() String get transientValue => ...; } A transient property's key will not be present in asMap() if its value is null.","title":"Behavior of Transient Properties"},{"location":"db/serialization/#behavior-of-relationship-properties","text":"When a managed object is encoded, relationship properties are represented as maps (for belongs-to or has-one relationships) or a list of maps (for has-many relationships). The same rules for property availability apply to relationship properties. The following shows an example map that mirrors a managed object with aptly named relationship properties: { \"id\": 1, \"belongsTo\": { \"id\": 1 }, \"hasOne\": { \"id\": 2, \"name\": \"Fred\" }, \"hasMany\": [ {\"id\": 3, \"name\": \"Bob\"}, {\"id\": 4, \"name\": \"Joe\"}, ] } A belongs-to relationship is always a map. This is important for client applications that will often create or update an object's belongs-to relationships. For example, a client wishing to create a child named Timmy with the parent that has id == 1 would send the following JSON: { \"name\": \"Timmy\", \"parent\": { \"id\": 1 } } This is different from some frameworks that would flatten this structure, e.g.: { \"name\": \"Timmy\", \"parent_id\": 1 }","title":"Behavior of Relationship Properties"},{"location":"db/transactions/","text":"Database Transactions Learn how to execute multiple Query<T> s in a database transaction. Transactions A transaction is a series of queries that are executed together. If one of the queries in that set fails, then all of the queries fail and their changes are reversed if they had already been executed. Consider an application that stores employee records. Each employee belongs to a department. Management decides to combine two departments into a totally new department. To do this, the application must insert a new department, set each employee's foreign key reference to that department, and then delete the old departments. An straightforward (but problematic) implementation would look like this: // Create the new department final newDepartment = await ctx.insertObject(Department()..name = \"New Department\"); // Set employee's departments to the new one final changeDepartmentQuery = Query<Employee>(ctx) ..where((e) => e.department.id).oneOf([1, 2]) ..values.department.id = newDepartment.id; await changeDepartmentQuery.update(); // Delete the old ones final deleteDepartmentQuery = Query<Department>(ctx) ..where((e) => e.department.id).oneOf([1, 2]); await deleteDepartmentQuery.delete(); This change to your database is three separate queries, but they all most complete for the 'transfer' to be successful. If one of them fails, our database can be left in an inconsistent state. For example, if deleting the departments succeeds, but the employees failed to be transferred to the new department, then a lot of employees would be without a department. A database transaction combines queries together as a single unit. If a query in a transaction fails, the previous queries in that transaction are reverted and the remaining queries are aborted. You create transactions by invoking ManagedContext.transaction and writing your queries in its closure argument. await context.transaction((transaction) async { // note that 'transaction' is the context for each of these queries. final newDepartment = await transaction.insertObject(Department()..name = \"New Department\"); final changeDepartmentQuery = Query<Employee>(transaction) ..where((e) => e.department.id).oneOf([1, 2]) ..values.department.id = newDepartment.id; await changeDepartmentQuery.update(); final deleteDepartmentQuery = Query<Department>(transaction) ..where((e) => e.department.id).oneOf([1, 2]); await deleteDepartmentQuery.delete(); }); The closure has a transaction object that all queries in the transaction must use as their context. Queries that use this transaction context will be grouped in the same transaction. Once they have all succeeded, the transaction method's future completes. If an exception is thrown in the closure, the transaction is rolled back and the transaction method re-throws that exception. !!! warning \"Failing to Use the Transaction Context will Deadlock your Application\" If you use the transaction's parent context in a query inside a transaction closure, the database connection will deadlock and will stop working. Returning Values The value returned from a transaction closure is returned to the caller, so values created within the transaction closure can escape its scope. final employees = [...]; final insertedEmployees = await context.transaction((transaction) async { return Future.wait(employees.map((e) => transaction.insertObject(e))); }); Rollbacks You can cancel a transaction and revert its changes at anytime within the transaction closure by throwing a Rollback object. try { await context.transaction((t) async { // do something if (somethingIsTrue) { throw Rollback(\"something was true\"); } // do something }); } on Rollback catch (rollback) { print(\"${rollback.reason}\"); // prints 'something was true' } When you rollback, your transaction fails, the transaction closure is aborted and all changes are reverted. The transaction method completes with an error, where the error object is the Rollback .","title":"Transactions"},{"location":"db/transactions/#database-transactions","text":"Learn how to execute multiple Query<T> s in a database transaction.","title":"Database Transactions"},{"location":"db/transactions/#transactions","text":"A transaction is a series of queries that are executed together. If one of the queries in that set fails, then all of the queries fail and their changes are reversed if they had already been executed. Consider an application that stores employee records. Each employee belongs to a department. Management decides to combine two departments into a totally new department. To do this, the application must insert a new department, set each employee's foreign key reference to that department, and then delete the old departments. An straightforward (but problematic) implementation would look like this: // Create the new department final newDepartment = await ctx.insertObject(Department()..name = \"New Department\"); // Set employee's departments to the new one final changeDepartmentQuery = Query<Employee>(ctx) ..where((e) => e.department.id).oneOf([1, 2]) ..values.department.id = newDepartment.id; await changeDepartmentQuery.update(); // Delete the old ones final deleteDepartmentQuery = Query<Department>(ctx) ..where((e) => e.department.id).oneOf([1, 2]); await deleteDepartmentQuery.delete(); This change to your database is three separate queries, but they all most complete for the 'transfer' to be successful. If one of them fails, our database can be left in an inconsistent state. For example, if deleting the departments succeeds, but the employees failed to be transferred to the new department, then a lot of employees would be without a department. A database transaction combines queries together as a single unit. If a query in a transaction fails, the previous queries in that transaction are reverted and the remaining queries are aborted. You create transactions by invoking ManagedContext.transaction and writing your queries in its closure argument. await context.transaction((transaction) async { // note that 'transaction' is the context for each of these queries. final newDepartment = await transaction.insertObject(Department()..name = \"New Department\"); final changeDepartmentQuery = Query<Employee>(transaction) ..where((e) => e.department.id).oneOf([1, 2]) ..values.department.id = newDepartment.id; await changeDepartmentQuery.update(); final deleteDepartmentQuery = Query<Department>(transaction) ..where((e) => e.department.id).oneOf([1, 2]); await deleteDepartmentQuery.delete(); }); The closure has a transaction object that all queries in the transaction must use as their context. Queries that use this transaction context will be grouped in the same transaction. Once they have all succeeded, the transaction method's future completes. If an exception is thrown in the closure, the transaction is rolled back and the transaction method re-throws that exception. !!! warning \"Failing to Use the Transaction Context will Deadlock your Application\" If you use the transaction's parent context in a query inside a transaction closure, the database connection will deadlock and will stop working.","title":"Transactions"},{"location":"db/transactions/#returning-values","text":"The value returned from a transaction closure is returned to the caller, so values created within the transaction closure can escape its scope. final employees = [...]; final insertedEmployees = await context.transaction((transaction) async { return Future.wait(employees.map((e) => transaction.insertObject(e))); });","title":"Returning Values"},{"location":"db/transactions/#rollbacks","text":"You can cancel a transaction and revert its changes at anytime within the transaction closure by throwing a Rollback object. try { await context.transaction((t) async { // do something if (somethingIsTrue) { throw Rollback(\"something was true\"); } // do something }); } on Rollback catch (rollback) { print(\"${rollback.reason}\"); // prints 'something was true' } When you rollback, your transaction fails, the transaction closure is aborted and all changes are reverted. The transaction method completes with an error, where the error object is the Rollback .","title":"Rollbacks"},{"location":"db/validations/","text":"Validating Data Data is added to a database through update and insert queries. As part of these two operations, a ManagedObject<T> will ensure that its properties have valid values. For example, a Person object might ensure that its name starts with a capital letter and that its phone number has only numeric values. If one or more validation fails, the update or insert operation will fail and the data is not sent to the database. A validation failure will throw a QueryException that returns an HTTP response with error messaging to help the client correct their request. The preferred way of setting a validation is to add Validate metadata to properties of a table definition. Here's an example of a validation that ensures a tweet is less than 140 characters: class Tweet extends ManagedObject<_Tweet> implements _Tweet {} class _Tweet { @primaryKey int id; @Validate.length(lessThan: 140) String message; } Built-in Validators There are a handful of built-in validations for common operations. For example, it is common to apply a regular expression to a value to ensure it is formatted correctly or to restrict the possible values to a list of available options. Common validators are available as named constructors of the Validate class. Here is an example: class _Story { @primaryKey int id; @Validate.oneOf(const [\"started\", \"accepted\", \"rejected\", \"delivered\"]) String state; } A built-in validator is useful because it automatically generates an error message that is returned in an HTTP response. For example, the previous code snippet indicates that the state property must be one of the four listed strings. If a value other than one of those four strings is used, the error message returned to the HTTP client would be: \"The value `invalidValue` is not valid for `state`. Valid values are: 'started', 'accepted', 'rejected', 'delivered'.\". See the API reference for Validate and its named constructors for possible options. Validate annotations on properties declared in a managed object subclass (transient properties) have no effect. Validating Relationships Validations are only valid for properties declared in a table definition. Validators applied to relationship properties are applied to the primary key of the related object (i.e. the foreign key value). Validation logic is only ran on the properties of the managed object being validated - validations on properties of a related object are not run. When validating a graph of managed objects, you must initiate validation on any related objects manually. !!! warning \"Validating Related Objects\" The behavior of a validation is different when an object is being validated as a relationship. In other words, a validation applied to the primary key of an object likely requires different behavior when being applied to a foreign key reference to that object. Custom Validators There will be times where the built-in validators are not sufficient for your application's use case. You may create subclasses of Validate to provide custom validation behavior. For example, if there were a ValidatePhoneNumber class: class _Person { @primaryKey int id; @ValidatePhoneNumber() String phoneNumber; } A subclass of Validate must override Validate.validate() and call the superclass' primary constructor when instantiated. Here's an example of that phone number validator: class ValidatePhoneNumber extends Validate { ValidatePhoneNumber({bool onUpdate: true, bool onInsert: true}) : super(onUpdate: onUpdate, onInsert: onInsert); @override void validate(ValidationContext context, dynamic value) { if (value.length != 15) { context.addError(\"must be 15 digits\"); } if (containsNonNumericValues(value)) { context.addError(\"must contain characters 0-9 only.\"); } } } If value is doesn't meet the validation criteria, this method adds an error string to the ValidationContext it is passed. Error messages should be brief and indicate the successful criteria that failed. Information about the property being validated will automatically be added to the error message, so you do not need to include that information. If the context has no errors at the end of validation, the validation succeeds; otherwise, it fails. A ValidationContext also has information about the property being validated, and whether the validation is running for an object being inserted or an object being updated. Validation Behavior A property may have more than one Validate metadata. In this case, all of the validations for a property must pass. The order in which multiple validations are performed is undefined and subject to change. Here's an example of validations that ensure a property's value is 10 characters long and only contains 10 alphabetic capital letters: @Validate.length(equalTo: 10) @Validate.matches(r\"$[A-Z]+^\") String tenCapitalLetters; By default, validations are executed when a Query<T> 's insert or update method is invoked. A validator can be restricted to only run on insert or update by passing values for its optional constructor arguments onUpdate and onInsert : @Validate.matches(r\"^[A-Z]+$\", onInsert: true, onUpdate: false) String validateOnInsertOnly; It is important to understand how validations work when a value for a property is not specified in an insert or update query. For example, consider a Person with a name and email property and then inserted in a query where email hasn't been set: var query = new Query<Person>(context) ..values.name = \"Bob\"; await query.insert(); Because email was not set on Query.values , validations will not be run on that property. There are two special validators that can require a property to be set, or require that a property not be set. Validate.present() requires that the associated property must have a value. A property with this validator must be provided each time the object is inserted or updated. For example, the following declaration requires that email is set on insertion, but doesn't have to be for updates: @Validate.present(onUpdate: false, onInsert: true) String email; The inverse of Validate.present() is Validate.absent() . This validation prevents a property from being set. This is useful when a value should be included during insertion, but can't be updated. Here's an example: @Validate.absent(onUpdate: true, onInsert: false) String canOnlyBeSetOnce; In the above declaration, the validator is only run on update operations and ensures that the property canOnlyBeSetOnce does not have a value. Because this validator is not run on insert operations, there is no restriction when the object is first inserted. Validators are not run when a value is null. For example, the following insertion explicitly inserts null for the property email : var query = new Query<Person>(context) ..values.email = null ..values.name = \"Bob\"; await query.insert(); Nullability is enforced by Column.isNullable property. Consider the following declaration: @Column(nullable: false) @Validate.length(greaterThan: 10) String name; Here, the property name must not be null and must be greater than 10 characters long. The behavior of inserting or updating this property is shown in the following table. Input Value for Name Validation Runs? Outcome Insert value longer than 10 characters Yes Successful database insert Insert value shorter than 10 characters Yes Database insert not executed, exception thrown Insert value not specified No Database insert fails with non-null violation, exception thrown Insert value is null No Database insert fails with non-null violation, exception thrown Update value longer than 10 characters Yes Successful database update Update value shorter than 10 characters Yes Database update not executed, exception thrown Update value not specified No Successful database update Update value is explicit null No Successful database update This behavior allows ManagedObject<T> instances to be partially updated, which also allows for partial PUTs. Partial PUTs can be prevented by adding Validate.present() metadata to all properties. This also means that any custom validator can assert that a value passed to Validate.validate() is non-null. Other Validator Behavior For validators that can't be built by subclassing Validate , you may override ManagedObject<T>.validate() . This method is useful when a validation involves more than one property. Here's an example: class Person extends ManagedObject<_Person> implements _Person { @override ValidationContext validate({Validating forEvent: Validating.insert}) { final ctx = super.validate(forEvent: forEvent); if (a + b > 10) { ctx.addError(\"a + b must be greater than 10\"); } return ctx; } } When overriding this method, the super implementation must be invoked to run validations managed by annotations. You must return the ValidationContext created by the superclass' implementation. Skipping Validations Validations are only run when values are set via Query<T>.values . Values set via Query<T>.valueMap are not validated and is useful for inserting data without validation. Here's an example of skipping validation: var query = new Query<Person>(context) ..valueMap = { \"name\" : \"xyz\", \"email\" : \"whatever\" }; Update and Insert Callbacks ManagedObject<T> subclasses may override willUpdate and willInsert to make changes prior to being updated or inserted. For example, a managed object may have updated and created dates that can be guaranteed to be set when inserted or updated: class Person extends ManagedObject<_Person> implements _Person { @override void willUpdate() { updatedAt = new DateTime.now().toUtc(); } @override void willInsert() { createdAt = new DateTime.now().toUtc(); } } class _Person { @primaryKey int id; String name; DateTime createdAt; DateTime updatedAt; } Both willUpdate and willInsert are run before any validation occurs. Like validations, willUpdate and willInsert are skipped when using Query.valueMap .","title":"Validations"},{"location":"db/validations/#validating-data","text":"Data is added to a database through update and insert queries. As part of these two operations, a ManagedObject<T> will ensure that its properties have valid values. For example, a Person object might ensure that its name starts with a capital letter and that its phone number has only numeric values. If one or more validation fails, the update or insert operation will fail and the data is not sent to the database. A validation failure will throw a QueryException that returns an HTTP response with error messaging to help the client correct their request. The preferred way of setting a validation is to add Validate metadata to properties of a table definition. Here's an example of a validation that ensures a tweet is less than 140 characters: class Tweet extends ManagedObject<_Tweet> implements _Tweet {} class _Tweet { @primaryKey int id; @Validate.length(lessThan: 140) String message; }","title":"Validating Data"},{"location":"db/validations/#built-in-validators","text":"There are a handful of built-in validations for common operations. For example, it is common to apply a regular expression to a value to ensure it is formatted correctly or to restrict the possible values to a list of available options. Common validators are available as named constructors of the Validate class. Here is an example: class _Story { @primaryKey int id; @Validate.oneOf(const [\"started\", \"accepted\", \"rejected\", \"delivered\"]) String state; } A built-in validator is useful because it automatically generates an error message that is returned in an HTTP response. For example, the previous code snippet indicates that the state property must be one of the four listed strings. If a value other than one of those four strings is used, the error message returned to the HTTP client would be: \"The value `invalidValue` is not valid for `state`. Valid values are: 'started', 'accepted', 'rejected', 'delivered'.\". See the API reference for Validate and its named constructors for possible options. Validate annotations on properties declared in a managed object subclass (transient properties) have no effect.","title":"Built-in Validators"},{"location":"db/validations/#validating-relationships","text":"Validations are only valid for properties declared in a table definition. Validators applied to relationship properties are applied to the primary key of the related object (i.e. the foreign key value). Validation logic is only ran on the properties of the managed object being validated - validations on properties of a related object are not run. When validating a graph of managed objects, you must initiate validation on any related objects manually. !!! warning \"Validating Related Objects\" The behavior of a validation is different when an object is being validated as a relationship. In other words, a validation applied to the primary key of an object likely requires different behavior when being applied to a foreign key reference to that object.","title":"Validating Relationships"},{"location":"db/validations/#custom-validators","text":"There will be times where the built-in validators are not sufficient for your application's use case. You may create subclasses of Validate to provide custom validation behavior. For example, if there were a ValidatePhoneNumber class: class _Person { @primaryKey int id; @ValidatePhoneNumber() String phoneNumber; } A subclass of Validate must override Validate.validate() and call the superclass' primary constructor when instantiated. Here's an example of that phone number validator: class ValidatePhoneNumber extends Validate { ValidatePhoneNumber({bool onUpdate: true, bool onInsert: true}) : super(onUpdate: onUpdate, onInsert: onInsert); @override void validate(ValidationContext context, dynamic value) { if (value.length != 15) { context.addError(\"must be 15 digits\"); } if (containsNonNumericValues(value)) { context.addError(\"must contain characters 0-9 only.\"); } } } If value is doesn't meet the validation criteria, this method adds an error string to the ValidationContext it is passed. Error messages should be brief and indicate the successful criteria that failed. Information about the property being validated will automatically be added to the error message, so you do not need to include that information. If the context has no errors at the end of validation, the validation succeeds; otherwise, it fails. A ValidationContext also has information about the property being validated, and whether the validation is running for an object being inserted or an object being updated.","title":"Custom Validators"},{"location":"db/validations/#validation-behavior","text":"A property may have more than one Validate metadata. In this case, all of the validations for a property must pass. The order in which multiple validations are performed is undefined and subject to change. Here's an example of validations that ensure a property's value is 10 characters long and only contains 10 alphabetic capital letters: @Validate.length(equalTo: 10) @Validate.matches(r\"$[A-Z]+^\") String tenCapitalLetters; By default, validations are executed when a Query<T> 's insert or update method is invoked. A validator can be restricted to only run on insert or update by passing values for its optional constructor arguments onUpdate and onInsert : @Validate.matches(r\"^[A-Z]+$\", onInsert: true, onUpdate: false) String validateOnInsertOnly; It is important to understand how validations work when a value for a property is not specified in an insert or update query. For example, consider a Person with a name and email property and then inserted in a query where email hasn't been set: var query = new Query<Person>(context) ..values.name = \"Bob\"; await query.insert(); Because email was not set on Query.values , validations will not be run on that property. There are two special validators that can require a property to be set, or require that a property not be set. Validate.present() requires that the associated property must have a value. A property with this validator must be provided each time the object is inserted or updated. For example, the following declaration requires that email is set on insertion, but doesn't have to be for updates: @Validate.present(onUpdate: false, onInsert: true) String email; The inverse of Validate.present() is Validate.absent() . This validation prevents a property from being set. This is useful when a value should be included during insertion, but can't be updated. Here's an example: @Validate.absent(onUpdate: true, onInsert: false) String canOnlyBeSetOnce; In the above declaration, the validator is only run on update operations and ensures that the property canOnlyBeSetOnce does not have a value. Because this validator is not run on insert operations, there is no restriction when the object is first inserted. Validators are not run when a value is null. For example, the following insertion explicitly inserts null for the property email : var query = new Query<Person>(context) ..values.email = null ..values.name = \"Bob\"; await query.insert(); Nullability is enforced by Column.isNullable property. Consider the following declaration: @Column(nullable: false) @Validate.length(greaterThan: 10) String name; Here, the property name must not be null and must be greater than 10 characters long. The behavior of inserting or updating this property is shown in the following table. Input Value for Name Validation Runs? Outcome Insert value longer than 10 characters Yes Successful database insert Insert value shorter than 10 characters Yes Database insert not executed, exception thrown Insert value not specified No Database insert fails with non-null violation, exception thrown Insert value is null No Database insert fails with non-null violation, exception thrown Update value longer than 10 characters Yes Successful database update Update value shorter than 10 characters Yes Database update not executed, exception thrown Update value not specified No Successful database update Update value is explicit null No Successful database update This behavior allows ManagedObject<T> instances to be partially updated, which also allows for partial PUTs. Partial PUTs can be prevented by adding Validate.present() metadata to all properties. This also means that any custom validator can assert that a value passed to Validate.validate() is non-null.","title":"Validation Behavior"},{"location":"db/validations/#other-validator-behavior","text":"For validators that can't be built by subclassing Validate , you may override ManagedObject<T>.validate() . This method is useful when a validation involves more than one property. Here's an example: class Person extends ManagedObject<_Person> implements _Person { @override ValidationContext validate({Validating forEvent: Validating.insert}) { final ctx = super.validate(forEvent: forEvent); if (a + b > 10) { ctx.addError(\"a + b must be greater than 10\"); } return ctx; } } When overriding this method, the super implementation must be invoked to run validations managed by annotations. You must return the ValidationContext created by the superclass' implementation.","title":"Other Validator Behavior"},{"location":"db/validations/#skipping-validations","text":"Validations are only run when values are set via Query<T>.values . Values set via Query<T>.valueMap are not validated and is useful for inserting data without validation. Here's an example of skipping validation: var query = new Query<Person>(context) ..valueMap = { \"name\" : \"xyz\", \"email\" : \"whatever\" };","title":"Skipping Validations"},{"location":"db/validations/#update-and-insert-callbacks","text":"ManagedObject<T> subclasses may override willUpdate and willInsert to make changes prior to being updated or inserted. For example, a managed object may have updated and created dates that can be guaranteed to be set when inserted or updated: class Person extends ManagedObject<_Person> implements _Person { @override void willUpdate() { updatedAt = new DateTime.now().toUtc(); } @override void willInsert() { createdAt = new DateTime.now().toUtc(); } } class _Person { @primaryKey int id; String name; DateTime createdAt; DateTime updatedAt; } Both willUpdate and willInsert are run before any validation occurs. Like validations, willUpdate and willInsert are skipped when using Query.valueMap .","title":"Update and Insert Callbacks"},{"location":"deploy/","text":"Deploying Conduit Conduit has a built in CLI tool, conduit , for deploying Conduit applications, managing database schemas, OAuth 2.0 clients and creating projects. See Getting Started for installation instructions. Many of the tasks for deployment rely on using this tool. Conduit has a built in tool, conduit , for deploying Conduit applications, managing database schemas, OAuth 2.0 clients and creating projects. See Getting Started for installation instructions. Many of the tasks for deployment rely on using this tool. Conduit applications can be run anywhere that Dart can be installed. This topic covers deployment tasks on common hosting services. If you are just getting started or a hobbyist, you should consider using Heroku to host your applications. Guides Running a Conduit Application Locally Running a Conduit Application with Docker, Docker Compose and Kubernetes Running a Conduit Application without conduit serve","title":"Deploying Conduit"},{"location":"deploy/#deploying-conduit","text":"Conduit has a built in CLI tool, conduit , for deploying Conduit applications, managing database schemas, OAuth 2.0 clients and creating projects. See Getting Started for installation instructions. Many of the tasks for deployment rely on using this tool. Conduit has a built in tool, conduit , for deploying Conduit applications, managing database schemas, OAuth 2.0 clients and creating projects. See Getting Started for installation instructions. Many of the tasks for deployment rely on using this tool. Conduit applications can be run anywhere that Dart can be installed. This topic covers deployment tasks on common hosting services. If you are just getting started or a hobbyist, you should consider using Heroku to host your applications.","title":"Deploying Conduit"},{"location":"deploy/#guides","text":"Running a Conduit Application Locally Running a Conduit Application with Docker, Docker Compose and Kubernetes Running a Conduit Application without conduit serve","title":"Guides"},{"location":"deploy/build/","text":"Creating an Executable Beta Notes and Known Issues: This feature is currently in beta and there are known issues. Windows is not currently supported due to filesystem operations that have not been tested on the OS. Request body decoding methods, RequestBody.as<T> and RequestBody.decode<T> , have restrictions on the their type parameters when running as an executable. These types are limited to primitive types, such as int , String , double , num , List (of aforementioned primitives, or Map<String, dynamic> ) and Map (keys must String , values may be any of the aforementioned primitive types). There are bugs! Please report them to the Conduit repository . Building and Running an Executable By default, Conduit runs in the Dart VM. A VM application optimizes over time and is very convenient for machines that already have Dart installed. However, VM applications are slower to startup, consume significantly more memory, and aren't as portable. Therefore, Conduit offers an option to build an executable version of your application. This is done by running the following command in your Conduit app's project directory: conduit build The output of this command is an executable that contains your application without the expensive VM. The name of the executable defaults to 'XXXXX' and is run from the command-line like any other executable: ./my_app Executable's can only be run on the platform that created them. For example, you cannot create an executable in macOS and run it on Windows. Building Cross-Platform with Docker TBD","title":"Creating a Conduit Executable"},{"location":"deploy/build/#creating-an-executable","text":"","title":"Creating an Executable"},{"location":"deploy/build/#beta-notes-and-known-issues","text":"This feature is currently in beta and there are known issues. Windows is not currently supported due to filesystem operations that have not been tested on the OS. Request body decoding methods, RequestBody.as<T> and RequestBody.decode<T> , have restrictions on the their type parameters when running as an executable. These types are limited to primitive types, such as int , String , double , num , List (of aforementioned primitives, or Map<String, dynamic> ) and Map (keys must String , values may be any of the aforementioned primitive types). There are bugs! Please report them to the Conduit repository .","title":"Beta Notes and Known Issues:"},{"location":"deploy/build/#building-and-running-an-executable","text":"By default, Conduit runs in the Dart VM. A VM application optimizes over time and is very convenient for machines that already have Dart installed. However, VM applications are slower to startup, consume significantly more memory, and aren't as portable. Therefore, Conduit offers an option to build an executable version of your application. This is done by running the following command in your Conduit app's project directory: conduit build The output of this command is an executable that contains your application without the expensive VM. The name of the executable defaults to 'XXXXX' and is run from the command-line like any other executable: ./my_app Executable's can only be run on the platform that created them. For example, you cannot create an executable in macOS and run it on Windows.","title":"Building and Running an Executable"},{"location":"deploy/build/#building-cross-platform-with-docker","text":"TBD","title":"Building Cross-Platform with Docker"},{"location":"deploy/deploy_aws/","text":"Deploying a Conduit Application on Remote VMs For other deployment options, see Deploying Conduit Applications . Purpose This document will describe the steps to deploy a Conduit application to a remote machine that you are able to ssh into. This is often the case for Amazon Web Service (AWS) EC2 instances, Google Cloud Compute Instances, Azure Virtual Machines, and rented boxes on platforms like Digital Ocean or other cloud providers. If you are unfamiliar with deploying applications in this way, this is not a good beginner's guide and will not cover many of the steps necessary to deploy an application. Prefer to use a platform like Heroku or one that supports Docker. See the guides on Heroku and Docker for better options. Summary Conduit applications are run by using conduit serve or dart bin/main.dart . # in project directory conduit serve # or # in project directory dart bin/main.dart The target machine must have Dart installed. If you are using conduit serve , you must also activate the CLI on the target machine: pub global activate conduit Your source code must also be available on the target machine. You can transfer your source to a machine with tools like ftp , scp , rsync and git . Conduit will listen on port 8888 by default. Change this value at the CLI conduit serve --port 80 or in bin/main.dart . Ensure that security controls on your instance can accept connections on the port Conduit is listening on. It is preferable to use a reverse proxy (e.g. nginx or a load balancer) instead of serving the application directly. Use tools like supervisord to ensure the application restarts if the VM crashes. Configuration Management When deploying directly to a VM, it is your responsibility to manage your configuration file. This can often be done by transferring an environment specific config.yaml file to your target machine and storing it in your project's directory on the remote machine. CLI Tools Many deployments will need to perform database migrations and OAuth 2.0 client identifier management with the conduit CLI. You can run these tools locally with the --connect flag to specify the location of your database instance. Ensure that you have the propery security controls to access the database instance from your local machine.","title":"Deploy on AWS (VM)"},{"location":"deploy/deploy_aws/#deploying-a-conduit-application-on-remote-vms","text":"For other deployment options, see Deploying Conduit Applications .","title":"Deploying a Conduit Application on Remote VMs"},{"location":"deploy/deploy_aws/#purpose","text":"This document will describe the steps to deploy a Conduit application to a remote machine that you are able to ssh into. This is often the case for Amazon Web Service (AWS) EC2 instances, Google Cloud Compute Instances, Azure Virtual Machines, and rented boxes on platforms like Digital Ocean or other cloud providers. If you are unfamiliar with deploying applications in this way, this is not a good beginner's guide and will not cover many of the steps necessary to deploy an application. Prefer to use a platform like Heroku or one that supports Docker. See the guides on Heroku and Docker for better options.","title":"Purpose"},{"location":"deploy/deploy_aws/#summary","text":"Conduit applications are run by using conduit serve or dart bin/main.dart . # in project directory conduit serve # or # in project directory dart bin/main.dart The target machine must have Dart installed. If you are using conduit serve , you must also activate the CLI on the target machine: pub global activate conduit Your source code must also be available on the target machine. You can transfer your source to a machine with tools like ftp , scp , rsync and git . Conduit will listen on port 8888 by default. Change this value at the CLI conduit serve --port 80 or in bin/main.dart . Ensure that security controls on your instance can accept connections on the port Conduit is listening on. It is preferable to use a reverse proxy (e.g. nginx or a load balancer) instead of serving the application directly. Use tools like supervisord to ensure the application restarts if the VM crashes.","title":"Summary"},{"location":"deploy/deploy_aws/#configuration-management","text":"When deploying directly to a VM, it is your responsibility to manage your configuration file. This can often be done by transferring an environment specific config.yaml file to your target machine and storing it in your project's directory on the remote machine.","title":"Configuration Management"},{"location":"deploy/deploy_aws/#cli-tools","text":"Many deployments will need to perform database migrations and OAuth 2.0 client identifier management with the conduit CLI. You can run these tools locally with the --connect flag to specify the location of your database instance. Ensure that you have the propery security controls to access the database instance from your local machine.","title":"CLI Tools"},{"location":"deploy/deploy_docker/","text":"Deploying on Docker For other deployment options, see Deploying Conduit Applications . Purpose This document will describe the steps to deploy a Conduit application through Docker, Docker Compose or a container orchestration platform like Kubernetes. For Dockerfile and Kubernetes templates, see this repository . If you are unfamiliar with deploying applications in this way, this is not a good beginner's guide and will not cover the topics of Docker, Docker Compose or Kubernetes. Dockerfiles The following Dockerfile will run a Conduit application. FROM google/dart WORKDIR /app ADD pubspec.* /app/ RUN pub get --no-precompile ADD . /app/ RUN pub get --offline --no-precompile WORKDIR /app EXPOSE 80 ENTRYPOINT [\"pub\", \"run\", \"conduit:conduit\", \"serve\", \"--port\", \"80\"] Docker Compose To deploy your application (which uses the Conduit ORM) using Docker Compose, use this template: Dockerfile Use the Dockerfile specified above. docker-compose.yml version: '3' services: my-app: build: . ports: - \"80:80\" db: image: \"postgres:11\" container_name: \"postgres_database\" environment: - POSTGRES_PASSWORD=password-from-config-yaml - POSTGRES_USER=user-from-config-yaml - POSTGRES_DB=db-from-config-yaml ports: - \"65432:port-from-config-yaml\" # If you want to expose the db from the container volumes: - db_data:/var/lib/postgresql/data volumes: db_data: {} Once the service is up (using docker-compose up -d ), you can run your database migrations using conduit db upgrade --connect postgres://user-from-config-yaml:password-from-config-yaml@hostname:65432/db-from-config-yaml Kubernetes Objects For more Kubernetes objects - including tasks for database migrations and OAuth 2.0 client management - see this repository . The following is Kubernetes configuration file for starting a Conduit application and exposing it as a service. Replace <APP_NAME> with your application's name. apiVersion: v1 kind: Service metadata: name: api-service namespace: <APP_NAME> spec: selector: app: <APP_NAME> role: backend type: api ports: - port: 80 targetPort: 8082 --- apiVersion: apps/v1beta1 kind: Deployment metadata: name: api-deployment namespace: <APP_NAME> spec: replicas: 2 template: metadata: labels: app: <APP_NAME> role: backend type: api spec: containers: - name: <APP_NAME> # In development, setting `imagePullPolicy: Always` and using :latest tag is useful. # imagePullPolicy: Always image: <IMAGE> envFrom: - secretRef: name: secrets - configMapRef: name: config ports: - containerPort: 8082 securityContext: runAsNonRoot: true","title":"Deploying with Docker and Kubernetes (VM)"},{"location":"deploy/deploy_docker/#deploying-on-docker","text":"For other deployment options, see Deploying Conduit Applications .","title":"Deploying on Docker"},{"location":"deploy/deploy_docker/#purpose","text":"This document will describe the steps to deploy a Conduit application through Docker, Docker Compose or a container orchestration platform like Kubernetes. For Dockerfile and Kubernetes templates, see this repository . If you are unfamiliar with deploying applications in this way, this is not a good beginner's guide and will not cover the topics of Docker, Docker Compose or Kubernetes.","title":"Purpose"},{"location":"deploy/deploy_docker/#dockerfiles","text":"The following Dockerfile will run a Conduit application. FROM google/dart WORKDIR /app ADD pubspec.* /app/ RUN pub get --no-precompile ADD . /app/ RUN pub get --offline --no-precompile WORKDIR /app EXPOSE 80 ENTRYPOINT [\"pub\", \"run\", \"conduit:conduit\", \"serve\", \"--port\", \"80\"]","title":"Dockerfiles"},{"location":"deploy/deploy_docker/#docker-compose","text":"To deploy your application (which uses the Conduit ORM) using Docker Compose, use this template: Dockerfile Use the Dockerfile specified above. docker-compose.yml version: '3' services: my-app: build: . ports: - \"80:80\" db: image: \"postgres:11\" container_name: \"postgres_database\" environment: - POSTGRES_PASSWORD=password-from-config-yaml - POSTGRES_USER=user-from-config-yaml - POSTGRES_DB=db-from-config-yaml ports: - \"65432:port-from-config-yaml\" # If you want to expose the db from the container volumes: - db_data:/var/lib/postgresql/data volumes: db_data: {} Once the service is up (using docker-compose up -d ), you can run your database migrations using conduit db upgrade --connect postgres://user-from-config-yaml:password-from-config-yaml@hostname:65432/db-from-config-yaml","title":"Docker Compose"},{"location":"deploy/deploy_docker/#kubernetes-objects","text":"For more Kubernetes objects - including tasks for database migrations and OAuth 2.0 client management - see this repository . The following is Kubernetes configuration file for starting a Conduit application and exposing it as a service. Replace <APP_NAME> with your application's name. apiVersion: v1 kind: Service metadata: name: api-service namespace: <APP_NAME> spec: selector: app: <APP_NAME> role: backend type: api ports: - port: 80 targetPort: 8082 --- apiVersion: apps/v1beta1 kind: Deployment metadata: name: api-deployment namespace: <APP_NAME> spec: replicas: 2 template: metadata: labels: app: <APP_NAME> role: backend type: api spec: containers: - name: <APP_NAME> # In development, setting `imagePullPolicy: Always` and using :latest tag is useful. # imagePullPolicy: Always image: <IMAGE> envFrom: - secretRef: name: secrets - configMapRef: name: config ports: - containerPort: 8082 securityContext: runAsNonRoot: true","title":"Kubernetes Objects"},{"location":"deploy/deploy_heroku/","text":"Deploying a Conduit Application on Heroku For other deployment options, see Deploying Conduit Applications . Purpose To run a production Conduit application on Heroku. Make sure to also read Testing Conduit Applications . Prerequisites Dart has been installed. A Heroku account. git has been installed. heroku has been installed. Conduit has been activated. Overview Setting up a Heroku application Setting up a Conduit application to run on Heroku Configuring application values Running the Conduit application Estimated Time: 5 minutes. Step 1: Setting up a Heroku Application Create a new application in Heroku's web portal, and if you are using a database, add the 'Heroku Postgres' add-on. Navigate to the Settings tab in the Heroku web interface and click 'Reveal Config Vars'. Note that there is a DATABASE_URL environment variable that is the connection details for your PostgreSQL database. You won't need to remember the value, only that this environment variable exists. Step 2: Setting up a Conduit Application to Run on Heroku If you have not yet, create a new Conduit application on your local machine, go into that directory, and initialize it as a git repository if it is not already: conduit create app_name cd app_name git init Run the following commands to configure your project in Heroku's environment. !!! warning \"Heroku Application Name\" In the following commands, ensure that app_name is the name of your Heroku application created in their web portal, not the name of your Conduit application. # This is an interactive command that you have to enter your username and password. heroku login # This adds a remote repository hosted by Heroku for your application that you push to. heroku git:remote -a app_name # Specifies the Dart SDK to use heroku config:set DART_SDK_URL=https://storage.googleapis.com/dart-archive/channels/stable/release/latest/sdk/dartsdk-linux-x64-release.zip # Specifies the Heroku Buildpack to use heroku config:set BUILDPACK_URL=https://github.com/conduit.dart/heroku-buildpack-dart.git # Specifies that conduit should be activated heroku config:set DART_GLOBAL_PACKAGES=\"conduit@3.0.0\" heroku config:set PATH=/app/bin:/usr/local/bin:/usr/bin:/bin:/app/.pub-cache/bin:/app/dart-sdk/bin heroku config:set PUB_CACHE=/app/pub-cache Then, create a new file in your project directory named Procfile (with no suffix) and enter the following: release: /app/dart-sdk/bin/pub global run conduit:conduit db upgrade --connect $DATABASE_URL web: /app/dart-sdk/bin/pub global run conduit:conduit serve --port $PORT --config-path heroku.yaml This file tells Heroku how to run your application, and to execute any database migrations each time you push a release. Make sure this file is checked into version control: git commit -am \"Adds Procfile\" Step 3: Configuring Application Values Heroku provides configuration values through environment variables. In our Procfile , we indicated that we will use a file named heroku.yaml for configuration. This file will map configuration values in our application to environment variables in the Heroku platform. Your configuration file may vary, but it is important to note that if you are using a database, the database credentials are provided through a connection string . A connection string looks like this: postgres://user:password@host:5432/name and by default, Heroku stores it in the environment variable named DATABASE_URL . In heroku.yaml (which you will need to create in your project directory), you can reference an environment variable by prefixing its name with a $ . When using the built-in DatabaseConfiguration type, you can assign the connection string like so: database: $DATABASE_URL !!! warning \"Your heroku.yaml might be different\" Make sure the structure of your heroku.yaml file matches the expected structure in your application's Configuration subclass. Check heroku.yaml into version control. git commit -am \"add heroku.yaml\" Step 4: Running the Conduit Application If your application uses a database, make sure you have generated your migration file(s) and added it to version control. The Procfile will ensure that database is up to date with any migrations checked into source control before running your app. Generate your migration file with the following command from your project directory and then check it into version control: conduit db generate git commit -am \"adds migration files\" Now, you can deploy your application. It's as simple as this: git push heroku master This command pushes your code to a remote git server hosted by Heroku, which triggers your application to run its release script. Now that your application's database schema has been uploaded, you can configure your OAuth 2 server with client identifiers if you are using package:conduit/managed_auth . The following command will run within your application's remote environment. heroku run /app/dart-sdk/bin/pub global run conduit:conduit auth add-client --id com.app.standard --secret secret --connect \\$DATABASE_URL Finally, scale up a dyno and the application will start receiving requests: heroku ps:scale web=1 Now your application is running!","title":"Deploy on Heroku (VM)"},{"location":"deploy/deploy_heroku/#deploying-a-conduit-application-on-heroku","text":"For other deployment options, see Deploying Conduit Applications .","title":"Deploying a Conduit Application on Heroku"},{"location":"deploy/deploy_heroku/#purpose","text":"To run a production Conduit application on Heroku. Make sure to also read Testing Conduit Applications .","title":"Purpose"},{"location":"deploy/deploy_heroku/#prerequisites","text":"Dart has been installed. A Heroku account. git has been installed. heroku has been installed. Conduit has been activated.","title":"Prerequisites"},{"location":"deploy/deploy_heroku/#overview","text":"Setting up a Heroku application Setting up a Conduit application to run on Heroku Configuring application values Running the Conduit application Estimated Time: 5 minutes.","title":"Overview"},{"location":"deploy/deploy_heroku/#step-1-setting-up-a-heroku-application","text":"Create a new application in Heroku's web portal, and if you are using a database, add the 'Heroku Postgres' add-on. Navigate to the Settings tab in the Heroku web interface and click 'Reveal Config Vars'. Note that there is a DATABASE_URL environment variable that is the connection details for your PostgreSQL database. You won't need to remember the value, only that this environment variable exists.","title":"Step 1: Setting up a Heroku Application"},{"location":"deploy/deploy_heroku/#step-2-setting-up-a-conduit-application-to-run-on-heroku","text":"If you have not yet, create a new Conduit application on your local machine, go into that directory, and initialize it as a git repository if it is not already: conduit create app_name cd app_name git init Run the following commands to configure your project in Heroku's environment. !!! warning \"Heroku Application Name\" In the following commands, ensure that app_name is the name of your Heroku application created in their web portal, not the name of your Conduit application. # This is an interactive command that you have to enter your username and password. heroku login # This adds a remote repository hosted by Heroku for your application that you push to. heroku git:remote -a app_name # Specifies the Dart SDK to use heroku config:set DART_SDK_URL=https://storage.googleapis.com/dart-archive/channels/stable/release/latest/sdk/dartsdk-linux-x64-release.zip # Specifies the Heroku Buildpack to use heroku config:set BUILDPACK_URL=https://github.com/conduit.dart/heroku-buildpack-dart.git # Specifies that conduit should be activated heroku config:set DART_GLOBAL_PACKAGES=\"conduit@3.0.0\" heroku config:set PATH=/app/bin:/usr/local/bin:/usr/bin:/bin:/app/.pub-cache/bin:/app/dart-sdk/bin heroku config:set PUB_CACHE=/app/pub-cache Then, create a new file in your project directory named Procfile (with no suffix) and enter the following: release: /app/dart-sdk/bin/pub global run conduit:conduit db upgrade --connect $DATABASE_URL web: /app/dart-sdk/bin/pub global run conduit:conduit serve --port $PORT --config-path heroku.yaml This file tells Heroku how to run your application, and to execute any database migrations each time you push a release. Make sure this file is checked into version control: git commit -am \"Adds Procfile\"","title":"Step 2: Setting up a Conduit Application to Run on Heroku"},{"location":"deploy/deploy_heroku/#step-3-configuring-application-values","text":"Heroku provides configuration values through environment variables. In our Procfile , we indicated that we will use a file named heroku.yaml for configuration. This file will map configuration values in our application to environment variables in the Heroku platform. Your configuration file may vary, but it is important to note that if you are using a database, the database credentials are provided through a connection string . A connection string looks like this: postgres://user:password@host:5432/name and by default, Heroku stores it in the environment variable named DATABASE_URL . In heroku.yaml (which you will need to create in your project directory), you can reference an environment variable by prefixing its name with a $ . When using the built-in DatabaseConfiguration type, you can assign the connection string like so: database: $DATABASE_URL !!! warning \"Your heroku.yaml might be different\" Make sure the structure of your heroku.yaml file matches the expected structure in your application's Configuration subclass. Check heroku.yaml into version control. git commit -am \"add heroku.yaml\"","title":"Step 3: Configuring Application Values"},{"location":"deploy/deploy_heroku/#step-4-running-the-conduit-application","text":"If your application uses a database, make sure you have generated your migration file(s) and added it to version control. The Procfile will ensure that database is up to date with any migrations checked into source control before running your app. Generate your migration file with the following command from your project directory and then check it into version control: conduit db generate git commit -am \"adds migration files\" Now, you can deploy your application. It's as simple as this: git push heroku master This command pushes your code to a remote git server hosted by Heroku, which triggers your application to run its release script. Now that your application's database schema has been uploaded, you can configure your OAuth 2 server with client identifiers if you are using package:conduit/managed_auth . The following command will run within your application's remote environment. heroku run /app/dart-sdk/bin/pub global run conduit:conduit auth add-client --id com.app.standard --secret secret --connect \\$DATABASE_URL Finally, scale up a dyno and the application will start receiving requests: heroku ps:scale web=1 Now your application is running!","title":"Step 4: Running the Conduit Application"},{"location":"deploy/deploy_local/","text":"Deploy on a Local Machine Before You Begin This guide requires that you have created a Conduit project. If not, please refer to the first part of the Tutorial . Overview Create a local database. Upload the application schema to the local database. Add an OAuth 2.0 client. Modify the configuration file. Run the application. Step 1: Create a Local Database Create a database with the same name as your application and a user that can access that database. Run the following SQL locally with a user that has privileges to create databases. CREATE DATABASE app_name; CREATE USER app_name_user WITH CREATEDB; ALTER USER app_name_user WITH PASSWORD 'yourpassword'; GRANT ALL ON DATABASE app_name TO app_name_user; !!! warning \"dart_test database\" Do not use the name 'dart_test' for the database; this database is used by Conduit to run tests by default. Step 2: Upload the Application Schema If you have not yet created database migration files for your project, run the database schema generation tool from the project directory: conduit db generate This command creates the file migrations/00000001_initial.migration.dart . Now, run the database migration tool to execute the migration file against the local database. Ensure that the values for the option --connect match those of the database created in the last step. conduit db upgrade --connect postgres://app_name_user:yourpassword@localhost:5432/app_name (Note that you may provide database credentials in a file named database.yaml instead of using --connect . See conduit db --help for details.) Step 3: Add an OAuth 2.0 client. If you are using package:conduit/managed_auth , you'll want to create an OAuth2 client identifier. From the command line, run the following, ensuring that the values for the option --connect match the recently created database. conduit auth add-client --id com.app_name.standard --secret abcdefghi --connect postgres://app_name_user:yourpassword@localhost:5432/app_name Step 4: Modify the Configuration File If config.yaml doesn't exist, create it by copying the configuration file template config.yaml.src . In config.yaml , update the database credentials to the local database. database: username: app_name_user password: yourpassword host: localhost port: 5432 databaseName: app_name Step 5: Run the Application From the project directory, run: conduit serve Your application is now running. You may also run the generated start script in your project's bin directory: dart bin/main.dart If you restart the application, the data in your database will remain.","title":"Deploy Locally (VM)"},{"location":"deploy/deploy_local/#deploy-on-a-local-machine","text":"","title":"Deploy on a Local Machine"},{"location":"deploy/deploy_local/#before-you-begin","text":"This guide requires that you have created a Conduit project. If not, please refer to the first part of the Tutorial .","title":"Before You Begin"},{"location":"deploy/deploy_local/#overview","text":"Create a local database. Upload the application schema to the local database. Add an OAuth 2.0 client. Modify the configuration file. Run the application.","title":"Overview"},{"location":"deploy/deploy_local/#step-1-create-a-local-database","text":"Create a database with the same name as your application and a user that can access that database. Run the following SQL locally with a user that has privileges to create databases. CREATE DATABASE app_name; CREATE USER app_name_user WITH CREATEDB; ALTER USER app_name_user WITH PASSWORD 'yourpassword'; GRANT ALL ON DATABASE app_name TO app_name_user; !!! warning \"dart_test database\" Do not use the name 'dart_test' for the database; this database is used by Conduit to run tests by default.","title":"Step 1: Create a Local Database"},{"location":"deploy/deploy_local/#step-2-upload-the-application-schema","text":"If you have not yet created database migration files for your project, run the database schema generation tool from the project directory: conduit db generate This command creates the file migrations/00000001_initial.migration.dart . Now, run the database migration tool to execute the migration file against the local database. Ensure that the values for the option --connect match those of the database created in the last step. conduit db upgrade --connect postgres://app_name_user:yourpassword@localhost:5432/app_name (Note that you may provide database credentials in a file named database.yaml instead of using --connect . See conduit db --help for details.)","title":"Step 2: Upload the Application Schema"},{"location":"deploy/deploy_local/#step-3-add-an-oauth-20-client","text":"If you are using package:conduit/managed_auth , you'll want to create an OAuth2 client identifier. From the command line, run the following, ensuring that the values for the option --connect match the recently created database. conduit auth add-client --id com.app_name.standard --secret abcdefghi --connect postgres://app_name_user:yourpassword@localhost:5432/app_name","title":"Step 3: Add an OAuth 2.0 client."},{"location":"deploy/deploy_local/#step-4-modify-the-configuration-file","text":"If config.yaml doesn't exist, create it by copying the configuration file template config.yaml.src . In config.yaml , update the database credentials to the local database. database: username: app_name_user password: yourpassword host: localhost port: 5432 databaseName: app_name","title":"Step 4: Modify the Configuration File"},{"location":"deploy/deploy_local/#step-5-run-the-application","text":"From the project directory, run: conduit serve Your application is now running. You may also run the generated start script in your project's bin directory: dart bin/main.dart If you restart the application, the data in your database will remain.","title":"Step 5: Run the Application"},{"location":"deploy/script/","text":"Script You may also run Conduit applications with a standalone script, instead of conduit serve . In fact, conduit serve creates a temporary Dart script to run the application. If you created your application with conduit create , a standalone already exists in your project named bin/main.dart . A sample script looks like this: import 'dart:async'; import 'dart:io'; import 'package:conduit/conduit.dart'; import 'package:my_application/my_application.dart'; Future main() async { var app = new Application<MyApplicationChannel>() ..options.port = 8888 ..options.configurationFilePath = \"config.yaml\"; await app.start(numberOfInstances: 3); } This script can be used in place of conduit serve , but you must configure all ApplicationOptions in this script and not through the CLI.","title":"Deploying without aqueduct serve (VM)"},{"location":"deploy/script/#script","text":"You may also run Conduit applications with a standalone script, instead of conduit serve . In fact, conduit serve creates a temporary Dart script to run the application. If you created your application with conduit create , a standalone already exists in your project named bin/main.dart . A sample script looks like this: import 'dart:async'; import 'dart:io'; import 'package:conduit/conduit.dart'; import 'package:my_application/my_application.dart'; Future main() async { var app = new Application<MyApplicationChannel>() ..options.port = 8888 ..options.configurationFilePath = \"config.yaml\"; await app.start(numberOfInstances: 3); } This script can be used in place of conduit serve , but you must configure all ApplicationOptions in this script and not through the CLI.","title":"Script"},{"location":"http/","text":"index Tasks A Conduit application serves HTTP clients by sending responses for requests. You create and link Controller objects to handle requests. There are many subclasses of Controller that handle common tasks, and you often create your own subclasses of Controller to implement application logic. Most of your logic is implemented in subclasses of ResourceController , a controller type geared for REST API endpoints. You create a subclass of ApplicationChannel to configure controllers used by your application. This subclass also initializes any services your application will use to fulfill requests, like database connections or third party API connections. Most often, you use a Router controller at the entry point of your application channel to modularize your application logic. Your application may have many configurable options. This configuration is handled in your application channel. Configuration file management is provided by application-specific Configuration subclasses that add type and name safety to your configuration files. Your application is run by using the conduit serve command or the bin/main.dart script. In either case, your application starts by creating multiple, memory-isolated threads that replicate your ApplicationChannel . Guides Handling Requests and Sending Responsers Serializing Request and Response Bodies Routing Request Binding with ResourceControllers Serving Files and Caching Websockets Uploading Files","title":"Overview"},{"location":"http/#index","text":"","title":"index"},{"location":"http/#tasks","text":"A Conduit application serves HTTP clients by sending responses for requests. You create and link Controller objects to handle requests. There are many subclasses of Controller that handle common tasks, and you often create your own subclasses of Controller to implement application logic. Most of your logic is implemented in subclasses of ResourceController , a controller type geared for REST API endpoints. You create a subclass of ApplicationChannel to configure controllers used by your application. This subclass also initializes any services your application will use to fulfill requests, like database connections or third party API connections. Most often, you use a Router controller at the entry point of your application channel to modularize your application logic. Your application may have many configurable options. This configuration is handled in your application channel. Configuration file management is provided by application-specific Configuration subclasses that add type and name safety to your configuration files. Your application is run by using the conduit serve command or the bin/main.dart script. In either case, your application starts by creating multiple, memory-isolated threads that replicate your ApplicationChannel .","title":"Tasks"},{"location":"http/#guides","text":"Handling Requests and Sending Responsers Serializing Request and Response Bodies Routing Request Binding with ResourceControllers Serving Files and Caching Websockets Uploading Files","title":"Guides"},{"location":"http/controller/","text":"Handling Requests: Fundamentals In Conduit, HTTP requests and responses are instances of Request s and Response s. For each HTTP request an application receives, an instance of Request is created. A Response must be created for each request. Responses are created by controller objects . This guide discusses the behavior and initialization of controllers. You can read more about request and response objects here . Overview A controller is the basic building block of a Conduit application. A controller handles an HTTP request in some way. For example, a controller could return a 200 OK response with a JSON-encoded list of city names. A controller could also check a request to make sure it had the right credentials in its authorization header. Controllers are linked together to compose their behaviors into a channel . A channel handles a request by performing each of its controllers' behavior in order. For example, a channel might verify the credentials of a request and then return a list of city names by composing two controllers that take each of these actions. You subclass controllers to provide their request handling logic, and there are common controller subclasses in Conduit for your use. Linking Controllers Controllers are linked with their link method. This method takes a closure that returns the next controller in the channel. The following shows a channel composed of two controllers: final controller = VerifyController(); controller.link(() => ResponseController()); In the above, VerifyController links ResponseController . A request handled by the verifying controller can either respond to the request or let the response controller handle it. If the verifying controller sends a respond, the response controller will never receive the request. Any number of controllers can be linked, but the last controller linked must respond to a request. Controllers that always respond to request are called endpoint controllers . Middleware controllers verify or modify the request, and typically only respond when an error is encountered. Linking occurs in an application channel , and is finalized during startup of your application (i.e., once you have set up your controllers, the cannot be changed once the application starts receiving requests). Subclassing Controller to Handle Requests Every Controller implements its handle method to handle a request. You override this method in your controllers to provide the logic for your controllers. The following is an example of an endpoint controller, because it always sends a response: class NoteController extends Controller { @override Future<RequestOrResponse> handle(Request request) async { final notes = await fetchNotesFromDatabase(); return Response.ok(notes); } } This handle method returns a Response object. Any time a controller returns a response, Conduit sends a response to the client and terminates the request so that no other controllers can handle it. A middleware controller returns a response when it can provide the response or for error conditions. For example, an Authorizer controller returns a 401 Unauthorized response if the request's credentials are invalid. To let the request pass to the next controller, you must return the request object. As an example, the pseudo-code for an Authorizer looks like this: class Authorizer extends Controller { @override Future<RequestOrResponse> handle(Request request) async { if (isValid(request)) { return request; } return Response.unauthorized(); } } !!! tip \"Endpoint Controllers\" In most cases, endpoint controllers are created by subclassing ResourceController . This controller allows you to declare more than one handler method in a controller to better organize logic. For example, one method might handle POST requests, while another handles GET requests. Modifying a Response with Middleware A middleware controller can add a response modifier to a request. When an endpoint controller eventually creates a response, these modifiers are applied to the response before it is sent. Modifiers are added by invoking addResponseModifier on a request. class Versioner extends Controller { Future<RequestOrResponse> handle(Request request) async { request.addResponseModifier((response) { response.headers[\"x-api-version\"] = \"2.1\"; }); return request; } } Any number of controllers can add a response modifier to a request; they will be processed in the order that they were added. Response modifiers are applied before the response body is encoded, allowing the body object to be manipulated. Response modifiers are invoked regardless of the response generated by the endpoint controller. If an uncaught error is thrown while adding response modifiers, any remaining response modifiers are not called and a 500 Server Error response is sent. Linking Functions For simple behavior, functions with the same signature as handle can be linked to controllers: router .route(\"/path\") .linkFunction((req) async => req); .linkFunction((req) async => Response.ok(null)); Linking a function has all of the same behavior as Controller.handle : it can return a request or response, automatically handles exceptions, and can have controllers (and functions) linked to it. Controller Instantiation and Recycling It is important to understand why link takes a closure, instead of a controller object. Conduit is an object oriented framework. Objects have both state and behavior. An application will receive multiple requests that will be handled by the same type of controller. If a mutable controller object were reused to handle multiple requests, it could retain some of its state between requests. This would create problems that are difficult to debug. Most controllers are immutable - in other words, all of their properties are final and they have no setters. This (mostly) ensures that the controller won't change behavior between requests. When a controller is immutable, the link closure is invoked once to create and link the controller object, and then the closure is discarded. The same controller object will be reused for every request. Controllers can be mutable, with the caveat that they cannot be reused for multiple requests. For example, a ResourceController can have properties that are bound to the values of a request, and therefore these properties will change and a new instance must be created for each request. A mutable Controller subclass must implement Recyclable<T> . The link closure will be invoked for each request, creating a new instance of the recyclable controller to handle the request. If a controller has an expensive initialization process, the results of that initialization can be calculated once and reused for each controller instance by implementing the methods from Recyclable<T> . class MyControllerState { dynamic stuff; } class MyController extends Controller implements Recyclable<MyControllerState> { @override MyControllerState get recycledState => expensiveCalculation(); @override void restore(MyControllerState state) { _restoredState = state; } MyControllerState _restoredState; @override FutureOr<RequestOrResponse> handle(Request request) async { /* use _restoredState */ return new Response.ok(...); } } The recycledState getter is called once, when the controller is first linked. Each new instance of a recyclable controller has its restore method invoked prior to handling the request, and the data returned by recycledState is passed as an argument. As an example, ResourceController 'compiles' its operation methods. The compiled product is stored as recycled state so that future instances can bind request data more efficiently. Exception Handling If an exception or error is thrown during the handling of a request, the controller currently handling the request will catch it. For the majority of values caught, a controller will send a 500 Server Response. The details of the exception or error will be logged , and the request is removed from the channel (it will not be passed to a linked controller). This is the default behavior for all thrown values except Response and HandlerException . Throwing Responses A Response can be thrown at any time; the controller handling the request will catch it and send it to the client. This completes the request. This might not seem useful, for example, the following shows a silly use of this behavior: class Thrower extends Controller { @override Future<RequestOrResponse> handle(Request request) async { if (!isForbidden(request)) { throw new Response.forbidden(); } return Response.ok(null); } } Throwing HandlerExceptions Exceptions can implement HandlerException to provide a response other than the default when thrown. For example, an application that handles bank transactions might declare an exception for invalid withdrawals: enum WithdrawalProblem { insufficientFunds, bankClosed } class WithdrawalException implements Exception { WithdrawalException(this.problem); final WithdrawalProblem problem; } Controller code can catch this exception to return a different status code depending on the exact problem with a withdrawal. If this code has to be written in multiple places, it is useful for WithdrawalException to implement HandlerException . An implementor must provide an implementation for response : class WithdrawalException implements HandlerException { WithdrawalException(this.problem); final WithdrawalProblem problem; @override Response get response { switch (problem) { case WithdrawalProblem.insufficientFunds: return new Response.badRequest(body: {\"error\": \"insufficient_funds\"}); case WithdrawalProblem.bankClosed: return new Response.badRequest(body: {\"error\": \"bank_closed\"}); } } } CORS Headers and Preflight Requests Controller s have built-in behavior for handling CORS requests. They will automatically respond to OPTIONS preflight requests and attach CORS headers to any other response. See the chapter on CORS for more details.","title":"Handling Requests and Sending Response"},{"location":"http/controller/#handling-requests-fundamentals","text":"In Conduit, HTTP requests and responses are instances of Request s and Response s. For each HTTP request an application receives, an instance of Request is created. A Response must be created for each request. Responses are created by controller objects . This guide discusses the behavior and initialization of controllers. You can read more about request and response objects here .","title":"Handling Requests: Fundamentals"},{"location":"http/controller/#overview","text":"A controller is the basic building block of a Conduit application. A controller handles an HTTP request in some way. For example, a controller could return a 200 OK response with a JSON-encoded list of city names. A controller could also check a request to make sure it had the right credentials in its authorization header. Controllers are linked together to compose their behaviors into a channel . A channel handles a request by performing each of its controllers' behavior in order. For example, a channel might verify the credentials of a request and then return a list of city names by composing two controllers that take each of these actions. You subclass controllers to provide their request handling logic, and there are common controller subclasses in Conduit for your use.","title":"Overview"},{"location":"http/controller/#linking-controllers","text":"Controllers are linked with their link method. This method takes a closure that returns the next controller in the channel. The following shows a channel composed of two controllers: final controller = VerifyController(); controller.link(() => ResponseController()); In the above, VerifyController links ResponseController . A request handled by the verifying controller can either respond to the request or let the response controller handle it. If the verifying controller sends a respond, the response controller will never receive the request. Any number of controllers can be linked, but the last controller linked must respond to a request. Controllers that always respond to request are called endpoint controllers . Middleware controllers verify or modify the request, and typically only respond when an error is encountered. Linking occurs in an application channel , and is finalized during startup of your application (i.e., once you have set up your controllers, the cannot be changed once the application starts receiving requests).","title":"Linking Controllers"},{"location":"http/controller/#subclassing-controller-to-handle-requests","text":"Every Controller implements its handle method to handle a request. You override this method in your controllers to provide the logic for your controllers. The following is an example of an endpoint controller, because it always sends a response: class NoteController extends Controller { @override Future<RequestOrResponse> handle(Request request) async { final notes = await fetchNotesFromDatabase(); return Response.ok(notes); } } This handle method returns a Response object. Any time a controller returns a response, Conduit sends a response to the client and terminates the request so that no other controllers can handle it. A middleware controller returns a response when it can provide the response or for error conditions. For example, an Authorizer controller returns a 401 Unauthorized response if the request's credentials are invalid. To let the request pass to the next controller, you must return the request object. As an example, the pseudo-code for an Authorizer looks like this: class Authorizer extends Controller { @override Future<RequestOrResponse> handle(Request request) async { if (isValid(request)) { return request; } return Response.unauthorized(); } } !!! tip \"Endpoint Controllers\" In most cases, endpoint controllers are created by subclassing ResourceController . This controller allows you to declare more than one handler method in a controller to better organize logic. For example, one method might handle POST requests, while another handles GET requests.","title":"Subclassing Controller to Handle Requests"},{"location":"http/controller/#modifying-a-response-with-middleware","text":"A middleware controller can add a response modifier to a request. When an endpoint controller eventually creates a response, these modifiers are applied to the response before it is sent. Modifiers are added by invoking addResponseModifier on a request. class Versioner extends Controller { Future<RequestOrResponse> handle(Request request) async { request.addResponseModifier((response) { response.headers[\"x-api-version\"] = \"2.1\"; }); return request; } } Any number of controllers can add a response modifier to a request; they will be processed in the order that they were added. Response modifiers are applied before the response body is encoded, allowing the body object to be manipulated. Response modifiers are invoked regardless of the response generated by the endpoint controller. If an uncaught error is thrown while adding response modifiers, any remaining response modifiers are not called and a 500 Server Error response is sent.","title":"Modifying a Response with Middleware"},{"location":"http/controller/#linking-functions","text":"For simple behavior, functions with the same signature as handle can be linked to controllers: router .route(\"/path\") .linkFunction((req) async => req); .linkFunction((req) async => Response.ok(null)); Linking a function has all of the same behavior as Controller.handle : it can return a request or response, automatically handles exceptions, and can have controllers (and functions) linked to it.","title":"Linking Functions"},{"location":"http/controller/#controller-instantiation-and-recycling","text":"It is important to understand why link takes a closure, instead of a controller object. Conduit is an object oriented framework. Objects have both state and behavior. An application will receive multiple requests that will be handled by the same type of controller. If a mutable controller object were reused to handle multiple requests, it could retain some of its state between requests. This would create problems that are difficult to debug. Most controllers are immutable - in other words, all of their properties are final and they have no setters. This (mostly) ensures that the controller won't change behavior between requests. When a controller is immutable, the link closure is invoked once to create and link the controller object, and then the closure is discarded. The same controller object will be reused for every request. Controllers can be mutable, with the caveat that they cannot be reused for multiple requests. For example, a ResourceController can have properties that are bound to the values of a request, and therefore these properties will change and a new instance must be created for each request. A mutable Controller subclass must implement Recyclable<T> . The link closure will be invoked for each request, creating a new instance of the recyclable controller to handle the request. If a controller has an expensive initialization process, the results of that initialization can be calculated once and reused for each controller instance by implementing the methods from Recyclable<T> . class MyControllerState { dynamic stuff; } class MyController extends Controller implements Recyclable<MyControllerState> { @override MyControllerState get recycledState => expensiveCalculation(); @override void restore(MyControllerState state) { _restoredState = state; } MyControllerState _restoredState; @override FutureOr<RequestOrResponse> handle(Request request) async { /* use _restoredState */ return new Response.ok(...); } } The recycledState getter is called once, when the controller is first linked. Each new instance of a recyclable controller has its restore method invoked prior to handling the request, and the data returned by recycledState is passed as an argument. As an example, ResourceController 'compiles' its operation methods. The compiled product is stored as recycled state so that future instances can bind request data more efficiently.","title":"Controller Instantiation and Recycling"},{"location":"http/controller/#exception-handling","text":"If an exception or error is thrown during the handling of a request, the controller currently handling the request will catch it. For the majority of values caught, a controller will send a 500 Server Response. The details of the exception or error will be logged , and the request is removed from the channel (it will not be passed to a linked controller). This is the default behavior for all thrown values except Response and HandlerException .","title":"Exception Handling"},{"location":"http/controller/#throwing-responses","text":"A Response can be thrown at any time; the controller handling the request will catch it and send it to the client. This completes the request. This might not seem useful, for example, the following shows a silly use of this behavior: class Thrower extends Controller { @override Future<RequestOrResponse> handle(Request request) async { if (!isForbidden(request)) { throw new Response.forbidden(); } return Response.ok(null); } }","title":"Throwing Responses"},{"location":"http/controller/#throwing-handlerexceptions","text":"Exceptions can implement HandlerException to provide a response other than the default when thrown. For example, an application that handles bank transactions might declare an exception for invalid withdrawals: enum WithdrawalProblem { insufficientFunds, bankClosed } class WithdrawalException implements Exception { WithdrawalException(this.problem); final WithdrawalProblem problem; } Controller code can catch this exception to return a different status code depending on the exact problem with a withdrawal. If this code has to be written in multiple places, it is useful for WithdrawalException to implement HandlerException . An implementor must provide an implementation for response : class WithdrawalException implements HandlerException { WithdrawalException(this.problem); final WithdrawalProblem problem; @override Response get response { switch (problem) { case WithdrawalProblem.insufficientFunds: return new Response.badRequest(body: {\"error\": \"insufficient_funds\"}); case WithdrawalProblem.bankClosed: return new Response.badRequest(body: {\"error\": \"bank_closed\"}); } } }","title":"Throwing HandlerExceptions"},{"location":"http/controller/#cors-headers-and-preflight-requests","text":"Controller s have built-in behavior for handling CORS requests. They will automatically respond to OPTIONS preflight requests and attach CORS headers to any other response. See the chapter on CORS for more details.","title":"CORS Headers and Preflight Requests"},{"location":"http/file_upload/","text":"Uploading Files Files are often uploaded as part of a multipart form request. A request of this type has the content-type multipart/form-data and is body is made up of multiple data parts . These segments are typically the base64 encoded contents of a file and accompanying metadata for the upload. Multipart data is decoded using objects from package:mime . You must add this package your application's pubspec.yaml file: dependencies: mime: any # prefer a better constraint than this By default, resource controllers only accept application/json requests and must be configured to accept multipart/form-data requests. To read each part, create a MimeMultipartTransformer and stream the body into it. The following shows an example: import 'package:conduit/conduit.dart'; import 'package:mime/mime.dart'; class MyController extends ResourceController { MyController() { acceptedContentTypes = [ContentType(\"multipart\", \"form-data\")]; } @Operation.post() Future<Response> postForm() async {} final boundary = request.raw.headers.contentType.parameters[\"boundary\"]; final transformer = MimeMultipartTransformer(boundary); final bodyBytes = await request.body.decode<List<int>>(); // Pay special attention to the square brackets in the argument: final bodyStream = Stream.fromIterable([bodyBytes]); final parts = await transformer.bind(bodyStream).toList(); for (var part in parts) { final headers = part.headers; final content = await part.toList(); // Use headers['content-disposition'] to identify the part // The byte content of the part is available in 'content'. } } }","title":"Uploading Files"},{"location":"http/file_upload/#uploading-files","text":"Files are often uploaded as part of a multipart form request. A request of this type has the content-type multipart/form-data and is body is made up of multiple data parts . These segments are typically the base64 encoded contents of a file and accompanying metadata for the upload. Multipart data is decoded using objects from package:mime . You must add this package your application's pubspec.yaml file: dependencies: mime: any # prefer a better constraint than this By default, resource controllers only accept application/json requests and must be configured to accept multipart/form-data requests. To read each part, create a MimeMultipartTransformer and stream the body into it. The following shows an example: import 'package:conduit/conduit.dart'; import 'package:mime/mime.dart'; class MyController extends ResourceController { MyController() { acceptedContentTypes = [ContentType(\"multipart\", \"form-data\")]; } @Operation.post() Future<Response> postForm() async {} final boundary = request.raw.headers.contentType.parameters[\"boundary\"]; final transformer = MimeMultipartTransformer(boundary); final bodyBytes = await request.body.decode<List<int>>(); // Pay special attention to the square brackets in the argument: final bodyStream = Stream.fromIterable([bodyBytes]); final parts = await transformer.bind(bodyStream).toList(); for (var part in parts) { final headers = part.headers; final content = await part.toList(); // Use headers['content-disposition'] to identify the part // The byte content of the part is available in 'content'. } } }","title":"Uploading Files"},{"location":"http/request_and_response/","text":"Serializing Request and Response Bodies In Conduit, HTTP requests and responses are instances of Request s and Response s. For each HTTP request an application receives, an instance of Request is created. A Response must be created for each request. Responses are created by controller objects . This guide discusses the behavior of request and response objects. The Request Object A Request is created for each HTTP request to your application. A Request stores everything about the HTTP request and has some additional behavior that makes reading from them easier. You handle requests by writing code in a controller object or closures. All properties of a request are available in its raw property (a Dart standard library HttpRequest ). A Request has attachments that data can be attached to in a controller for use by a linked controller: router.route(\"/path\").linkFunction((req) { req.attachments[\"key\"] = \"value\"; }).linkFunction((req) { return Response.ok({\"key\": req.attachments[\"value\"]}); }); A Request also has two built-in attachments, authorization and path . authorization contains authorization information from an Authorizer and path has request path information from a Router . The Response Object An Response has a status code, headers and body. The default constructor takes a status code, header map and body object. There are many named constructors for common response types: Response(200, {\"x-header\": \"value\"}, body: [1, 2, 3]); Response.ok({\"key\": \"value\"}); Response.created(); Response.badRequest(body: {\"error\": \"reason\"}); Headers are encoded according to dart:io.HttpHeaders.add . For body encoding behavior, see the following sections. Encoding and Decoding the HTTP Body Request and Response objects have behavior for handling the HTTP body. You decode the contents of a Request body into Dart objects that are used in your code. You provide a Dart object to a Response and it is automatically encoded according to the content-type of the response. Decoding Request Bodies Every Request has a body property. This object decodes the bytes from the request body into Dart objects. The behavior for decoding is determined by the content-type header of the request (see the section on CodecRegistry later in this guide). When you decode a body, you can specify the Dart object type you expect it to be. If the decoded body object is not the expected type, an exception that sends a 400 Bad Request error is thrown. // Ensures that the decoded body is a Map<String, dynamic> final map = await request.body.decode<Map<String, dynamic>>(); // Takes whatever object the body is decoded into final anyObject = await request.body.decode(); Once a request's body has been decoded, it can be accessed through a synchronous as method. This method also takes a type argument to enforce the type of the decoded body object. final map = request.body.as<Map<String, dynamic>>(); !!! tip \"Inferred Types\" You don't need to provide a type argument to as or decode if the type can be inferred. For example, object.read(await request.body.decode()) will infer the type of the decoded body as a Map<String, dynamic> without having to provide type parameters. If a body cannot be decoded according to its content-type (the data is malformed), an error is thrown that sends the appropriate error response to the client. For more request body behavior, see the API reference for RequestBody , the section on body binding for ResourceControllers and a later section in this guide on Serializable . !!! note \"Max Body Size\" The size of a request body is limited to 10MB by default and can be changed by setting the value of RequestBody.maxSize during application initialization. Encoding Response Body Objects An HTTP response often contains a body . For example, the body in response to GET /users/1 might be JSON object that represents a user. To ensure the client understands that the body is a JSON object, it includes the header Content-Type: application/json; charset=utf-8 . When creating a Response that has a body, you provide a body object and a contentType . For example: var map = {\"key\": \"value\"}; // ContentType.json is the default, setting it may be omitted. // ContentType.json == `application/json; charset=utf-8' final response = Response.ok(map) ..contentType = ContentType.json; Body objects are encoded according to their content-type. In the above, map is first encoded as a JSON string and then to a list of UTF8 bytes. A ContentType is made up of three components: a primary type, a subtype and an optional character set. The primary and subtype determine the first conversion step and the charset determines the next. Each step is performed by an instance of Codec (from dart:convert ). For example, the content type application/json selects JsonCodec , while charset utf-8 selects Utf8Codec . These two codecs are run in succession to convert the Map to a list of bytes. The codec is selected by your application's CodecRegistry ; this is covered in later section. The body object must be valid for the selected codec. In the above example, a Map<String, dynamic> can be encoded by a JsonCodec . But if the body object cannot be encoded, a 500 Server Error response is sent. A valid input for one Codec may not be valid for another; it is up to you to ensure that the body object is valid for the contentType of the response. Not all content types require two conversion steps. For example, when serving an HTML file, the body object is already an HTML String . It will only be converted by a charset encoder: var html = \"<html></html>\"; var response = Response.ok(html) ..contentType = ContentType.html; And an image body object needs no conversion at all, since it is already a list of bytes. If there is no registered codec for a content-type, the body object must be a byte array ( List<int> where each value is between 0-255). final imageFile = File(\"image.jpg\"); final imageBytes = await imageFile.readAsBytes(); final response = Response.ok(imageBytes) ..contentType = ContentType(\"image\", \"jpeg\"); You may disable the automatic encoding of a body as long as the body object is a byte array: final jsonBytes = utf8.encode(json.encode({\"key\": \"value\"})); final response = Response.ok(jsonBytes)..encodeBody = false; See a later section for more details on content type to codec mappings. Also, see the documentation for CodecRegistry for details on built-in codecs and adding codecs. Streaming Response Bodies A body object may also be a Stream<T> . Stream<T> body objects are most often used when serving files. This allows the contents of the file to be streamed from disk to the HTTP client without having to load the whole file into memory first. (See also FileController .) final imageFile = File(\"image.jpg\"); final imageByteStream = imageFile.openRead(); final response = new Response.ok(imageByteStream) ..contentType = new ContentType(\"image\", \"jpeg\"); When a body object is a Stream<T> , the response will not be sent until the stream is closed. For finite streams - like those from opened filed - this happens as soon as the entire file is read. For streams that you construct yourself, you must close the stream some time after the response has been returned. Codecs and Content Types In the above sections, we glossed over how a codec gets selected when preparing the response body. The common case of ManagedObject<T> body objects that are sent as UTF8 encoded JSON 'just works' and is suitable for most applications. When serving assets for a web application or different data formats like XML, it becomes important to understand how Conduit's codec registry works. CodecRegistry contains mappings from content types to Codec s. These codecs encode response bodies and decode request bodies. There are three built-in codecs for application/json , application/x-www-form-urlencoded and text/* . When a response is being sent, the repository is searched for an entry that exactly matches the primary and subtype of the Response.contentType . If an entry exists, the associated Codec starts the conversion. For example, if the content type is application/json; charset=utf-8 , the built-in application/json codec encodes the body object. If there isn't an exact match, but there is an entry for the primary type with the wildcard ( * ) subtype, that codec is used. For example, the built-in codec for text/* will be selected for both text/plain and text/html . If there was something special that had to be done for text/html , a more specific codec may be added for that type: class MyChannel extends ApplicationChannel { @override Future prepare() async { CodecRegistry.defaultInstance.add(ContentType(\"application\", \"html\"), HTMLCodec()); } } Codecs must be added in your ApplicationChannel.prepare method. The codec must implement Codec from dart:convert . In the above example, when a response's content type is text/html , the HTMLCodec will encode the body object. This codec takes precedence over text/* because it is more specific. When selecting a codec for a response body, the ContentType.charset doesn't impact which codec is selected. If a response's content-type has a charset, then a charset encoder like UTF8 will be applied as a last encoding step. For example, a response with content-type application/json; charset=utf-8 will encode the body object as a JSON string, which is then encoded as a list of UTF8 bytes. It is required that a response body's eventually encoded type is a list of bytes, so it follows that a codec that produces a string must have a charset. If there is no codec in the repository for the content type of a Response , the body object must be a List<int> or Stream<List<int>> . If you find yourself converting data prior to setting it as a body object, it may make sense to add your own codec to CodecRegistry . A request's body always starts as a list of bytes and is decoded into Dart objects. To decode a JSON request body, it first must be decoded from the list of UTF8 bytes into a string. It is possible that a client could omit the charset in its content-type header. Codecs added to CodecRegistry may specify a default charset to interpret a charset-less content-type. When a codec is added to the repository, if content-type's charset is non-null, that is the default. For example, the JSON codec is added like this: CodecRegistry.defaultInstance.add( ContentType(\"application\", \"json\", charset: \"utf-8\"), const JsonCodec(), allowCompression: true); If no charset is specified when registering a codec, no charset decoding occurs on a request body if one doesn't exist. Content-types that are decoded from a String should not use a default charset because the repository would always attempt to decode the body as a string first. Compression with gzip Body objects may be compressed with gzip if the HTTP client allows it and the CodecRegistry has been configured to compress the content type of the response. The three built-in codecs - application/json , application/x-www-form-urlencoded and text/* - are all configured to allow compression. Compression occurs as the last step of conversion and only if the HTTP client sends the Accept-Encoding: gzip header. Content types that are not in the codec repository will not trigger compression, even if the HTTP client allows compression with the Accept-Encoding header. This is to prevent binary contents like images from being 'compressed', since they are likely already compressed by a content-specific algorithm. In order for Conduit to compress a content type other than the built-in types, you may add a codec to the repository with the allowCompression flag. (The default value is true .) CodecRegistry.add( ContentType(\"application\", \"x-special\"), MyCodec(), allowCompression: true); You may also set whether or not a content type uses compression without having to specify a codec if no conversion step needs to occur: CodecRegistry.setAllowsCompression(new ContentType(\"application\", \"x-special\"), true); Serializable Objects Most request and response bodies are JSON objects and lists of objects. In Dart, JSON objects are maps. A Serializable object can be read from a map and converted back into a map. You subclass Serializable to assign keys from a map to properties of a your subclass, and to write its properties back to a map. This allows static types you declare in your application to represent expected request and response bodies. Conduit's ORM type ManagedObject is a Serializable , for example. Sending Serializable Objects as Response Bodies The body object of a response can be a Serializable . Before the response is sent, asMap() is called before the body object is encoded into JSON (or some other transmission format). For example, a single serializable object returned in a 200 OK response: final query = Query<Person>(context)..where((p) => p.id).equalTo(1); final person = await query.fetchOne(); final response = Response.ok(person); A response body object can also be a list of Serializable objects. final query = Query<Person>(context); final people = await query.fetch(); final response = Response.ok(people); The flow of a body object is shown in the following diagram. Each orange item is an allowed body object type and shows the steps it will go through when being encoded to the HTTP response body. For example, a Serializable goes through three steps, whereas a List<int> goes through zero steps and is added as-is to the HTTP response. Reading Serializable Objects from Request Bodies A serializable object can be read from a request body: final person = Person()..read(await request.body.decode()); A list of serializable objects as well: List<Map<String, dynamic>> objects = await request.body.decode(); final people = objects.map((o) => Person()..read(o)).toList(); Both serializable and a list of serializable can be bound to a operation method parameter in a ResourceController . @Operation.post() Future<Response> addPerson(@Bind.body() Person person) async { final insertedPerson = await context.insertObject(person); return Response.ok(insertedPerson); } Key Filtering Both read and Bind.body (when binding a Serializable ) support key filtering. A key filter is a list of keys that either discard keys from the body, requires keys in the body, or throws an error if a key exists in the body. Example: final person = Person() ..read(await request.body.decode(), ignore: [\"id\"], reject: [\"password\"], require: [\"name\", \"height\", \"weight\"]); In the above: if the body contains 'id', the value is discarded immediately; if the body contains 'password', a 400 status code exception is thrown; and if the body doesn't contain all of name, height and weight, a 400 status code exception is thrown. When binding a list of serializables, filters are applied to each element of the list. @Operation.post() Future<Response> addPerson(@Bind.body(reject: [\"privateInfo\"]) List<Person> people) async { // if any Person in the body contains the privateInfo key, a 400 Bad Request is sent and this method // is not called } Subclassing Serializable A Serializable object must implement a readFromMap() and asMap() . An object that extends Serializable may be used as a response body object directly: class Person extends Serializable { String name; String email; Map<String, dynamic> asMap() { return { \"name\": name, \"email\": email }; } void readFromMap(Map<String, dynamic> inputMap) { name = inputMap['name']; email = inputMap['email']; } } final person = Person(); final response = Response.ok(person); readFromMap is invoked by read , after all filters have been applied. Serializable and OpenAPI Generation See the section on how Serializable types work with OpenAPI documentation generation here .","title":"Serializing Request and Response Bodies"},{"location":"http/request_and_response/#serializing-request-and-response-bodies","text":"In Conduit, HTTP requests and responses are instances of Request s and Response s. For each HTTP request an application receives, an instance of Request is created. A Response must be created for each request. Responses are created by controller objects . This guide discusses the behavior of request and response objects.","title":"Serializing Request and Response Bodies"},{"location":"http/request_and_response/#the-request-object","text":"A Request is created for each HTTP request to your application. A Request stores everything about the HTTP request and has some additional behavior that makes reading from them easier. You handle requests by writing code in a controller object or closures. All properties of a request are available in its raw property (a Dart standard library HttpRequest ). A Request has attachments that data can be attached to in a controller for use by a linked controller: router.route(\"/path\").linkFunction((req) { req.attachments[\"key\"] = \"value\"; }).linkFunction((req) { return Response.ok({\"key\": req.attachments[\"value\"]}); }); A Request also has two built-in attachments, authorization and path . authorization contains authorization information from an Authorizer and path has request path information from a Router .","title":"The Request Object"},{"location":"http/request_and_response/#the-response-object","text":"An Response has a status code, headers and body. The default constructor takes a status code, header map and body object. There are many named constructors for common response types: Response(200, {\"x-header\": \"value\"}, body: [1, 2, 3]); Response.ok({\"key\": \"value\"}); Response.created(); Response.badRequest(body: {\"error\": \"reason\"}); Headers are encoded according to dart:io.HttpHeaders.add . For body encoding behavior, see the following sections.","title":"The Response Object"},{"location":"http/request_and_response/#encoding-and-decoding-the-http-body","text":"Request and Response objects have behavior for handling the HTTP body. You decode the contents of a Request body into Dart objects that are used in your code. You provide a Dart object to a Response and it is automatically encoded according to the content-type of the response.","title":"Encoding and Decoding the HTTP Body"},{"location":"http/request_and_response/#decoding-request-bodies","text":"Every Request has a body property. This object decodes the bytes from the request body into Dart objects. The behavior for decoding is determined by the content-type header of the request (see the section on CodecRegistry later in this guide). When you decode a body, you can specify the Dart object type you expect it to be. If the decoded body object is not the expected type, an exception that sends a 400 Bad Request error is thrown. // Ensures that the decoded body is a Map<String, dynamic> final map = await request.body.decode<Map<String, dynamic>>(); // Takes whatever object the body is decoded into final anyObject = await request.body.decode(); Once a request's body has been decoded, it can be accessed through a synchronous as method. This method also takes a type argument to enforce the type of the decoded body object. final map = request.body.as<Map<String, dynamic>>(); !!! tip \"Inferred Types\" You don't need to provide a type argument to as or decode if the type can be inferred. For example, object.read(await request.body.decode()) will infer the type of the decoded body as a Map<String, dynamic> without having to provide type parameters. If a body cannot be decoded according to its content-type (the data is malformed), an error is thrown that sends the appropriate error response to the client. For more request body behavior, see the API reference for RequestBody , the section on body binding for ResourceControllers and a later section in this guide on Serializable . !!! note \"Max Body Size\" The size of a request body is limited to 10MB by default and can be changed by setting the value of RequestBody.maxSize during application initialization.","title":"Decoding Request Bodies"},{"location":"http/request_and_response/#encoding-response-body-objects","text":"An HTTP response often contains a body . For example, the body in response to GET /users/1 might be JSON object that represents a user. To ensure the client understands that the body is a JSON object, it includes the header Content-Type: application/json; charset=utf-8 . When creating a Response that has a body, you provide a body object and a contentType . For example: var map = {\"key\": \"value\"}; // ContentType.json is the default, setting it may be omitted. // ContentType.json == `application/json; charset=utf-8' final response = Response.ok(map) ..contentType = ContentType.json; Body objects are encoded according to their content-type. In the above, map is first encoded as a JSON string and then to a list of UTF8 bytes. A ContentType is made up of three components: a primary type, a subtype and an optional character set. The primary and subtype determine the first conversion step and the charset determines the next. Each step is performed by an instance of Codec (from dart:convert ). For example, the content type application/json selects JsonCodec , while charset utf-8 selects Utf8Codec . These two codecs are run in succession to convert the Map to a list of bytes. The codec is selected by your application's CodecRegistry ; this is covered in later section. The body object must be valid for the selected codec. In the above example, a Map<String, dynamic> can be encoded by a JsonCodec . But if the body object cannot be encoded, a 500 Server Error response is sent. A valid input for one Codec may not be valid for another; it is up to you to ensure that the body object is valid for the contentType of the response. Not all content types require two conversion steps. For example, when serving an HTML file, the body object is already an HTML String . It will only be converted by a charset encoder: var html = \"<html></html>\"; var response = Response.ok(html) ..contentType = ContentType.html; And an image body object needs no conversion at all, since it is already a list of bytes. If there is no registered codec for a content-type, the body object must be a byte array ( List<int> where each value is between 0-255). final imageFile = File(\"image.jpg\"); final imageBytes = await imageFile.readAsBytes(); final response = Response.ok(imageBytes) ..contentType = ContentType(\"image\", \"jpeg\"); You may disable the automatic encoding of a body as long as the body object is a byte array: final jsonBytes = utf8.encode(json.encode({\"key\": \"value\"})); final response = Response.ok(jsonBytes)..encodeBody = false; See a later section for more details on content type to codec mappings. Also, see the documentation for CodecRegistry for details on built-in codecs and adding codecs.","title":"Encoding Response Body Objects"},{"location":"http/request_and_response/#streaming-response-bodies","text":"A body object may also be a Stream<T> . Stream<T> body objects are most often used when serving files. This allows the contents of the file to be streamed from disk to the HTTP client without having to load the whole file into memory first. (See also FileController .) final imageFile = File(\"image.jpg\"); final imageByteStream = imageFile.openRead(); final response = new Response.ok(imageByteStream) ..contentType = new ContentType(\"image\", \"jpeg\"); When a body object is a Stream<T> , the response will not be sent until the stream is closed. For finite streams - like those from opened filed - this happens as soon as the entire file is read. For streams that you construct yourself, you must close the stream some time after the response has been returned.","title":"Streaming Response Bodies"},{"location":"http/request_and_response/#codecs-and-content-types","text":"In the above sections, we glossed over how a codec gets selected when preparing the response body. The common case of ManagedObject<T> body objects that are sent as UTF8 encoded JSON 'just works' and is suitable for most applications. When serving assets for a web application or different data formats like XML, it becomes important to understand how Conduit's codec registry works. CodecRegistry contains mappings from content types to Codec s. These codecs encode response bodies and decode request bodies. There are three built-in codecs for application/json , application/x-www-form-urlencoded and text/* . When a response is being sent, the repository is searched for an entry that exactly matches the primary and subtype of the Response.contentType . If an entry exists, the associated Codec starts the conversion. For example, if the content type is application/json; charset=utf-8 , the built-in application/json codec encodes the body object. If there isn't an exact match, but there is an entry for the primary type with the wildcard ( * ) subtype, that codec is used. For example, the built-in codec for text/* will be selected for both text/plain and text/html . If there was something special that had to be done for text/html , a more specific codec may be added for that type: class MyChannel extends ApplicationChannel { @override Future prepare() async { CodecRegistry.defaultInstance.add(ContentType(\"application\", \"html\"), HTMLCodec()); } } Codecs must be added in your ApplicationChannel.prepare method. The codec must implement Codec from dart:convert . In the above example, when a response's content type is text/html , the HTMLCodec will encode the body object. This codec takes precedence over text/* because it is more specific. When selecting a codec for a response body, the ContentType.charset doesn't impact which codec is selected. If a response's content-type has a charset, then a charset encoder like UTF8 will be applied as a last encoding step. For example, a response with content-type application/json; charset=utf-8 will encode the body object as a JSON string, which is then encoded as a list of UTF8 bytes. It is required that a response body's eventually encoded type is a list of bytes, so it follows that a codec that produces a string must have a charset. If there is no codec in the repository for the content type of a Response , the body object must be a List<int> or Stream<List<int>> . If you find yourself converting data prior to setting it as a body object, it may make sense to add your own codec to CodecRegistry . A request's body always starts as a list of bytes and is decoded into Dart objects. To decode a JSON request body, it first must be decoded from the list of UTF8 bytes into a string. It is possible that a client could omit the charset in its content-type header. Codecs added to CodecRegistry may specify a default charset to interpret a charset-less content-type. When a codec is added to the repository, if content-type's charset is non-null, that is the default. For example, the JSON codec is added like this: CodecRegistry.defaultInstance.add( ContentType(\"application\", \"json\", charset: \"utf-8\"), const JsonCodec(), allowCompression: true); If no charset is specified when registering a codec, no charset decoding occurs on a request body if one doesn't exist. Content-types that are decoded from a String should not use a default charset because the repository would always attempt to decode the body as a string first.","title":"Codecs and Content Types"},{"location":"http/request_and_response/#compression-with-gzip","text":"Body objects may be compressed with gzip if the HTTP client allows it and the CodecRegistry has been configured to compress the content type of the response. The three built-in codecs - application/json , application/x-www-form-urlencoded and text/* - are all configured to allow compression. Compression occurs as the last step of conversion and only if the HTTP client sends the Accept-Encoding: gzip header. Content types that are not in the codec repository will not trigger compression, even if the HTTP client allows compression with the Accept-Encoding header. This is to prevent binary contents like images from being 'compressed', since they are likely already compressed by a content-specific algorithm. In order for Conduit to compress a content type other than the built-in types, you may add a codec to the repository with the allowCompression flag. (The default value is true .) CodecRegistry.add( ContentType(\"application\", \"x-special\"), MyCodec(), allowCompression: true); You may also set whether or not a content type uses compression without having to specify a codec if no conversion step needs to occur: CodecRegistry.setAllowsCompression(new ContentType(\"application\", \"x-special\"), true);","title":"Compression with gzip"},{"location":"http/request_and_response/#serializable-objects","text":"Most request and response bodies are JSON objects and lists of objects. In Dart, JSON objects are maps. A Serializable object can be read from a map and converted back into a map. You subclass Serializable to assign keys from a map to properties of a your subclass, and to write its properties back to a map. This allows static types you declare in your application to represent expected request and response bodies. Conduit's ORM type ManagedObject is a Serializable , for example.","title":"Serializable Objects"},{"location":"http/request_and_response/#sending-serializable-objects-as-response-bodies","text":"The body object of a response can be a Serializable . Before the response is sent, asMap() is called before the body object is encoded into JSON (or some other transmission format). For example, a single serializable object returned in a 200 OK response: final query = Query<Person>(context)..where((p) => p.id).equalTo(1); final person = await query.fetchOne(); final response = Response.ok(person); A response body object can also be a list of Serializable objects. final query = Query<Person>(context); final people = await query.fetch(); final response = Response.ok(people); The flow of a body object is shown in the following diagram. Each orange item is an allowed body object type and shows the steps it will go through when being encoded to the HTTP response body. For example, a Serializable goes through three steps, whereas a List<int> goes through zero steps and is added as-is to the HTTP response.","title":"Sending Serializable Objects as Response Bodies"},{"location":"http/request_and_response/#reading-serializable-objects-from-request-bodies","text":"A serializable object can be read from a request body: final person = Person()..read(await request.body.decode()); A list of serializable objects as well: List<Map<String, dynamic>> objects = await request.body.decode(); final people = objects.map((o) => Person()..read(o)).toList(); Both serializable and a list of serializable can be bound to a operation method parameter in a ResourceController . @Operation.post() Future<Response> addPerson(@Bind.body() Person person) async { final insertedPerson = await context.insertObject(person); return Response.ok(insertedPerson); }","title":"Reading Serializable Objects from Request Bodies"},{"location":"http/request_and_response/#key-filtering","text":"Both read and Bind.body (when binding a Serializable ) support key filtering. A key filter is a list of keys that either discard keys from the body, requires keys in the body, or throws an error if a key exists in the body. Example: final person = Person() ..read(await request.body.decode(), ignore: [\"id\"], reject: [\"password\"], require: [\"name\", \"height\", \"weight\"]); In the above: if the body contains 'id', the value is discarded immediately; if the body contains 'password', a 400 status code exception is thrown; and if the body doesn't contain all of name, height and weight, a 400 status code exception is thrown. When binding a list of serializables, filters are applied to each element of the list. @Operation.post() Future<Response> addPerson(@Bind.body(reject: [\"privateInfo\"]) List<Person> people) async { // if any Person in the body contains the privateInfo key, a 400 Bad Request is sent and this method // is not called }","title":"Key Filtering"},{"location":"http/request_and_response/#subclassing-serializable","text":"A Serializable object must implement a readFromMap() and asMap() . An object that extends Serializable may be used as a response body object directly: class Person extends Serializable { String name; String email; Map<String, dynamic> asMap() { return { \"name\": name, \"email\": email }; } void readFromMap(Map<String, dynamic> inputMap) { name = inputMap['name']; email = inputMap['email']; } } final person = Person(); final response = Response.ok(person); readFromMap is invoked by read , after all filters have been applied.","title":"Subclassing Serializable"},{"location":"http/request_and_response/#serializable-and-openapi-generation","text":"See the section on how Serializable types work with OpenAPI documentation generation here .","title":"Serializable and OpenAPI Generation"},{"location":"http/resource_controller/","text":"ResourceController A ResourceController is a controller that provide conveniences for implementing endpoint controllers. A ResourceController must be subclassed, and in that subclass, you write a method for each operation on that type of resource. For example, a UserController might handle the following operations: creating a new user ( POST /users ) getting all users ( GET /users ) getting an individual user ( GET /users/:id ) updating an individual user ( PUT /users/:id ) deleting an individual user ( DELETE /users/:id ) These methods that are invoked for an operation are called operation methods . Operation Methods An operation method is an instance method of a ResourceController subclass that has an @Operation annotation. It must return an instance of Future<Response> . Here's an example: class CityController extends ResourceController { @Operation.get() Future<Response> getAllCities() async { return Response.ok([\"Atlanta\", \"Madison\", \"Mountain View\"]); } } The above operation method will be invoked when CityController handles GET requests without path variables. To handle operation methods with path variables, the name of the path variable is added to the @Operation annotation: class CityController extends ResourceController { @Operation.get() Future<Response> getAllCities() async { return Response.ok([\"Atlanta\", \"Madison\", \"Mountain View\"]); } @Operation.get('name') Future<Response> getCityByName() async { final id = request.path.variables['name']; return Response.ok(fetchCityWithName(name)); } } !!! note \"Path Variables\" This controller would be linked to the route specification /cities/[:name] , so that it can handle both of these operations. Read more about path variables in Routing . The named constructor of Operation tells us which HTTP method the operation method handles. The following named constructors exist: Operation.post() Operation.get() Operation.put() Operation.delete() The canonical Operation() constructor takes the HTTP method as its first argument for non-standard operations, e.g.: @Operation('PATCH', 'id') Future<Response> patchObjectWithID() async => ...; All Operation constructors take a variable list of path variables. There can be multiple path variables for an operation. An operation method will only be invoked if all of its path variables are present in the request path. There can be multiple operation methods for a given HTTP method, as long as each expects a different set of path variables. Here's an example of an operation that requires two path variables: @Operation.get('userID', 'itemID') Future<Response> getUserItem() async { final userID = request.path.variables['userID']; final itemID = request.path.variables['itemID']; return Response.ok(...); } If no operation method exists for a request, a 405 Method Not Allowed response is automatically sent and no operation method is invoked. Routing to a ResourceController A ResourceController subclass must be preceded by a Router in the application channel. The Router will parse path variables so that the controller can use them to determine which operation method should be invoked. A typical route to a ResourceController contains an optional identifying path variable: router .route(\"/cities/[:name]\") .link(() => CityController()); This route would allow CityController to implement operation methods for all HTTP methods with both no path variables and the 'name' path variable. It is considered good practice to break sub-resources into their own controller. For example, the following is preferred: router .route(\"/cities/[:name]\") .link(() => CityController()); router .route(\"/cities/:name/attractions/[:id]\") .link(() => CityAttractionController()); By contrast, the route /cities/[:name/[attractions/[:id]]] , while valid, makes controller logic much more unwieldy. Request Bindings Operation methods may bind properties of an HTTP request to its parameters. When the operation method is invoked, the value of that property is passed as an argument to the operation method. For example, the following binds the header named 'X-API-Key' to the argument apiKey : @Operation.get('name') Future<Response> getCityByName(@Bind.header('x-api-key') String apiKey) async { if (!isValid(apiKey)) { return Response.unauthorized(); } return Response.ok(...); } The following table shows the possible types of bindings: Property Binding Path Variable @Bind.path(pathVariableName) URL Query Parameter @Bind.query(queryParameterName) Header @Bind.header(headerName) Request Body @Bind.body() You may bind any number of HTTP request properties to a single operation method. Optional Bindings Bindings can be made optional. If a binding is optional, the operation method will still be called even if the binding isn't in a request. To make a binding optional, wrap it in curly brackets. @Operation.get() Future<Response> getAllCities({@Bind.header('x-api-key') String apiKey}) async { if (apiKey == null) { // No X-API-Key in request ... } ... } The curly bracket syntax is a Dart language feature for optional method parameters ( see more here ). If there are multiple optional parameters, use only one pair of curly brackets and list each optional parameter in those brackets. A bound parameter will be null if is not present in the request. You can provide a default value for optional parameters. @Operation.get() Future<Response> getAllCities({@Bind.header(\"x-api-key\") String apiKey: \"public\"}) async { ... } Automatically Parsing Bindings Query, header and path bindings can automatically be parsed into other types, such as int or DateTime . Simply declare the bound parameter's type to the desired type: Future<Response> getCityByID(@Bind.query('id') int cityID) The type of a bound parameter may be String or any type that implements parse (e.g., int , DateTime ). Query parameters may also be bound to bool parameters; a boolean query parameter will be true if the query parameter has no value (e.g. /path?boolean ). If parsing fails for any reason, an error response is sent and the operation method is not called. For example, the above example binds int cityID - if the path variable 'id' can't be parsed into an int , a 404 Not Found response is sent. If a query parameter or header value cannot be parsed, a 400 Bad Request response is sent. You may also bind List<T> parameters to headers and query parameters, where T must meet the same criteria as above. Query parameters and headers may appear more than once in a request. For example, the value of ids is [1, 2] if the request URL ends with /path?id=1&id=2 and the operation method looks like this: Future<Response> getCitiesByIDs(@Bind.query('id') List<int> ids) Note that if a parameter is not bound to a list and there are multiple occurrences of that property in the request, a 400 Bad Request response will be sent. If you want to allow multiple values, you must bind to a List<T> . Header Bindings The following operation method binds the header named X-API-Key to the apiKey parameter: class CityController extends ResourceController { @Operation.get() Future<Response> getAllCities(@Bind.header('x-api-key') String apiKey) async { if (!isValid(apiKey)) { return Response.unauthorized(); } return Response.ok(['Atlanta', 'Madison', 'Mountain View']); } } If an X-API-Key header is present in the request, its value will be available in apiKey . If it is not, getAllCities(apiKey) would not be called and a 400 Bad Request response will be sent. If apiKey were optional, the method is called as normal and apiKey is null or a default value. Header names are case-insensitive per the HTTP specification. Therefore, the header name may be 'X-API-KEY', 'X-Api-Key' 'x-api-key', etc. and apiKey will be bound in all cases. Query Parameter Bindings The following operation methods binds the query parameter named 'name' to the parameter cityName : class CityController extends ResourceController { @Operation.get() Future<Response> getAllCities(@Bind.query('name') String cityName) async { return Response.ok(cities.where((c) => c.name == cityName).toList()); } } Query parameters can be required or optional. If required, a 400 Bad Request response is sent and no operation method is called if the query parameter is not present in the request URL. If optional, the bound variable is null or a default value. Query parameters are case-sensitive; this binding will only match the query parameter 'name', but not 'Name' or 'NAME'. Query parameters may also bound for query strings in the request body when the content-type is 'application/x-www-form-urlencoded'. Path Variable Bindings The following operation method binds the path variable 'id' to the parameter cityID : class CityController extends ResourceController { @Operation.get('id') Future<Response> getCityByID(@Bind.path('id') String cityID) async { return Response.ok(cities.where((c) => c.id == cityID).toList()); } } Path variables are made available when creating routes . A Router must have a route that includes a path variable and that path variable must be listed in the Operation annotation. Path variables are case-sensitive and may not be optional. If you attempt to bind a path variable that is not present in the Operation , you will get a runtime exception at startup. You do not have to bind path variables for an operation method to be invoked. HTTP Request Body Bindings The body of an HTTP request can also be bound to a parameter: class CityController extends ResourceController { CityController(this.context); final ManagedContext context; @Operation.post() Future<Response> addCity(@Bind.body() City city) async { final insertedCity = await context.insertObject(city); return Response.ok(insertedCity); } } Since there is only one request body, Bind.body() doesn't take any identifying arguments (however, it does take optional arguments for ignoring, requiring or rejecting keys; this matches the behavior of Serializable.read and only works when the bound type is a Serializable or list of). The bound parameter type ( City in this example) must implement Serializable . Conduit will automatically decode the request body from it's content-type, create a new instance of the bound parameter type, and invoke its read method. In the above example, a valid request body would be the following JSON: { \"id\": 1, \"name\": \"Atlanta\" } !!! note \"HTTP Body Decoding\" Request bodies are decoded according to their content-type prior to being deserialized. For more information on request body decoding, including decoding content-types other than JSON, see this guide . If parsing fails or read throws an exception, a 400 Bad Request response will be sent and the operation method won't be called. You may also bind List<Serializable> parameters to the request body. Consider the following JSON that contains a list of cities: [ {\"id\": 1, \"name\": \"Atlanta\"}, {\"id\": 2, \"name\": \"Madison\"} ] This body can be bound by declaring the bound parameter to be a List of the desired type: Future<Response> addCity(@Bind.body() List<City> cities) !!! tip \"List vs Object\" An endpoint should either take a single object or a list of objects, but not both. If the request body is a JSON list and the bound variable is not a list, a 400 Bad Request response will be sent (and vice versa). Declaring a body binding of the appropriate type validates the expected value and aids in automatically generating an OpenAPI specification for your application. Note that if the request's Content-Type is 'x-www-form-urlencoded', its must be bound with Bind.query and not Bind.body . !!! tip \"Key Filters in Bind.body()\" Filters can be applied to keys of the object being read. Filters can ignore keys, require keys or throw an error if a key is found. See more here . Property Binding The properties of an ResourceController s may also have Bind.query and Bind.header metadata. This binds values from the request to the ResourceController instance itself, making them accessible from all operation methods. class CityController extends ResourceController { @requiredBinding @Bind.header(\"x-timestamp\") DateTime timestamp; @Bind.query(\"limit\") int limit; @Operation.get() Future<Response> getCities() async { // can use both limit and timestamp } } In the above, both timestamp and limit are bound prior to getCities being invoked. By default, a bound property is optional. Adding an requiredBinding annotation changes a property to required. If required, any request without the required property fails with a 400 Bad Request status code and none of the operation methods are invoked. Other ResourceController Behavior Besides binding, ResourceController s have some other behavior that is important to understand. Request and Response Bodies A ResourceController can limit the content type of HTTP request bodies it accepts. By default, a ResourceController will accept only application/json request bodies for its POST and PUT methods. This can be modified by setting the acceptedContentTypes property in the constructor. class UserController extends ResourceController { UserController() { acceptedContentTypes = [ContentType.JSON, ContentType.XML]; } } If a request is made with a content type other than the accepted content types, the controller automatically responds with a 415 Unsupported Media Type response. The body of an HTTP request is decoded if the content type is accepted and there exists a operation method to handle the request. The body is not decoded if there is not a matching operation method for the request. The body is decoded by ResourceController prior to your operation method being invoked. Therefore, you can always use the synchronous RequestBody.as method to access the body from within an operation method: @Operation.post() Future<Response> createThing() async { // do this: Map<String, dynamic> bodyMap = request.body.as(); // no need to do this: Map<String, dynamic> bodyMap = await request.body.decode(); return ...; } A ResourceController can also have a default content type for its responses. By default, this is application/json . This default can be changed by changing responseContentType in the constructor: class UserController extends ResourceController { UserController() { responseContentType = ContentType.XML; } } The responseContentType is the default response content type. An individual Response may set its own contentType , which takes precedence over the responseContentType . For example, the following controller returns JSON by default, but if the request specifically asks for XML, that's what it will return: class UserController extends ResourceController { UserController() { responseContentType = ContentType.JSON; } @Operation.get('id') Future<Response> getUserByID(@Bind.path('id') int id) async { var response = Response.ok(...); if (request.headers.value(Bind.headers.ACCEPT).startsWith(\"application/xml\")) { response.contentType = ContentType.XML; } return response; } } More Specialized ResourceControllers Many ResourceController subclasses will execute queries . There are helpful ResourceController subclasses for reducing boilerplate code. A QueryController<T> builds a Query<T> based on the incoming request. If the request has a body, this Query<T> 's values property is read from that body. If the request has a path variable, the Query<T> assigns an expression to the primary key value. For example, in a normal ResourceController that responds to a PUT request, you might write the following: @Operation.put('id') Future<Response> updateUser(@Bind.path('id') int id, @Bind.body() User user) async { var query = Query<User>(context) ..where((u) => u.id).equalTo(id) ..values = user; return Response.ok(await query.updateOne()); } A QueryController<T> builds this query before a operation method is invoked, storing it in the inherited query property. A ManagedObject<T> subclass is the type argument to QueryController<T> . class UserController extends QueryController<User> { UserController(ManagedContext context) : super(context); @Operation.put('id') Future<Response> updateUser(@Bind.path('id') int id) async { // query already exists and is identical to the snippet above var result = await query.updateOne(); return Response.ok(result); } } A ManagedObjectController<T> is significantly more powerful; you don't even need to subclass it. It does all the things a CRUD endpoint does without any code. Here's an example usage: router .route(\"/users/[:id]\") .link(() => ManagedObjectController<User>(context)); This controller has the following behavior: Request Action POST /users Inserts a user into the database with values from the request body GET /users Fetches all users in the database GET /users/:id Fetches a single user by id DELETE /users/:id Deletes a single user by id PUT /users/:id Updated a single user by id, using values from the request body The objects returned from getting the collection - e.g, GET /users - can be modified with query parameters. For example, the following request will return the users sorted by their name in ascending order: GET /users?sortBy=name,asc The results can be paged (see Paging in Advanced Queries ) with query parameters offset , count , pageBy , pageAfter and pagePrior . A ManagedObjectController<T> can also be subclassed. A subclass allows for callbacks to be overridden to adjust the query before execution, or the results before sending the respond. Each operation - fetch, update, delete, etc. - has a pair of methods to do this. For example, the following subclass alters the query and results before any update via PUT : class UserController extends ManagedObjectController<User> { UserController(ManagedContext context) : super(context); Future<Query<User>> willUpdateObjectWithQuery( Query<User> query) async { query.values.lastUpdatedAt = DateTime.now().toUtc(); return query; } Future<Response> didUpdateObject(User object) async { object.removePropertyFromBackingMap(\"private\"); return Response.ok(object); } } See the chapter on validations , which are powerful when combined with ManagedObjectController<T> .","title":"Request Binding with Resource Controllers"},{"location":"http/resource_controller/#resourcecontroller","text":"A ResourceController is a controller that provide conveniences for implementing endpoint controllers. A ResourceController must be subclassed, and in that subclass, you write a method for each operation on that type of resource. For example, a UserController might handle the following operations: creating a new user ( POST /users ) getting all users ( GET /users ) getting an individual user ( GET /users/:id ) updating an individual user ( PUT /users/:id ) deleting an individual user ( DELETE /users/:id ) These methods that are invoked for an operation are called operation methods .","title":"ResourceController"},{"location":"http/resource_controller/#operation-methods","text":"An operation method is an instance method of a ResourceController subclass that has an @Operation annotation. It must return an instance of Future<Response> . Here's an example: class CityController extends ResourceController { @Operation.get() Future<Response> getAllCities() async { return Response.ok([\"Atlanta\", \"Madison\", \"Mountain View\"]); } } The above operation method will be invoked when CityController handles GET requests without path variables. To handle operation methods with path variables, the name of the path variable is added to the @Operation annotation: class CityController extends ResourceController { @Operation.get() Future<Response> getAllCities() async { return Response.ok([\"Atlanta\", \"Madison\", \"Mountain View\"]); } @Operation.get('name') Future<Response> getCityByName() async { final id = request.path.variables['name']; return Response.ok(fetchCityWithName(name)); } } !!! note \"Path Variables\" This controller would be linked to the route specification /cities/[:name] , so that it can handle both of these operations. Read more about path variables in Routing . The named constructor of Operation tells us which HTTP method the operation method handles. The following named constructors exist: Operation.post() Operation.get() Operation.put() Operation.delete() The canonical Operation() constructor takes the HTTP method as its first argument for non-standard operations, e.g.: @Operation('PATCH', 'id') Future<Response> patchObjectWithID() async => ...; All Operation constructors take a variable list of path variables. There can be multiple path variables for an operation. An operation method will only be invoked if all of its path variables are present in the request path. There can be multiple operation methods for a given HTTP method, as long as each expects a different set of path variables. Here's an example of an operation that requires two path variables: @Operation.get('userID', 'itemID') Future<Response> getUserItem() async { final userID = request.path.variables['userID']; final itemID = request.path.variables['itemID']; return Response.ok(...); } If no operation method exists for a request, a 405 Method Not Allowed response is automatically sent and no operation method is invoked.","title":"Operation Methods"},{"location":"http/resource_controller/#routing-to-a-resourcecontroller","text":"A ResourceController subclass must be preceded by a Router in the application channel. The Router will parse path variables so that the controller can use them to determine which operation method should be invoked. A typical route to a ResourceController contains an optional identifying path variable: router .route(\"/cities/[:name]\") .link(() => CityController()); This route would allow CityController to implement operation methods for all HTTP methods with both no path variables and the 'name' path variable. It is considered good practice to break sub-resources into their own controller. For example, the following is preferred: router .route(\"/cities/[:name]\") .link(() => CityController()); router .route(\"/cities/:name/attractions/[:id]\") .link(() => CityAttractionController()); By contrast, the route /cities/[:name/[attractions/[:id]]] , while valid, makes controller logic much more unwieldy.","title":"Routing to a ResourceController"},{"location":"http/resource_controller/#request-bindings","text":"Operation methods may bind properties of an HTTP request to its parameters. When the operation method is invoked, the value of that property is passed as an argument to the operation method. For example, the following binds the header named 'X-API-Key' to the argument apiKey : @Operation.get('name') Future<Response> getCityByName(@Bind.header('x-api-key') String apiKey) async { if (!isValid(apiKey)) { return Response.unauthorized(); } return Response.ok(...); } The following table shows the possible types of bindings: Property Binding Path Variable @Bind.path(pathVariableName) URL Query Parameter @Bind.query(queryParameterName) Header @Bind.header(headerName) Request Body @Bind.body() You may bind any number of HTTP request properties to a single operation method.","title":"Request Bindings"},{"location":"http/resource_controller/#optional-bindings","text":"Bindings can be made optional. If a binding is optional, the operation method will still be called even if the binding isn't in a request. To make a binding optional, wrap it in curly brackets. @Operation.get() Future<Response> getAllCities({@Bind.header('x-api-key') String apiKey}) async { if (apiKey == null) { // No X-API-Key in request ... } ... } The curly bracket syntax is a Dart language feature for optional method parameters ( see more here ). If there are multiple optional parameters, use only one pair of curly brackets and list each optional parameter in those brackets. A bound parameter will be null if is not present in the request. You can provide a default value for optional parameters. @Operation.get() Future<Response> getAllCities({@Bind.header(\"x-api-key\") String apiKey: \"public\"}) async { ... }","title":"Optional Bindings"},{"location":"http/resource_controller/#automatically-parsing-bindings","text":"Query, header and path bindings can automatically be parsed into other types, such as int or DateTime . Simply declare the bound parameter's type to the desired type: Future<Response> getCityByID(@Bind.query('id') int cityID) The type of a bound parameter may be String or any type that implements parse (e.g., int , DateTime ). Query parameters may also be bound to bool parameters; a boolean query parameter will be true if the query parameter has no value (e.g. /path?boolean ). If parsing fails for any reason, an error response is sent and the operation method is not called. For example, the above example binds int cityID - if the path variable 'id' can't be parsed into an int , a 404 Not Found response is sent. If a query parameter or header value cannot be parsed, a 400 Bad Request response is sent. You may also bind List<T> parameters to headers and query parameters, where T must meet the same criteria as above. Query parameters and headers may appear more than once in a request. For example, the value of ids is [1, 2] if the request URL ends with /path?id=1&id=2 and the operation method looks like this: Future<Response> getCitiesByIDs(@Bind.query('id') List<int> ids) Note that if a parameter is not bound to a list and there are multiple occurrences of that property in the request, a 400 Bad Request response will be sent. If you want to allow multiple values, you must bind to a List<T> .","title":"Automatically Parsing Bindings"},{"location":"http/resource_controller/#header-bindings","text":"The following operation method binds the header named X-API-Key to the apiKey parameter: class CityController extends ResourceController { @Operation.get() Future<Response> getAllCities(@Bind.header('x-api-key') String apiKey) async { if (!isValid(apiKey)) { return Response.unauthorized(); } return Response.ok(['Atlanta', 'Madison', 'Mountain View']); } } If an X-API-Key header is present in the request, its value will be available in apiKey . If it is not, getAllCities(apiKey) would not be called and a 400 Bad Request response will be sent. If apiKey were optional, the method is called as normal and apiKey is null or a default value. Header names are case-insensitive per the HTTP specification. Therefore, the header name may be 'X-API-KEY', 'X-Api-Key' 'x-api-key', etc. and apiKey will be bound in all cases.","title":"Header Bindings"},{"location":"http/resource_controller/#query-parameter-bindings","text":"The following operation methods binds the query parameter named 'name' to the parameter cityName : class CityController extends ResourceController { @Operation.get() Future<Response> getAllCities(@Bind.query('name') String cityName) async { return Response.ok(cities.where((c) => c.name == cityName).toList()); } } Query parameters can be required or optional. If required, a 400 Bad Request response is sent and no operation method is called if the query parameter is not present in the request URL. If optional, the bound variable is null or a default value. Query parameters are case-sensitive; this binding will only match the query parameter 'name', but not 'Name' or 'NAME'. Query parameters may also bound for query strings in the request body when the content-type is 'application/x-www-form-urlencoded'.","title":"Query Parameter Bindings"},{"location":"http/resource_controller/#path-variable-bindings","text":"The following operation method binds the path variable 'id' to the parameter cityID : class CityController extends ResourceController { @Operation.get('id') Future<Response> getCityByID(@Bind.path('id') String cityID) async { return Response.ok(cities.where((c) => c.id == cityID).toList()); } } Path variables are made available when creating routes . A Router must have a route that includes a path variable and that path variable must be listed in the Operation annotation. Path variables are case-sensitive and may not be optional. If you attempt to bind a path variable that is not present in the Operation , you will get a runtime exception at startup. You do not have to bind path variables for an operation method to be invoked.","title":"Path Variable Bindings"},{"location":"http/resource_controller/#http-request-body-bindings","text":"The body of an HTTP request can also be bound to a parameter: class CityController extends ResourceController { CityController(this.context); final ManagedContext context; @Operation.post() Future<Response> addCity(@Bind.body() City city) async { final insertedCity = await context.insertObject(city); return Response.ok(insertedCity); } } Since there is only one request body, Bind.body() doesn't take any identifying arguments (however, it does take optional arguments for ignoring, requiring or rejecting keys; this matches the behavior of Serializable.read and only works when the bound type is a Serializable or list of). The bound parameter type ( City in this example) must implement Serializable . Conduit will automatically decode the request body from it's content-type, create a new instance of the bound parameter type, and invoke its read method. In the above example, a valid request body would be the following JSON: { \"id\": 1, \"name\": \"Atlanta\" } !!! note \"HTTP Body Decoding\" Request bodies are decoded according to their content-type prior to being deserialized. For more information on request body decoding, including decoding content-types other than JSON, see this guide . If parsing fails or read throws an exception, a 400 Bad Request response will be sent and the operation method won't be called. You may also bind List<Serializable> parameters to the request body. Consider the following JSON that contains a list of cities: [ {\"id\": 1, \"name\": \"Atlanta\"}, {\"id\": 2, \"name\": \"Madison\"} ] This body can be bound by declaring the bound parameter to be a List of the desired type: Future<Response> addCity(@Bind.body() List<City> cities) !!! tip \"List vs Object\" An endpoint should either take a single object or a list of objects, but not both. If the request body is a JSON list and the bound variable is not a list, a 400 Bad Request response will be sent (and vice versa). Declaring a body binding of the appropriate type validates the expected value and aids in automatically generating an OpenAPI specification for your application. Note that if the request's Content-Type is 'x-www-form-urlencoded', its must be bound with Bind.query and not Bind.body . !!! tip \"Key Filters in Bind.body()\" Filters can be applied to keys of the object being read. Filters can ignore keys, require keys or throw an error if a key is found. See more here .","title":"HTTP Request Body Bindings"},{"location":"http/resource_controller/#property-binding","text":"The properties of an ResourceController s may also have Bind.query and Bind.header metadata. This binds values from the request to the ResourceController instance itself, making them accessible from all operation methods. class CityController extends ResourceController { @requiredBinding @Bind.header(\"x-timestamp\") DateTime timestamp; @Bind.query(\"limit\") int limit; @Operation.get() Future<Response> getCities() async { // can use both limit and timestamp } } In the above, both timestamp and limit are bound prior to getCities being invoked. By default, a bound property is optional. Adding an requiredBinding annotation changes a property to required. If required, any request without the required property fails with a 400 Bad Request status code and none of the operation methods are invoked.","title":"Property Binding"},{"location":"http/resource_controller/#other-resourcecontroller-behavior","text":"Besides binding, ResourceController s have some other behavior that is important to understand.","title":"Other ResourceController Behavior"},{"location":"http/resource_controller/#request-and-response-bodies","text":"A ResourceController can limit the content type of HTTP request bodies it accepts. By default, a ResourceController will accept only application/json request bodies for its POST and PUT methods. This can be modified by setting the acceptedContentTypes property in the constructor. class UserController extends ResourceController { UserController() { acceptedContentTypes = [ContentType.JSON, ContentType.XML]; } } If a request is made with a content type other than the accepted content types, the controller automatically responds with a 415 Unsupported Media Type response. The body of an HTTP request is decoded if the content type is accepted and there exists a operation method to handle the request. The body is not decoded if there is not a matching operation method for the request. The body is decoded by ResourceController prior to your operation method being invoked. Therefore, you can always use the synchronous RequestBody.as method to access the body from within an operation method: @Operation.post() Future<Response> createThing() async { // do this: Map<String, dynamic> bodyMap = request.body.as(); // no need to do this: Map<String, dynamic> bodyMap = await request.body.decode(); return ...; } A ResourceController can also have a default content type for its responses. By default, this is application/json . This default can be changed by changing responseContentType in the constructor: class UserController extends ResourceController { UserController() { responseContentType = ContentType.XML; } } The responseContentType is the default response content type. An individual Response may set its own contentType , which takes precedence over the responseContentType . For example, the following controller returns JSON by default, but if the request specifically asks for XML, that's what it will return: class UserController extends ResourceController { UserController() { responseContentType = ContentType.JSON; } @Operation.get('id') Future<Response> getUserByID(@Bind.path('id') int id) async { var response = Response.ok(...); if (request.headers.value(Bind.headers.ACCEPT).startsWith(\"application/xml\")) { response.contentType = ContentType.XML; } return response; } }","title":"Request and Response Bodies"},{"location":"http/resource_controller/#more-specialized-resourcecontrollers","text":"Many ResourceController subclasses will execute queries . There are helpful ResourceController subclasses for reducing boilerplate code. A QueryController<T> builds a Query<T> based on the incoming request. If the request has a body, this Query<T> 's values property is read from that body. If the request has a path variable, the Query<T> assigns an expression to the primary key value. For example, in a normal ResourceController that responds to a PUT request, you might write the following: @Operation.put('id') Future<Response> updateUser(@Bind.path('id') int id, @Bind.body() User user) async { var query = Query<User>(context) ..where((u) => u.id).equalTo(id) ..values = user; return Response.ok(await query.updateOne()); } A QueryController<T> builds this query before a operation method is invoked, storing it in the inherited query property. A ManagedObject<T> subclass is the type argument to QueryController<T> . class UserController extends QueryController<User> { UserController(ManagedContext context) : super(context); @Operation.put('id') Future<Response> updateUser(@Bind.path('id') int id) async { // query already exists and is identical to the snippet above var result = await query.updateOne(); return Response.ok(result); } } A ManagedObjectController<T> is significantly more powerful; you don't even need to subclass it. It does all the things a CRUD endpoint does without any code. Here's an example usage: router .route(\"/users/[:id]\") .link(() => ManagedObjectController<User>(context)); This controller has the following behavior: Request Action POST /users Inserts a user into the database with values from the request body GET /users Fetches all users in the database GET /users/:id Fetches a single user by id DELETE /users/:id Deletes a single user by id PUT /users/:id Updated a single user by id, using values from the request body The objects returned from getting the collection - e.g, GET /users - can be modified with query parameters. For example, the following request will return the users sorted by their name in ascending order: GET /users?sortBy=name,asc The results can be paged (see Paging in Advanced Queries ) with query parameters offset , count , pageBy , pageAfter and pagePrior . A ManagedObjectController<T> can also be subclassed. A subclass allows for callbacks to be overridden to adjust the query before execution, or the results before sending the respond. Each operation - fetch, update, delete, etc. - has a pair of methods to do this. For example, the following subclass alters the query and results before any update via PUT : class UserController extends ManagedObjectController<User> { UserController(ManagedContext context) : super(context); Future<Query<User>> willUpdateObjectWithQuery( Query<User> query) async { query.values.lastUpdatedAt = DateTime.now().toUtc(); return query; } Future<Response> didUpdateObject(User object) async { object.removePropertyFromBackingMap(\"private\"); return Response.ok(object); } } See the chapter on validations , which are powerful when combined with ManagedObjectController<T> .","title":"More Specialized ResourceControllers"},{"location":"http/routing/","text":"Routing What is routing? Every HTTP request has a URL. A URL identifies a resource . In the early days of the Internet, a resource was a file. For example, the URL http://www.geocities.com/my_page/image.jpg would return the file image.jpg from the folder my_page on the webserver located at www.geocities.com . In a web application today, resources come from many other sources of data, like a database or a connected device. The job of a web application is to provide, create or modify a resource for a URL, wherever that resource might come from. A URL is made up of many parts, some of which are optional. The typical URL we see as humans looks like this: http://conduit.dart.com/about . Most people recognize that typing this URL into a browser would take them to our company's \"About\" page. In other words, our \"About\" page is a resource and the URL identifies it. More generally, the \"About\" page URL has the three required components of a URL: a scheme ( http ), a host ( conduit.dart.com ) and a path ( /about ). The host specifies the computer responsible for providing the resource, the path identifies the resource and the scheme lets both the requester and the host know how they should exchange information. A Conduit application receives requests when the scheme is http (or https ) and the host refers to a machine where the application is running. Therefore, once the application gets the request, it only cares about the remaining component: the path. In Conduit, a Router routes Request s to a Controller based on the request path. This process is known as routing . When an application starts up, routes are registered in a subclass of ApplicationChannel . Each registered route creates a new channel of Controller s that will handle the request. Route Specifications Match HTTP Request Paths A route is registered by invoking Router.route . This method takes a route specification - a String with some syntax rules that will match the path of a request. This registration occurs when an application first starts by overriding ApplicationChannel.entryPoint . For example: class MyApplicationChannel extends ApplicationChannel { @override Controller get entryPoint { final router = new Router(); router .route(\"/users\") .linkFunction((req) async => new Response.ok(await getAllUsers()); return router; } } The argument to route is the route specification string. This particular route matches the path /users . That is, a request for the URL http://myserver.com/users will be handled by the linkFunction closure. (Leading and trailing slashes are stripped out when routes are compiled, so including them has no effect, but it is good style to show a leading slash.) A path can have multiple segments (the characters between slashes). For example, the path /users/foo has two path segments: users and foo . A route specification matches each segment of a path against each of its segments. The path and the route must also have the same number of segments. Thus, the route specification /users/foo would match the path /users/foo , but it would not match the paths /users , /users/7 or /users/foo/1 . Path Variables A route specification may have path variables . A path variable captures the value from a path segment, so that your code can use it. A path variable is most often used to uniquely identify a resource by some identifier, like /users/1 and /users/2 . In a route specification, a path variable starts with a colon ( : ). The name of the variable follows this colon. For example, consider the following route that declares a path variable named userID : router.route(\"/users/:userID\") This route specification will match /users/1 , /users/2 , /users/foo , etc. The value of userID is 1 , 2 and foo , respectively. This route won't match /users or /users/1/2 . Optional Path Segments Routes may have optional path segments. This allows a group of routes that all refer to a resource collection and its individual resources to go to the same controller. For example, the requests /users and /users/1 can both be covered by a single route specification. An optional path segment has square brackets ( [] ) around it. The brackets can go before or after slashes. For example, the following two syntaxes register a route that accepts both /users and /users/:userID : route(\"/users/[:userID]\") route(\"/users[/:userID]\") Conceptually, a request with a path of /users/1 identifies a single user, where /users identifies all users. Optional segments are used to create better code structure by forwarding requests that deal with a specific type of resource to the same controller. Therefore, the code to handle one user or multiple users is written in the same place. You may have any number of optional segments in a route specification. Each optional segment must be nested. The following route would match /a , /a/b and /a/b/c . It would not match /a/c . route(\"/a/[b/[c]]\") It's pretty rare to have more than one optional segment in a route. For example, consider the route: route(\"/users/[:id/[:subresource/[:subresourceid]]]\"); The code to handle one or more users is likely very different than the code to handle one of its subresources - different database tables will be queried and different authorization may be needed. Thus, a better approach is to split subresources into their own routes to keep controller logic modular: // Matches /users and /users/:id route(\"/users/[:id]\")...; // Matches /users/:userId/posts and /users/:userId/posts/:postId route(\"/users/:userId/posts/[:postId]\")...; // Matches /users/:userId/notes and /users/:userId/notes/:noteId route(\"/users/:userId/notes/[:noteId]\")...; Restricting Path Variable Values Path variables may restrict their possible values with a regular expression. The expression comes in parentheses following the path variable name. For example, the following route specification limits userID to numbers only: route(\"/users/:userID([0-9]+)\") This regular expression would only apply to the :userID segment. Note that capture groups and parentheses in general can't be included in a route's regular expression. Everything in between the parentheses is evaluated as the regular expression. Therefore, any additional spaces or characters will be a part of the regular expression. Since spaces aren't valid in a URL, you don't want spaces in a regular expression. Matching the Remaining Path Finally, a route specification may have a special 'match-all' token, the asterisk ( * ). This token allows for any remaining request path to be matched, regardless of its contents or length. For example, the route specification /users/* would match the following paths: /users /users/1 /users/foo /users/foo/bar /users/foo/bar/something/else/and/this/goes/on/forever This token is used when another medium is going to interpret the URL. For example, FileController - which reads a file from the filesystem - might have a route /file/* . It uses everything after /file to figure out the path on the filesystem. Accessing Path Variables Information that a router parses from a request path - like path variables - are stored in Request.path . When a Request is handled by a router, its path is set to an instance of this type. Controllers deeper in the channel access Request.path to help determine which resource the request is identifying. The path is an instance of RequestPath . A RequestPath contains an map of variables , where the key is path variable name and the value is the value of that variable in the request. For example, consider a route specification /users/:id . When a request with path /users/1 is routed, the value 1 is stored in this map for the key id : final identifier = request.path.variables[\"id\"]; // identifier = \"1\" The values in variables are always String s, since a request path is a String . Controller s may parse path variables into types like int . ResourceController uses path variables to select a operation method to handle a request. Failed Matches Return 404 A Router will return a 404 Not Found if there is no matching route for the request. No linked controllers will handle the request. This behavior may be overridden by providing a closure to Router 's constructor.","title":"Routing"},{"location":"http/routing/#routing","text":"","title":"Routing"},{"location":"http/routing/#what-is-routing","text":"Every HTTP request has a URL. A URL identifies a resource . In the early days of the Internet, a resource was a file. For example, the URL http://www.geocities.com/my_page/image.jpg would return the file image.jpg from the folder my_page on the webserver located at www.geocities.com . In a web application today, resources come from many other sources of data, like a database or a connected device. The job of a web application is to provide, create or modify a resource for a URL, wherever that resource might come from. A URL is made up of many parts, some of which are optional. The typical URL we see as humans looks like this: http://conduit.dart.com/about . Most people recognize that typing this URL into a browser would take them to our company's \"About\" page. In other words, our \"About\" page is a resource and the URL identifies it. More generally, the \"About\" page URL has the three required components of a URL: a scheme ( http ), a host ( conduit.dart.com ) and a path ( /about ). The host specifies the computer responsible for providing the resource, the path identifies the resource and the scheme lets both the requester and the host know how they should exchange information. A Conduit application receives requests when the scheme is http (or https ) and the host refers to a machine where the application is running. Therefore, once the application gets the request, it only cares about the remaining component: the path. In Conduit, a Router routes Request s to a Controller based on the request path. This process is known as routing . When an application starts up, routes are registered in a subclass of ApplicationChannel . Each registered route creates a new channel of Controller s that will handle the request.","title":"What is routing?"},{"location":"http/routing/#route-specifications-match-http-request-paths","text":"A route is registered by invoking Router.route . This method takes a route specification - a String with some syntax rules that will match the path of a request. This registration occurs when an application first starts by overriding ApplicationChannel.entryPoint . For example: class MyApplicationChannel extends ApplicationChannel { @override Controller get entryPoint { final router = new Router(); router .route(\"/users\") .linkFunction((req) async => new Response.ok(await getAllUsers()); return router; } } The argument to route is the route specification string. This particular route matches the path /users . That is, a request for the URL http://myserver.com/users will be handled by the linkFunction closure. (Leading and trailing slashes are stripped out when routes are compiled, so including them has no effect, but it is good style to show a leading slash.) A path can have multiple segments (the characters between slashes). For example, the path /users/foo has two path segments: users and foo . A route specification matches each segment of a path against each of its segments. The path and the route must also have the same number of segments. Thus, the route specification /users/foo would match the path /users/foo , but it would not match the paths /users , /users/7 or /users/foo/1 .","title":"Route Specifications Match HTTP Request Paths"},{"location":"http/routing/#path-variables","text":"A route specification may have path variables . A path variable captures the value from a path segment, so that your code can use it. A path variable is most often used to uniquely identify a resource by some identifier, like /users/1 and /users/2 . In a route specification, a path variable starts with a colon ( : ). The name of the variable follows this colon. For example, consider the following route that declares a path variable named userID : router.route(\"/users/:userID\") This route specification will match /users/1 , /users/2 , /users/foo , etc. The value of userID is 1 , 2 and foo , respectively. This route won't match /users or /users/1/2 .","title":"Path Variables"},{"location":"http/routing/#optional-path-segments","text":"Routes may have optional path segments. This allows a group of routes that all refer to a resource collection and its individual resources to go to the same controller. For example, the requests /users and /users/1 can both be covered by a single route specification. An optional path segment has square brackets ( [] ) around it. The brackets can go before or after slashes. For example, the following two syntaxes register a route that accepts both /users and /users/:userID : route(\"/users/[:userID]\") route(\"/users[/:userID]\") Conceptually, a request with a path of /users/1 identifies a single user, where /users identifies all users. Optional segments are used to create better code structure by forwarding requests that deal with a specific type of resource to the same controller. Therefore, the code to handle one user or multiple users is written in the same place. You may have any number of optional segments in a route specification. Each optional segment must be nested. The following route would match /a , /a/b and /a/b/c . It would not match /a/c . route(\"/a/[b/[c]]\") It's pretty rare to have more than one optional segment in a route. For example, consider the route: route(\"/users/[:id/[:subresource/[:subresourceid]]]\"); The code to handle one or more users is likely very different than the code to handle one of its subresources - different database tables will be queried and different authorization may be needed. Thus, a better approach is to split subresources into their own routes to keep controller logic modular: // Matches /users and /users/:id route(\"/users/[:id]\")...; // Matches /users/:userId/posts and /users/:userId/posts/:postId route(\"/users/:userId/posts/[:postId]\")...; // Matches /users/:userId/notes and /users/:userId/notes/:noteId route(\"/users/:userId/notes/[:noteId]\")...;","title":"Optional Path Segments"},{"location":"http/routing/#restricting-path-variable-values","text":"Path variables may restrict their possible values with a regular expression. The expression comes in parentheses following the path variable name. For example, the following route specification limits userID to numbers only: route(\"/users/:userID([0-9]+)\") This regular expression would only apply to the :userID segment. Note that capture groups and parentheses in general can't be included in a route's regular expression. Everything in between the parentheses is evaluated as the regular expression. Therefore, any additional spaces or characters will be a part of the regular expression. Since spaces aren't valid in a URL, you don't want spaces in a regular expression.","title":"Restricting Path Variable Values"},{"location":"http/routing/#matching-the-remaining-path","text":"Finally, a route specification may have a special 'match-all' token, the asterisk ( * ). This token allows for any remaining request path to be matched, regardless of its contents or length. For example, the route specification /users/* would match the following paths: /users /users/1 /users/foo /users/foo/bar /users/foo/bar/something/else/and/this/goes/on/forever This token is used when another medium is going to interpret the URL. For example, FileController - which reads a file from the filesystem - might have a route /file/* . It uses everything after /file to figure out the path on the filesystem.","title":"Matching the Remaining Path"},{"location":"http/routing/#accessing-path-variables","text":"Information that a router parses from a request path - like path variables - are stored in Request.path . When a Request is handled by a router, its path is set to an instance of this type. Controllers deeper in the channel access Request.path to help determine which resource the request is identifying. The path is an instance of RequestPath . A RequestPath contains an map of variables , where the key is path variable name and the value is the value of that variable in the request. For example, consider a route specification /users/:id . When a request with path /users/1 is routed, the value 1 is stored in this map for the key id : final identifier = request.path.variables[\"id\"]; // identifier = \"1\" The values in variables are always String s, since a request path is a String . Controller s may parse path variables into types like int . ResourceController uses path variables to select a operation method to handle a request.","title":"Accessing Path Variables"},{"location":"http/routing/#failed-matches-return-404","text":"A Router will return a 404 Not Found if there is no matching route for the request. No linked controllers will handle the request. This behavior may be overridden by providing a closure to Router 's constructor.","title":"Failed Matches Return 404"},{"location":"http/serving_files/","text":"Serving Files and Caching Conduit can serve files by returning the contents of a file as an HTTP response body. FileController Instances of FileController serve a directory from the filesystem through an HTTP interface. Any route that channels requests to an FileController must contain a * match-all token. @override Controller get entryPoint { final router = Router(); router.route(\"/files/*\").link(() => FileController(\"public/\")); return router; } The argument to FileController is the directory on the filesystem in which request paths will be resolved against. In the above example, an HTTP request with the path /files/image.jpg would return the contents of the file public/image.jpg . Note that public/ does not have a leading slash - therefore, the directory public must be relative to the directory that the Conduit application was served from. In practice, this means you might have a directory structure like: project/ pubspec.yaml lib/ channel.dart ... test/ ... public/ image.jpg Adding a leading slash to the directory served by FileController will resolve it relative to the filesystem root. If the requested path was a directory, the filename index.html will be appended to the path when searching for a file to return. If a file does not exist, an FileController returns a 404 Not Found response. Content-Type of Files An FileController will set the content-type of the HTTP response based on the served files path extension. By default, it recognizes many common extensions like .html , .css , .jpg , .js . You may add content-types for extensions to an instance: var controller = FileController(\"public/\") ..setContentTypeForExtension(\"xml\", ContentType(\"application\", \"xml\")); If there is no entry for an extension of a file being served, the content-type defaults to application/octet-stream . An FileController will never invoke any encoders from CodecRegistry , but it will GZIP data if the repository allows compression for the content-type of the file (see CodecRegistry.add and CodecRegistry.setAllowsCompression ). Caching An FileController always sets the the Last-Modified header of the response to the last modified date according to the filesystem. If a request sends an If-Modified-Since header and the file has not been modified since that date, a 304 Not Modified response is sent with the appropriate headers. You may provide Cache-Control headers depending on the path of the file being served. Here's an example that adds Cache-Control: public, max-age=31536000 var policy = CachePolicy(expirationFromNow: Duration(days: 365)); var controller = FileController(\"public/\") ..addCachePolicy(policy, (path) => path.endsWith(\".css\")); File Serving and Caching Outside of FileController A file can be served by any controller by setting the body object of a Response with its contents: var file = File(\"index.html\"); // By loading contents into memory first... var response = Response.ok(file.readAsStringSync()) ..contentType = ContentType(\"application\", \"html\"); // Or by streaming the contents from disk var response = Response.ok(file.openRead()) ..encodeBody = false ..contentType = ContentType(\"application\", \"html\"); It is important to understand the how Conduit uses content-types to manipulate response bodies to serve file contents. You may set the CachePolicy of any Response . Note that CachePolicy only modifies the Cache-Control header of a response. Headers like Last-Modified and ETag are not added. var response = Response.ok(\"contents\") ..cachePolicy = CachePolicy();","title":"Serving Files and Caching"},{"location":"http/serving_files/#serving-files-and-caching","text":"Conduit can serve files by returning the contents of a file as an HTTP response body.","title":"Serving Files and Caching"},{"location":"http/serving_files/#filecontroller","text":"Instances of FileController serve a directory from the filesystem through an HTTP interface. Any route that channels requests to an FileController must contain a * match-all token. @override Controller get entryPoint { final router = Router(); router.route(\"/files/*\").link(() => FileController(\"public/\")); return router; } The argument to FileController is the directory on the filesystem in which request paths will be resolved against. In the above example, an HTTP request with the path /files/image.jpg would return the contents of the file public/image.jpg . Note that public/ does not have a leading slash - therefore, the directory public must be relative to the directory that the Conduit application was served from. In practice, this means you might have a directory structure like: project/ pubspec.yaml lib/ channel.dart ... test/ ... public/ image.jpg Adding a leading slash to the directory served by FileController will resolve it relative to the filesystem root. If the requested path was a directory, the filename index.html will be appended to the path when searching for a file to return. If a file does not exist, an FileController returns a 404 Not Found response.","title":"FileController"},{"location":"http/serving_files/#content-type-of-files","text":"An FileController will set the content-type of the HTTP response based on the served files path extension. By default, it recognizes many common extensions like .html , .css , .jpg , .js . You may add content-types for extensions to an instance: var controller = FileController(\"public/\") ..setContentTypeForExtension(\"xml\", ContentType(\"application\", \"xml\")); If there is no entry for an extension of a file being served, the content-type defaults to application/octet-stream . An FileController will never invoke any encoders from CodecRegistry , but it will GZIP data if the repository allows compression for the content-type of the file (see CodecRegistry.add and CodecRegistry.setAllowsCompression ).","title":"Content-Type of Files"},{"location":"http/serving_files/#caching","text":"An FileController always sets the the Last-Modified header of the response to the last modified date according to the filesystem. If a request sends an If-Modified-Since header and the file has not been modified since that date, a 304 Not Modified response is sent with the appropriate headers. You may provide Cache-Control headers depending on the path of the file being served. Here's an example that adds Cache-Control: public, max-age=31536000 var policy = CachePolicy(expirationFromNow: Duration(days: 365)); var controller = FileController(\"public/\") ..addCachePolicy(policy, (path) => path.endsWith(\".css\"));","title":"Caching"},{"location":"http/serving_files/#file-serving-and-caching-outside-of-filecontroller","text":"A file can be served by any controller by setting the body object of a Response with its contents: var file = File(\"index.html\"); // By loading contents into memory first... var response = Response.ok(file.readAsStringSync()) ..contentType = ContentType(\"application\", \"html\"); // Or by streaming the contents from disk var response = Response.ok(file.openRead()) ..encodeBody = false ..contentType = ContentType(\"application\", \"html\"); It is important to understand the how Conduit uses content-types to manipulate response bodies to serve file contents. You may set the CachePolicy of any Response . Note that CachePolicy only modifies the Cache-Control header of a response. Headers like Last-Modified and ETag are not added. var response = Response.ok(\"contents\") ..cachePolicy = CachePolicy();","title":"File Serving and Caching Outside of FileController"},{"location":"http/websockets/","text":"Using Websockets in Conduit A standard HTTP request will yield an HTTP response from a web server. In order for the server to send data to a client, the client must have sent a request for that data. A websocket is a special type of HTTP request that stays open, and both the server and client can send data to one another whenever they please. For example, a chat application might use websockets to send messages to everyone in a chatroom. In this scenario, the chat client application opens a websocket connection to the server application. When the user types a message, their chat client sends that message on its websocket. The payload might be JSON data that looks like this: { \"action\": \"send_message\", \"room\": \"general\", \"text\": \"Hi everyone\" } The server will receive this data, then turn around and send a modified version to every websocket connection it has. That data might look like this: { \"action\": \"receive_message\", \"room\": \"general\", \"from\": \"Bob\", \"text\": \"Hi everyone\" } Every connected user will receive this data and draw Bob: Hi everyone to the screen. Note that there's nothing about websockets that says you have to use JSON data - you can use any data format you like. Upgrading an HTTP Request to a WebSocket In Conduit, websockets are handled by Dart's standard library WebSocket type. Here's an example: router .route(\"/connect\") .linkFunction((request) async { var socket = await WebSocketTransformer.upgrade(request.raw); socket.listen(listener); return null; }); It's important that a request that is upgraded to a websocket is removed from the channel by returning null from the controller. (See the section on Conduit and dart:io in this guide for more details.) A client application can connect to the URL ws://localhost:8888/connect . A Dart application would make this connection like so: var socket = await WebSocket.connect(\"ws://localhost:8888/connect\"); socket.listen(...); Bi-directional Communication In the simple example above, the server only listens for data from the client. For data to be sent to the client, a reference must be kept to the WebSocket so that data can be added to it. How a Conduit application manages its websocket connections depends greatly on the behavior of the application, the number of isolates the application is running on and the infrastructure of the system as a whole. A simple application might keep track of websocket connections in a Map , where the key is a user identifier acquired from the authorization of the request: router .route(\"/connect\") .link(() => new Authorizer(authServer)); .linkFunction((request) async { var userID = request.authorization.ownerID; var socket = await WebSocketTransformer.upgrade(request.raw); socket.listen((event) => handleEvent(event, fromUserID: userID)); connections[userID] = socket; return null; }); If we continue with the 'chat application' example, the code for handleEvent may be something like: void handleEvent(dynamic event, {int fromUserID}) { var incoming = json.decode(UTF8.decode(event)); var outgoing = utf8.encode(json.encode({ \"text\": incoming[\"text\"], ... })); connections.keys .where((userID) => userID != fromUserID) .forEach((userID) { var connection = connections[userID]; connection.add(outgoing); }); } Note that this simple implementation doesn't account for multiple connections from the same user or multi-isolate applications. Considerations for Multi-Isolate and Multi-Instance Applications By default, a Conduit application runs on multiple isolates. Since each isolate has its own heap, a websocket created on one isolate is not directly accessible by another isolate. In the example above, each isolate would have its own map of connections - therefore, a message is only sent to connections that were opened on the same isolate that the chat message originated from. A simple solution is to only run the application on a single isolate, ensuring that all websockets are on a single isolate and accessible to one another: conduit serve -n 1 For many applications, this is a fine solution. For others, it may not be. Recall that one of the benefits of Conduit's multi-isolate architecture is that code tested on a single instance will scale to multiple instances behind a load balancer. If a Conduit application runs correctly on a single, multi-isolate instance, it will run correctly on multiple instances. This (somewhat) enforced structure prevents us from naively keeping track of websocket connections on a single isolate, which would cause issues when we scale out to a multi-instance system. If you find yourself in a situation where your application is so popular you need multiple servers to efficiently serve requests, you'll have a good idea on how to architect an appropriate solution (or you'll have the money to hire someone that does). In many situations, the REST API and websocket server are separate instances anyhow - they have different lifecycles and deployment behavior. It may make sense to run a websocket server on a single isolate, since you are likely IO-bound instead of CPU bound. If you still prefer to have a multi-isolate server with websockets, the ApplicationMessageHub will come in handy. When broadcasting messages to connected websockets across the application, you first send the data to each websocket connected to the isolate that is originating the message. Then, the message is added to the ApplicationMessageHub : void onChatMessage(String message) { connectedSockets.forEach((socket) { socket.add(message); }); ApplicationChannel.messageHub.add({\"event\": \"websocket_broadcast\", \"message\": message}); } Anything added to the messageHub will be delivered to the listener for every other message hub - i.e., every other isolate will receive this data. The other isolates then send the message to each of their connected websockets: class ChatChannel extends ApplicationChannel { @override Future prepare() async { messageHub.listen((event) { if (event is Map && event[\"event\"] == \"websocket_broadcast\") { connectedSockets.forEach((socket) { socket.add(event[\"message\"]); }); } }); } }","title":"Websockets"},{"location":"http/websockets/#using-websockets-in-conduit","text":"A standard HTTP request will yield an HTTP response from a web server. In order for the server to send data to a client, the client must have sent a request for that data. A websocket is a special type of HTTP request that stays open, and both the server and client can send data to one another whenever they please. For example, a chat application might use websockets to send messages to everyone in a chatroom. In this scenario, the chat client application opens a websocket connection to the server application. When the user types a message, their chat client sends that message on its websocket. The payload might be JSON data that looks like this: { \"action\": \"send_message\", \"room\": \"general\", \"text\": \"Hi everyone\" } The server will receive this data, then turn around and send a modified version to every websocket connection it has. That data might look like this: { \"action\": \"receive_message\", \"room\": \"general\", \"from\": \"Bob\", \"text\": \"Hi everyone\" } Every connected user will receive this data and draw Bob: Hi everyone to the screen. Note that there's nothing about websockets that says you have to use JSON data - you can use any data format you like.","title":"Using Websockets in Conduit"},{"location":"http/websockets/#upgrading-an-http-request-to-a-websocket","text":"In Conduit, websockets are handled by Dart's standard library WebSocket type. Here's an example: router .route(\"/connect\") .linkFunction((request) async { var socket = await WebSocketTransformer.upgrade(request.raw); socket.listen(listener); return null; }); It's important that a request that is upgraded to a websocket is removed from the channel by returning null from the controller. (See the section on Conduit and dart:io in this guide for more details.) A client application can connect to the URL ws://localhost:8888/connect . A Dart application would make this connection like so: var socket = await WebSocket.connect(\"ws://localhost:8888/connect\"); socket.listen(...);","title":"Upgrading an HTTP Request to a WebSocket"},{"location":"http/websockets/#bi-directional-communication","text":"In the simple example above, the server only listens for data from the client. For data to be sent to the client, a reference must be kept to the WebSocket so that data can be added to it. How a Conduit application manages its websocket connections depends greatly on the behavior of the application, the number of isolates the application is running on and the infrastructure of the system as a whole. A simple application might keep track of websocket connections in a Map , where the key is a user identifier acquired from the authorization of the request: router .route(\"/connect\") .link(() => new Authorizer(authServer)); .linkFunction((request) async { var userID = request.authorization.ownerID; var socket = await WebSocketTransformer.upgrade(request.raw); socket.listen((event) => handleEvent(event, fromUserID: userID)); connections[userID] = socket; return null; }); If we continue with the 'chat application' example, the code for handleEvent may be something like: void handleEvent(dynamic event, {int fromUserID}) { var incoming = json.decode(UTF8.decode(event)); var outgoing = utf8.encode(json.encode({ \"text\": incoming[\"text\"], ... })); connections.keys .where((userID) => userID != fromUserID) .forEach((userID) { var connection = connections[userID]; connection.add(outgoing); }); } Note that this simple implementation doesn't account for multiple connections from the same user or multi-isolate applications.","title":"Bi-directional Communication"},{"location":"http/websockets/#considerations-for-multi-isolate-and-multi-instance-applications","text":"By default, a Conduit application runs on multiple isolates. Since each isolate has its own heap, a websocket created on one isolate is not directly accessible by another isolate. In the example above, each isolate would have its own map of connections - therefore, a message is only sent to connections that were opened on the same isolate that the chat message originated from. A simple solution is to only run the application on a single isolate, ensuring that all websockets are on a single isolate and accessible to one another: conduit serve -n 1 For many applications, this is a fine solution. For others, it may not be. Recall that one of the benefits of Conduit's multi-isolate architecture is that code tested on a single instance will scale to multiple instances behind a load balancer. If a Conduit application runs correctly on a single, multi-isolate instance, it will run correctly on multiple instances. This (somewhat) enforced structure prevents us from naively keeping track of websocket connections on a single isolate, which would cause issues when we scale out to a multi-instance system. If you find yourself in a situation where your application is so popular you need multiple servers to efficiently serve requests, you'll have a good idea on how to architect an appropriate solution (or you'll have the money to hire someone that does). In many situations, the REST API and websocket server are separate instances anyhow - they have different lifecycles and deployment behavior. It may make sense to run a websocket server on a single isolate, since you are likely IO-bound instead of CPU bound. If you still prefer to have a multi-isolate server with websockets, the ApplicationMessageHub will come in handy. When broadcasting messages to connected websockets across the application, you first send the data to each websocket connected to the isolate that is originating the message. Then, the message is added to the ApplicationMessageHub : void onChatMessage(String message) { connectedSockets.forEach((socket) { socket.add(message); }); ApplicationChannel.messageHub.add({\"event\": \"websocket_broadcast\", \"message\": message}); } Anything added to the messageHub will be delivered to the listener for every other message hub - i.e., every other isolate will receive this data. The other isolates then send the message to each of their connected websockets: class ChatChannel extends ApplicationChannel { @override Future prepare() async { messageHub.listen((event) { if (event is Map && event[\"event\"] == \"websocket_broadcast\") { connectedSockets.forEach((socket) { socket.add(event[\"message\"]); }); } }); } }","title":"Considerations for Multi-Isolate and Multi-Instance Applications"},{"location":"openapi/","text":"OpenAPI Conduit applications auto-generate an OpenAPI 3.0 document. Most of your OpenAPI document is generated by reflecting on your application code, especially ResourceController subclasses. You add customization or additional information by overriding methods in APIComponentDocumenter and APIOperationDocumenter . At minimum, you override methods in your ResourceController to document the responses your application will send for a particular endpoint. You create documents with the conduit document command-line tool. Guides Creating an OpenAPI Document Documenting Components Documenting Endpoint Controllers Documenting Middleware Controllers","title":"OpenAPI"},{"location":"openapi/#openapi","text":"Conduit applications auto-generate an OpenAPI 3.0 document. Most of your OpenAPI document is generated by reflecting on your application code, especially ResourceController subclasses. You add customization or additional information by overriding methods in APIComponentDocumenter and APIOperationDocumenter . At minimum, you override methods in your ResourceController to document the responses your application will send for a particular endpoint. You create documents with the conduit document command-line tool.","title":"OpenAPI"},{"location":"openapi/#guides","text":"Creating an OpenAPI Document Documenting Components Documenting Endpoint Controllers Documenting Middleware Controllers","title":"Guides"},{"location":"openapi/cli/","text":"Creating OpenAPI Documents In this document, you'll learn how to use the conduit command line tool to generate an OpenAPI document for your application. OpenAPI Documents OpenAPI documents describe the details of every request and possible response your application has. These documents are JSON objects that follow a specification. This specification defines which properties the document can (or must) have. By following this specification, your application can take advantage of tools such as documentation viewers and source code generators. The two most important objects in an OpenAPI document are components and path operations. A path operation contains an expected request and possible responses. Components are reusable definitions that you can use in a path operation. For example, a 400 Bad Request response component can be reused across path operations that may send this response. Most of the documentation process revolves around registering components and creating path operations. The conduit document Command Documents can be written by hand, but it takes a lot of time and is hard to keep in sync with your code. Conduit analyzes your code to build (most) of a document for you. You run the conduit document command in your project's directory, and it prints the JSON document to your console. cd my_project/ conduit document -- Conduit CLI Version: 3.0.0 -- Conduit project version: 3.0.0 {\"openapi\":\"3.0.0\",\"info\":... You may copy the output to use it in another tool; for example, by entering it into Swagger Editor . If you want to build a tool that runs this command, but don't want to parse the version info from the output, use the --machine flag. conduit document --machine {\"openapi\":\"3.0.0\",\"info\":... Much of the metadata in an OpenAPI document - such as title or version - is derived from your application's pubspec.yaml . If you want to override the derived values, or provide values that can't be derived, use options like --title or --license-name . See conduit document --help for all options. How Applications are Documented When you run the conduit document command, it creates an empty APIDocument that objects in your application will populate. Your application goes through its normal initialization process (i.e., prepare and entryPoint ). Controllers and service objects are then told to register components. For example, all ManagedObject s register themselves as a reusable schema component. After components are registered, the controllers in an application are told to create path operations that define the requests they handle. !!! note \"Configuration Files\" Because your application goes through initialization as if it were going to run the application, you must have a valid configuration file when documenting. This defaults to 'config.yaml.src', the same file you use for running tests. See conduit document --help to use a different file. Documenting Components Objects that register components implement APIComponentDocumenter.documentComponents . Controllers - which implement this method - automatically document their components as long as they are linked to your application's entry point. Other types of objects that implement this method will be automatically documented if they are declared as a property of your ApplicationChannel . For example, in the following code, the AuthServer , Router and PathController all automatically document their components. class MyChannel extends ApplicationChannel { AuthServer authServer; @override Future prepare() async { authServer = new AuthServer(...); } @override Controller get entryPoint { final router = new Router(); router.route(\"/path\").link(() => new PathController()); return router; } } In most applications, the automatically documented objects are the only objects that register components. If you have an object that needs to register components, but aren't automatically documented, override documentComponents in your app channel to tell that object to register components. You must call the superclass' implementation. class MyChannel extends ApplicationChannel { ... @override void documentComponents(APIDocumentContext context) { super.documentComponents(context); objectWithComponents.documentComponents(context); } } You can override documentComponents in controllers and services that you create. Read the guide on component documentation for more details. Document Path Operations A path operation is the expected request and possible responses for a path (e.g., /users ) and its request method (e.g., GET ). Each operation describes how to send a request to the server, like which headers or query parameters to include. Responses describe the status code, headers and body that can be sent. Each controller implements APIOperationDocumenter.documentOperations to define this information for the requests it handles. Built-in controllers like Authorizer and ResourceController already implement this method. You typically only override this method when creating your own middleware. For more information on documenting middleware, see this guide . When creating documentation for ResourceController s, request parameters are derived from your bindings, but you still need to provide the possible responses. For more information on documenting endpoint controllers, see this guide .","title":"Creating an OpenAPI Document"},{"location":"openapi/cli/#creating-openapi-documents","text":"In this document, you'll learn how to use the conduit command line tool to generate an OpenAPI document for your application.","title":"Creating OpenAPI Documents"},{"location":"openapi/cli/#openapi-documents","text":"OpenAPI documents describe the details of every request and possible response your application has. These documents are JSON objects that follow a specification. This specification defines which properties the document can (or must) have. By following this specification, your application can take advantage of tools such as documentation viewers and source code generators. The two most important objects in an OpenAPI document are components and path operations. A path operation contains an expected request and possible responses. Components are reusable definitions that you can use in a path operation. For example, a 400 Bad Request response component can be reused across path operations that may send this response. Most of the documentation process revolves around registering components and creating path operations.","title":"OpenAPI Documents"},{"location":"openapi/cli/#the-conduit-document-command","text":"Documents can be written by hand, but it takes a lot of time and is hard to keep in sync with your code. Conduit analyzes your code to build (most) of a document for you. You run the conduit document command in your project's directory, and it prints the JSON document to your console. cd my_project/ conduit document -- Conduit CLI Version: 3.0.0 -- Conduit project version: 3.0.0 {\"openapi\":\"3.0.0\",\"info\":... You may copy the output to use it in another tool; for example, by entering it into Swagger Editor . If you want to build a tool that runs this command, but don't want to parse the version info from the output, use the --machine flag. conduit document --machine {\"openapi\":\"3.0.0\",\"info\":... Much of the metadata in an OpenAPI document - such as title or version - is derived from your application's pubspec.yaml . If you want to override the derived values, or provide values that can't be derived, use options like --title or --license-name . See conduit document --help for all options.","title":"The conduit document Command"},{"location":"openapi/cli/#how-applications-are-documented","text":"When you run the conduit document command, it creates an empty APIDocument that objects in your application will populate. Your application goes through its normal initialization process (i.e., prepare and entryPoint ). Controllers and service objects are then told to register components. For example, all ManagedObject s register themselves as a reusable schema component. After components are registered, the controllers in an application are told to create path operations that define the requests they handle. !!! note \"Configuration Files\" Because your application goes through initialization as if it were going to run the application, you must have a valid configuration file when documenting. This defaults to 'config.yaml.src', the same file you use for running tests. See conduit document --help to use a different file.","title":"How Applications are Documented"},{"location":"openapi/cli/#documenting-components","text":"Objects that register components implement APIComponentDocumenter.documentComponents . Controllers - which implement this method - automatically document their components as long as they are linked to your application's entry point. Other types of objects that implement this method will be automatically documented if they are declared as a property of your ApplicationChannel . For example, in the following code, the AuthServer , Router and PathController all automatically document their components. class MyChannel extends ApplicationChannel { AuthServer authServer; @override Future prepare() async { authServer = new AuthServer(...); } @override Controller get entryPoint { final router = new Router(); router.route(\"/path\").link(() => new PathController()); return router; } } In most applications, the automatically documented objects are the only objects that register components. If you have an object that needs to register components, but aren't automatically documented, override documentComponents in your app channel to tell that object to register components. You must call the superclass' implementation. class MyChannel extends ApplicationChannel { ... @override void documentComponents(APIDocumentContext context) { super.documentComponents(context); objectWithComponents.documentComponents(context); } } You can override documentComponents in controllers and services that you create. Read the guide on component documentation for more details.","title":"Documenting Components"},{"location":"openapi/cli/#document-path-operations","text":"A path operation is the expected request and possible responses for a path (e.g., /users ) and its request method (e.g., GET ). Each operation describes how to send a request to the server, like which headers or query parameters to include. Responses describe the status code, headers and body that can be sent. Each controller implements APIOperationDocumenter.documentOperations to define this information for the requests it handles. Built-in controllers like Authorizer and ResourceController already implement this method. You typically only override this method when creating your own middleware. For more information on documenting middleware, see this guide . When creating documentation for ResourceController s, request parameters are derived from your bindings, but you still need to provide the possible responses. For more information on documenting endpoint controllers, see this guide .","title":"Document Path Operations"},{"location":"openapi/components/","text":"Document Components In this document, you'll learn how to register and use OpenAPI components in your application's documentation. Registering Components with APIDocumentContext When your application is being documented, a single instance of APIDocumentContext is created and passed to every documentation method. The context stores the document being created, but more importantly, is a container for reusable components. You may register components by implementing APIComponentDocumenter and implementing its abstract method. For example, the following code registers a reusable schema object: class SourceRepository implements APIComponentDocumenter { @override void documentComponents(APIDocumentContext context) { super.documentComponents(context); context.schema.register(\"SourceRepository\", APISchemaObject.object({ \"id\": APISchemaObject.integer(), \"name\": APISchemaObject.string() }); } } A \"SourceRepository\" is an object that contains two fields, \"id\" (an integer) and \"name\" (a string). This component can be used anywhere a schema object can be used. Schema objects are one type of component that document what is typically considered to be a 'model object'. You most often see schema objects in request and response bodies. By default, each of your ManagedObject s are registered as schema objects. The other types of components are: responses, request bodies, parameters, headers, security schemes, and callbacks. Components must be registered with a name, but can additionally be registered with a type. This allows users of a component to reference it by its Dart type. Including a type reference for an object is an optional argument when registering. context.schema.register(\"SourceRepository\", APISchemaObject.object({ \"id\": APISchemaObject.integer(), \"name\": APISchemaObject.string() }, representation: SourceRepository); The order in which components are registered and referenced does not matter. If you reference a component that is created later in the documentation process, it will be resolved prior to the document being completed. If a referenced component is never registered, an error is thrown and your document will fail to generate. Using Components Components can be used when declaring path operations, or as part of other components. For example, if you were to describe a response whose body was a component named \"SourceRepository\", it would look like this: class RepositoryController extends ResourceController { ... @override Map<String, APIResponse> documentOperationResponses(APIDocumentContext context, Operation operation) { if (operation.method == \"GET\") { return { \"200\": APIResponse.schema(context.schema[\"SourceRepository\"]) }; } return null; } } If an object has been registered by its type, you may use getObjectWithType . class RepositoryController extends ResourceController { ... @override Map<String, APIResponse> documentOperationResponses(APIDocumentContext context, Operation operation) { if (operation.method == \"GET\") { return { \"200\": APIResponse.schema(context.schema.getObjectWithType(SourceRepository)) }; } return null; } } Component Discovery All controllers are can document components when they are linked to the entry point. Objects other than controllers will automatically document their components if they implement APIComponentDocumenter and are declared properties of your ApplicationChannel . (See this guide for other options.) Built-in Conduit types will register any applicable components. This includes the types that handle OAuth2 as well as all ManagedObject subclasses in your application. ManagedObject Discovery Declaring a ManagedContext as a property of your ApplicationChannel will automatically document the managed objects of your application as schema components. Serializable Discovery If a Serializable object is bound to a request body in a ResourceController , it will automatically be documented as a schema component. By default, the properties of the Serializable object are reflected on to produce this component. To override this behavior and provide your own component documentation, implement the following method in your Serializable subclass: class Person extends Serializable { String name; Map<String, dynamic> asMap() => {\"name\": name}; void readFromMap(Map<String, dynamic> map) { name = map['name']; } APISchemaObject documentSchema(APIDocumentContext context) { return APISchemaObject.object(properties: { \"name\": APISchemaObject.string() }); } } If you Serializable type is not bound to a resource controller operation, you must register it yourself. This typically occurs by overriding documentComponents in the controller that uses the type. class MyController extends ResourceController { ... @override void documentComponents(APIDocumentContext context) { super.documentComponents(context); final personSchema = Person().documentSchema(context); context.schema.register( \"Person\", personSchema, representation: Person); } }","title":"Documenting Components"},{"location":"openapi/components/#document-components","text":"In this document, you'll learn how to register and use OpenAPI components in your application's documentation.","title":"Document Components"},{"location":"openapi/components/#registering-components-with-apidocumentcontext","text":"When your application is being documented, a single instance of APIDocumentContext is created and passed to every documentation method. The context stores the document being created, but more importantly, is a container for reusable components. You may register components by implementing APIComponentDocumenter and implementing its abstract method. For example, the following code registers a reusable schema object: class SourceRepository implements APIComponentDocumenter { @override void documentComponents(APIDocumentContext context) { super.documentComponents(context); context.schema.register(\"SourceRepository\", APISchemaObject.object({ \"id\": APISchemaObject.integer(), \"name\": APISchemaObject.string() }); } } A \"SourceRepository\" is an object that contains two fields, \"id\" (an integer) and \"name\" (a string). This component can be used anywhere a schema object can be used. Schema objects are one type of component that document what is typically considered to be a 'model object'. You most often see schema objects in request and response bodies. By default, each of your ManagedObject s are registered as schema objects. The other types of components are: responses, request bodies, parameters, headers, security schemes, and callbacks. Components must be registered with a name, but can additionally be registered with a type. This allows users of a component to reference it by its Dart type. Including a type reference for an object is an optional argument when registering. context.schema.register(\"SourceRepository\", APISchemaObject.object({ \"id\": APISchemaObject.integer(), \"name\": APISchemaObject.string() }, representation: SourceRepository); The order in which components are registered and referenced does not matter. If you reference a component that is created later in the documentation process, it will be resolved prior to the document being completed. If a referenced component is never registered, an error is thrown and your document will fail to generate.","title":"Registering Components with APIDocumentContext"},{"location":"openapi/components/#using-components","text":"Components can be used when declaring path operations, or as part of other components. For example, if you were to describe a response whose body was a component named \"SourceRepository\", it would look like this: class RepositoryController extends ResourceController { ... @override Map<String, APIResponse> documentOperationResponses(APIDocumentContext context, Operation operation) { if (operation.method == \"GET\") { return { \"200\": APIResponse.schema(context.schema[\"SourceRepository\"]) }; } return null; } } If an object has been registered by its type, you may use getObjectWithType . class RepositoryController extends ResourceController { ... @override Map<String, APIResponse> documentOperationResponses(APIDocumentContext context, Operation operation) { if (operation.method == \"GET\") { return { \"200\": APIResponse.schema(context.schema.getObjectWithType(SourceRepository)) }; } return null; } }","title":"Using Components"},{"location":"openapi/components/#component-discovery","text":"All controllers are can document components when they are linked to the entry point. Objects other than controllers will automatically document their components if they implement APIComponentDocumenter and are declared properties of your ApplicationChannel . (See this guide for other options.) Built-in Conduit types will register any applicable components. This includes the types that handle OAuth2 as well as all ManagedObject subclasses in your application.","title":"Component Discovery"},{"location":"openapi/components/#managedobject-discovery","text":"Declaring a ManagedContext as a property of your ApplicationChannel will automatically document the managed objects of your application as schema components.","title":"ManagedObject Discovery"},{"location":"openapi/components/#serializable-discovery","text":"If a Serializable object is bound to a request body in a ResourceController , it will automatically be documented as a schema component. By default, the properties of the Serializable object are reflected on to produce this component. To override this behavior and provide your own component documentation, implement the following method in your Serializable subclass: class Person extends Serializable { String name; Map<String, dynamic> asMap() => {\"name\": name}; void readFromMap(Map<String, dynamic> map) { name = map['name']; } APISchemaObject documentSchema(APIDocumentContext context) { return APISchemaObject.object(properties: { \"name\": APISchemaObject.string() }); } } If you Serializable type is not bound to a resource controller operation, you must register it yourself. This typically occurs by overriding documentComponents in the controller that uses the type. class MyController extends ResourceController { ... @override void documentComponents(APIDocumentContext context) { super.documentComponents(context); final personSchema = Person().documentSchema(context); context.schema.register( \"Person\", personSchema, representation: Person); } }","title":"Serializable Discovery"},{"location":"openapi/endpoint/","text":"Documenting Endpoint Controllers In this document, you'll learn how to document endpoint controllers. ResourceController Auto-Documentation A ResourceController does most of the heavy lifting when it comes to generating OpenAPI documents. It will reflect on the bound variables of operation methods to provide the majority of an OpenAPI document. You only need to provide the possible responses. You do this by overriding documentOperationResponses in your ResourceController subclass. The below shows a trivial example of a resource controller that returns a 200 OK with no body for every request. class MyController extends ResourceController { ... Map<String, APIResponse> documentOperationResponses(APIDocumentContext context, Operation operation) { return {\"200\": APIResponse(\"Successful response.\")}; } } This method must return a map, where each key is a string status code and each value is an APIResponse object. An APIResponse object is highly configurable, but in most cases, you only need to declare the schema of its body. For this purpose, a convenience constructor named APIResponse.schema exists. Here is an example where the JSON response body contains a single integer field named 'id': Map<String, APIResponse> documentOperationResponses(APIDocumentContext context, Operation operation) { return { \"200\": APIResponse.schema(\"Successful response.\", APISchemaObject.object({ \"id\": APISchemaObject.integer() })) }; } In practice, you'll want to have different responses depending on the request method and path variables. The operation argument tells you which operation you are documenting. Map<String, APIResponse> documentOperationResponses(APIDocumentContext context, Operation operation) { if (operation.method == \"GET\") { if (operation.pathVariables.contains(\"id\")) { return {\"200\": APIResponse(\"An object by its id.\")}; } else { return {\"200\": APIResponse(\"All objects.\")}; } } return null; } While a resource controller derives the rest of its documentation from your code, you may at times want to override this behavior. Individual elements may be modified by overriding methods like documentOperationParameters , or you may override documentOperations to take over the whole process. If you are not using ResourceController , you must override documentOperations in your controller and provide all of the operation information yourself.","title":"Documenting Endpoint Controllers"},{"location":"openapi/endpoint/#documenting-endpoint-controllers","text":"In this document, you'll learn how to document endpoint controllers.","title":"Documenting Endpoint Controllers"},{"location":"openapi/endpoint/#resourcecontroller-auto-documentation","text":"A ResourceController does most of the heavy lifting when it comes to generating OpenAPI documents. It will reflect on the bound variables of operation methods to provide the majority of an OpenAPI document. You only need to provide the possible responses. You do this by overriding documentOperationResponses in your ResourceController subclass. The below shows a trivial example of a resource controller that returns a 200 OK with no body for every request. class MyController extends ResourceController { ... Map<String, APIResponse> documentOperationResponses(APIDocumentContext context, Operation operation) { return {\"200\": APIResponse(\"Successful response.\")}; } } This method must return a map, where each key is a string status code and each value is an APIResponse object. An APIResponse object is highly configurable, but in most cases, you only need to declare the schema of its body. For this purpose, a convenience constructor named APIResponse.schema exists. Here is an example where the JSON response body contains a single integer field named 'id': Map<String, APIResponse> documentOperationResponses(APIDocumentContext context, Operation operation) { return { \"200\": APIResponse.schema(\"Successful response.\", APISchemaObject.object({ \"id\": APISchemaObject.integer() })) }; } In practice, you'll want to have different responses depending on the request method and path variables. The operation argument tells you which operation you are documenting. Map<String, APIResponse> documentOperationResponses(APIDocumentContext context, Operation operation) { if (operation.method == \"GET\") { if (operation.pathVariables.contains(\"id\")) { return {\"200\": APIResponse(\"An object by its id.\")}; } else { return {\"200\": APIResponse(\"All objects.\")}; } } return null; } While a resource controller derives the rest of its documentation from your code, you may at times want to override this behavior. Individual elements may be modified by overriding methods like documentOperationParameters , or you may override documentOperations to take over the whole process. If you are not using ResourceController , you must override documentOperations in your controller and provide all of the operation information yourself.","title":"ResourceController Auto-Documentation"},{"location":"openapi/middleware/","text":"Documenting Middleware Controllers In this document, you'll learn how to document middleware controllers. Adding to an Operation For the purposes of documentation, a middleware controller does not create operation request and responses. Rather, it modifies the operation details provided by its endpoint controller. When writing middleware controllers, you must override documentOperations and call the superclass' implementation. This allows the middleware's linked controller to document its operations, which will eventually reach an endpoint controller. Once the endpoint controller returns the meat of the operation document, a middleware controller can modify it. For example, a middleware that requires a query parameter named 'key' would like like so: class Middleware extends Controller { ... @override Map<String, APIOperation> documentOperations(APIDocumentContext context, String route, APIPath path) { final ops = super.documentOperations(context, route, path); // ops has been filled out by an endpoint controller, // add 'key' query parameter to each operation. ops.forEach((method, op) { op.addParameter(APIParameter.query(\"key\", schema: APISchemaObject.string())); }); return ops; } } Each string key in an operations map is the lowercase name of an HTTP method, e.g. 'get' or 'post'. An APIOperation encapsulates its request parameters and responses.","title":"Documenting Middleware Controllers"},{"location":"openapi/middleware/#documenting-middleware-controllers","text":"In this document, you'll learn how to document middleware controllers.","title":"Documenting Middleware Controllers"},{"location":"openapi/middleware/#adding-to-an-operation","text":"For the purposes of documentation, a middleware controller does not create operation request and responses. Rather, it modifies the operation details provided by its endpoint controller. When writing middleware controllers, you must override documentOperations and call the superclass' implementation. This allows the middleware's linked controller to document its operations, which will eventually reach an endpoint controller. Once the endpoint controller returns the meat of the operation document, a middleware controller can modify it. For example, a middleware that requires a query parameter named 'key' would like like so: class Middleware extends Controller { ... @override Map<String, APIOperation> documentOperations(APIDocumentContext context, String route, APIPath path) { final ops = super.documentOperations(context, route, path); // ops has been filled out by an endpoint controller, // add 'key' query parameter to each operation. ops.forEach((method, op) { op.addParameter(APIParameter.query(\"key\", schema: APISchemaObject.string())); }); return ops; } } Each string key in an operations map is the lowercase name of an HTTP method, e.g. 'get' or 'post'. An APIOperation encapsulates its request parameters and responses.","title":"Adding to an Operation"},{"location":"snippets/","text":"Conduit Snippets These snippets are quick examples of common code that you can use and modify in your application. HTTP Routing, Request and Response Snippets ORM and Database Snippets Authorization and Authentication Snippets","title":"Overview"},{"location":"snippets/#conduit-snippets","text":"These snippets are quick examples of common code that you can use and modify in your application. HTTP Routing, Request and Response Snippets ORM and Database Snippets Authorization and Authentication Snippets","title":"Conduit Snippets"},{"location":"snippets/auth/","text":"Conduit Authorization and Authentication Snippets Enable OAuth 2.0 import 'package:conduit/conduit.dart'; import 'package:conduit/managed_auth.dart'; class AppChannel extends ApplicationChannel { AuthServer authServer; ManagedContext context; @override Future prepare() async { final dataModel = new ManagedDataModel.fromCurrentMirrorSystem(); final psc = new PostgreSQLPersistentStore( \"username\", \"password\", \"localhost\", 5432 \"my_app\"); context = new ManagedContext(dataModel, psc); final delegate = new ManagedAuthDelegate<User>(context); authServer = new AuthServer(delegate); } @override Controller get entryPoint { final router = Router(); router.route(\"/auth/token\").link(() => AuthController(authServer)); return router; } } Add OAuth 2.0 Clients to Database conduit auth add-client \\ --id com.app.test \\ --secret supersecret \\ --allowed-scopes 'profile kiosk:location raw_db_access.readonly' \\ --connect postgres://username:password@localhost:5432/my_app Require OAuth 2.0 Scope to Access Routes import 'package:conduit/conduit.dart'; import 'package:conduit/managed_auth.dart'; class AppChannel extends ApplicationChannel { AuthServer authServer; ManagedContext context; @override Future prepare() async { final dataModel = ManagedDataModel.fromCurrentMirrorSystem(); final psc = PostgreSQLPersistentStore( \"username\", \"password\", \"localhost\", 5432 \"my_app\"); context = new ManagedContext(dataModel, psc); final delegate = ManagedAuthDelegate<User>(context); authServer = AuthServer(delegate); } @override Controller get entryPoint { router.route(\"/auth/token\").link(() => AuthController(authServer)); router .route(\"/profile\") .link(() => Authorizer.bearer(authServer, scopes: [\"profile.readonly\"])) .link(() => ProfileController(context)); } } class ProfileController extends ResourceController { ProfileController(this.context); final ManagedContext context; @Operation.get() Future<Response> getProfile() async { final id = request.authorization.ownerID; final query = new Query<User>(context) ..where((u) => u.id).equalTo(id); return new Response.ok(await query.fetchOne()); } } Basic Authentication import 'package:conduit/conduit.dart'; class AppChannel extends ApplicationChannel { @override Controller get entryPoint { final router = new Router(); router .route(\"/profile\") .link(() => Authorizer.basic(PasswordVerifier())) .linkFunction((req) async => new Response.ok(null)); return router; } } class PasswordVerifier extends AuthValidator { @override FutureOr<Authorization> validate<T>(AuthorizationParser<T> parser, T authorizationData, {List<AuthScope> requiredScope}) { if (!isPasswordCorrect(authorizationData)) { return null; } return Authorization(null, authorizationData.username, this); } } Add OAuth 2.0 Authorization Code Flow import 'package:conduit/conduit.dart'; import 'package:conduit/managed_auth.dart'; class AppChannel extends ApplicationChannel { AuthServer authServer; ManagedContext context; @override Future prepare() async { final dataModel = ManagedDataModel.fromCurrentMirrorSystem(); final psc = PostgreSQLPersistentStore( \"username\", \"password\", \"localhost\", 5432 \"my_app\"); context = new ManagedContext(dataModel, psc); final delegate = new ManagedAuthDelegate<User>(context); authServer = new AuthServer(delegate); } @override Controller get entryPoint { final router = new Router(); router.route(\"/auth/token\").link(() => AuthController(authServer)); router.route(\"/auth/code\").link(() => AuthCodeController(authServer, delegate: this)); return router; } Future<String> render(AuthCodeController forController, Uri requestUri, String responseType, String clientID, String state, String scope) async { return \"\"\" <!DOCTYPE html> <html lang=\"en\"> <head> <meta charset=\"UTF-8\"> <title>Login</title> </head> <body> <div class=\"container\"> <h1>Login</h1> <form action=\"${requestUri.path}\" method=\"POST\"> <input type=\"hidden\" name=\"state\" value=\"$state\"> <input type=\"hidden\" name=\"client_id\" value=\"$clientID\"> <input type=\"hidden\" name=\"response_type\" value=\"$responseType\"> <div class=\"form-group\"> <label for=\"username\">User Name</label> <input type=\"text\" class=\"form-control\" name=\"username\" placeholder=\"Please enter your user name\"> </div> <div class=\"form-group\"> <label for=\"password\">Password</label> <input type=\"password\" class=\"form-control\" name=\"password\" placeholder=\"Please enter your password\"> </div> <button type=\"submit\" class=\"btn btn-success\">Login</button> </form> </div> </body> </html> \"\"\"; } }","title":"Authentication and Authorization"},{"location":"snippets/auth/#conduit-authorization-and-authentication-snippets","text":"","title":"Conduit Authorization and Authentication Snippets"},{"location":"snippets/auth/#enable-oauth-20","text":"import 'package:conduit/conduit.dart'; import 'package:conduit/managed_auth.dart'; class AppChannel extends ApplicationChannel { AuthServer authServer; ManagedContext context; @override Future prepare() async { final dataModel = new ManagedDataModel.fromCurrentMirrorSystem(); final psc = new PostgreSQLPersistentStore( \"username\", \"password\", \"localhost\", 5432 \"my_app\"); context = new ManagedContext(dataModel, psc); final delegate = new ManagedAuthDelegate<User>(context); authServer = new AuthServer(delegate); } @override Controller get entryPoint { final router = Router(); router.route(\"/auth/token\").link(() => AuthController(authServer)); return router; } }","title":"Enable OAuth 2.0"},{"location":"snippets/auth/#add-oauth-20-clients-to-database","text":"conduit auth add-client \\ --id com.app.test \\ --secret supersecret \\ --allowed-scopes 'profile kiosk:location raw_db_access.readonly' \\ --connect postgres://username:password@localhost:5432/my_app","title":"Add OAuth 2.0 Clients to Database"},{"location":"snippets/auth/#require-oauth-20-scope-to-access-routes","text":"import 'package:conduit/conduit.dart'; import 'package:conduit/managed_auth.dart'; class AppChannel extends ApplicationChannel { AuthServer authServer; ManagedContext context; @override Future prepare() async { final dataModel = ManagedDataModel.fromCurrentMirrorSystem(); final psc = PostgreSQLPersistentStore( \"username\", \"password\", \"localhost\", 5432 \"my_app\"); context = new ManagedContext(dataModel, psc); final delegate = ManagedAuthDelegate<User>(context); authServer = AuthServer(delegate); } @override Controller get entryPoint { router.route(\"/auth/token\").link(() => AuthController(authServer)); router .route(\"/profile\") .link(() => Authorizer.bearer(authServer, scopes: [\"profile.readonly\"])) .link(() => ProfileController(context)); } } class ProfileController extends ResourceController { ProfileController(this.context); final ManagedContext context; @Operation.get() Future<Response> getProfile() async { final id = request.authorization.ownerID; final query = new Query<User>(context) ..where((u) => u.id).equalTo(id); return new Response.ok(await query.fetchOne()); } }","title":"Require OAuth 2.0 Scope to Access Routes"},{"location":"snippets/auth/#basic-authentication","text":"import 'package:conduit/conduit.dart'; class AppChannel extends ApplicationChannel { @override Controller get entryPoint { final router = new Router(); router .route(\"/profile\") .link(() => Authorizer.basic(PasswordVerifier())) .linkFunction((req) async => new Response.ok(null)); return router; } } class PasswordVerifier extends AuthValidator { @override FutureOr<Authorization> validate<T>(AuthorizationParser<T> parser, T authorizationData, {List<AuthScope> requiredScope}) { if (!isPasswordCorrect(authorizationData)) { return null; } return Authorization(null, authorizationData.username, this); } }","title":"Basic Authentication"},{"location":"snippets/auth/#add-oauth-20-authorization-code-flow","text":"import 'package:conduit/conduit.dart'; import 'package:conduit/managed_auth.dart'; class AppChannel extends ApplicationChannel { AuthServer authServer; ManagedContext context; @override Future prepare() async { final dataModel = ManagedDataModel.fromCurrentMirrorSystem(); final psc = PostgreSQLPersistentStore( \"username\", \"password\", \"localhost\", 5432 \"my_app\"); context = new ManagedContext(dataModel, psc); final delegate = new ManagedAuthDelegate<User>(context); authServer = new AuthServer(delegate); } @override Controller get entryPoint { final router = new Router(); router.route(\"/auth/token\").link(() => AuthController(authServer)); router.route(\"/auth/code\").link(() => AuthCodeController(authServer, delegate: this)); return router; } Future<String> render(AuthCodeController forController, Uri requestUri, String responseType, String clientID, String state, String scope) async { return \"\"\" <!DOCTYPE html> <html lang=\"en\"> <head> <meta charset=\"UTF-8\"> <title>Login</title> </head> <body> <div class=\"container\"> <h1>Login</h1> <form action=\"${requestUri.path}\" method=\"POST\"> <input type=\"hidden\" name=\"state\" value=\"$state\"> <input type=\"hidden\" name=\"client_id\" value=\"$clientID\"> <input type=\"hidden\" name=\"response_type\" value=\"$responseType\"> <div class=\"form-group\"> <label for=\"username\">User Name</label> <input type=\"text\" class=\"form-control\" name=\"username\" placeholder=\"Please enter your user name\"> </div> <div class=\"form-group\"> <label for=\"password\">Password</label> <input type=\"password\" class=\"form-control\" name=\"password\" placeholder=\"Please enter your password\"> </div> <button type=\"submit\" class=\"btn btn-success\">Login</button> </form> </div> </body> </html> \"\"\"; } }","title":"Add OAuth 2.0 Authorization Code Flow"},{"location":"snippets/http/","text":"Conduit HTTP Snippets Hello, World class AppChannel extends ApplicationChannel { @override Controller get entryPoint { final router = Router(); router.route(\"/hello_world\").linkFunction((request) async { return Response.ok(\"Hello, world!\") ..contentType = ContentType.text; }); return router; } } Route Variables class AppChannel extends ApplicationChannel { @override Controller get entryPoint { final router = Router(); router.route(\"/variable/[:variable]\").linkFunction((request) async { return Response.ok({ \"method\": request.raw.method, \"path\": request.path.variables[\"variable\"] ?? \"not specified\" }); }); return router; } } Grouping Routes and Binding Path Variables class AppChannel extends ApplicationChannel { @override Controller get entryPoint { final router = Router(); router .route(\"/users/[:id]\") .link(() => MyController()); return router; } } class MyController extends ResourceController { final List<String> things = ['thing1', 'thing2']; @Operation.get() Future<Response> getThings() async { return Response.ok(things); } @Operation.get('id') Future<Response> getThing(@Bind.path('id') int id) async { if (id < 0 || id >= things.length) { return Response.notFound(); } return Response.ok(things[id]); } } Custom Middleware class AppChannel extends ApplicationChannel { @override Controller get entryPoint { final router = Router(); router .route(\"/rate_limit\") .link(() => RateLimiter()) .linkFunction((req) async => Response.ok({ \"requests_remaining\": req.attachments[\"remaining\"] })); return router; } } class RateLimiter extends RequestController { @override Future<RequestOrResponse> handle(Request request) async { final apiKey = request.raw.headers.value(\"x-apikey\"); final requestsRemaining = await remainingRequestsForAPIKey(apiKey); if (requestsRemaining <= 0) { return Response(429, null, null); } request.addResponseModifier((r) { r.headers[\"x-remaining-requests\"] = requestsRemaining; }); return request; } } Application-Wide CORS Allowed Origins class AppChannel extends ApplicationChannel { @override Future prepare() async { // All controllers will use this policy by default CORSPolicy.defaultPolicy.allowedOrigins = [\"https://mywebsite.com\"]; } @override Controller get entryPoint { final router = Router(); router.route(\"/things\").linkFunction((request) async { return Response.ok([\"Widget\", \"Doodad\", \"Transformer\"]); }); return router; } } Serve Files and Set Cache-Control Headers class AppChannel extends ApplicationChannel { @override Controller get entryPoint { final router = Router(); router.route(\"/files/*\").link(() => FileController(\"web\") ..addCachePolicy(new CachePolicy(expirationFromNow: new Duration(days: 365)), (path) => path.endsWith(\".js\") || path.endsWith(\".css\")) ); return router; } } Streaming Responses (Server Side Events with text/event-stream) class AppChannel extends ApplicationChannel { final StreamController<String> controller = new StreamController<String>(); @override Future prepare() async { var count = 0; Timer.periodic(new Duration(seconds: 1), (_) { count ++; controller.add(\"This server has been up for $count seconds\\n\"); }); } @override Controller get entryPoint { final router = new Router(); router.route(\"/stream\").linkFunction((req) async { return Response.ok(controller.stream) ..bufferOutput = false ..contentType = new ContentType( \"text\", \"event-stream\", charset: \"utf-8\"); }); return router; } } A websocket server class AppChannel extends ApplicationChannel { List<WebSocket> websockets = []; @override Future prepare() async { // When another isolate gets a websocket message, echo it to // websockets connected on this isolate. messageHub.listen(sendBytesToConnectedClients); } @override Controller get entryPoint { final router = Router(); // Allow websocket clients to connect to ws://host/connect router.route(\"/connect\").linkFunction((request) async { var websocket = await WebSocketTransformer.upgrade(request.raw); websocket.listen(echo, onDone: () { websockets.remove(websocket); }, cancelOnError: true); websockets.add(websocket); // Take request out of channel return null; }); return router; } void sendBytesToConnectedClients(List<int> bytes) { websockets.forEach((ws) { ws.add(bytes); }); } void echo(List<int> bytes) { sendBytesToConnectedClients(bytes); // Send to other isolates messageHub.add(bytes); } } Setting Content-Type and Encoding a Response Body class AppChannel extends ApplicationChannel { final ContentType CSV = ContentType(\"text\", \"csv\", charset: \"utf-8\"); @override Future prepare() async { // CsvCodec extends dart:convert.Codec CodecRegistry.defaultInstance.add(CSV, new CsvCodec()); } @override Controller get entryPoint { final router = Router(); router.route(\"/csv\").linkFunction((req) async { // These values will get converted by CsvCodec into a comma-separated string return Response.ok([[1, 2, 3], [\"a\", \"b\", \"c\"]]) ..contentType = CSV; }); return router; } } Proxy a File From Another Server class AppChannel extends ApplicationChannel { @override Controller get entryPoint { final router = Router(); router.route(\"/proxy/*\").linkFunction((req) async { var fileURL = \"https://otherserver/${req.path.remainingPath}\"; var fileRequest = await client.getUrl(url); var fileResponse = await req.close(); if (fileResponse.statusCode != 200) { return new Response.notFound(); } // A dart:io.HttpResponse is a Stream<List<int>> of its body bytes. return new Response.ok(fileResponse) ..contentType = fileResponse.headers.contentType // let the data just pass through because it has already been encoded // according to content-type; applying encoding again would cause // an issue ..encodeBody = false; }); return router; } }","title":"HTTP"},{"location":"snippets/http/#conduit-http-snippets","text":"","title":"Conduit HTTP Snippets"},{"location":"snippets/http/#hello-world","text":"class AppChannel extends ApplicationChannel { @override Controller get entryPoint { final router = Router(); router.route(\"/hello_world\").linkFunction((request) async { return Response.ok(\"Hello, world!\") ..contentType = ContentType.text; }); return router; } }","title":"Hello, World"},{"location":"snippets/http/#route-variables","text":"class AppChannel extends ApplicationChannel { @override Controller get entryPoint { final router = Router(); router.route(\"/variable/[:variable]\").linkFunction((request) async { return Response.ok({ \"method\": request.raw.method, \"path\": request.path.variables[\"variable\"] ?? \"not specified\" }); }); return router; } }","title":"Route Variables"},{"location":"snippets/http/#grouping-routes-and-binding-path-variables","text":"class AppChannel extends ApplicationChannel { @override Controller get entryPoint { final router = Router(); router .route(\"/users/[:id]\") .link(() => MyController()); return router; } } class MyController extends ResourceController { final List<String> things = ['thing1', 'thing2']; @Operation.get() Future<Response> getThings() async { return Response.ok(things); } @Operation.get('id') Future<Response> getThing(@Bind.path('id') int id) async { if (id < 0 || id >= things.length) { return Response.notFound(); } return Response.ok(things[id]); } }","title":"Grouping Routes and Binding Path Variables"},{"location":"snippets/http/#custom-middleware","text":"class AppChannel extends ApplicationChannel { @override Controller get entryPoint { final router = Router(); router .route(\"/rate_limit\") .link(() => RateLimiter()) .linkFunction((req) async => Response.ok({ \"requests_remaining\": req.attachments[\"remaining\"] })); return router; } } class RateLimiter extends RequestController { @override Future<RequestOrResponse> handle(Request request) async { final apiKey = request.raw.headers.value(\"x-apikey\"); final requestsRemaining = await remainingRequestsForAPIKey(apiKey); if (requestsRemaining <= 0) { return Response(429, null, null); } request.addResponseModifier((r) { r.headers[\"x-remaining-requests\"] = requestsRemaining; }); return request; } }","title":"Custom Middleware"},{"location":"snippets/http/#application-wide-cors-allowed-origins","text":"class AppChannel extends ApplicationChannel { @override Future prepare() async { // All controllers will use this policy by default CORSPolicy.defaultPolicy.allowedOrigins = [\"https://mywebsite.com\"]; } @override Controller get entryPoint { final router = Router(); router.route(\"/things\").linkFunction((request) async { return Response.ok([\"Widget\", \"Doodad\", \"Transformer\"]); }); return router; } }","title":"Application-Wide CORS Allowed Origins"},{"location":"snippets/http/#serve-files-and-set-cache-control-headers","text":"class AppChannel extends ApplicationChannel { @override Controller get entryPoint { final router = Router(); router.route(\"/files/*\").link(() => FileController(\"web\") ..addCachePolicy(new CachePolicy(expirationFromNow: new Duration(days: 365)), (path) => path.endsWith(\".js\") || path.endsWith(\".css\")) ); return router; } }","title":"Serve Files and Set Cache-Control Headers"},{"location":"snippets/http/#streaming-responses-server-side-events-with-textevent-stream","text":"class AppChannel extends ApplicationChannel { final StreamController<String> controller = new StreamController<String>(); @override Future prepare() async { var count = 0; Timer.periodic(new Duration(seconds: 1), (_) { count ++; controller.add(\"This server has been up for $count seconds\\n\"); }); } @override Controller get entryPoint { final router = new Router(); router.route(\"/stream\").linkFunction((req) async { return Response.ok(controller.stream) ..bufferOutput = false ..contentType = new ContentType( \"text\", \"event-stream\", charset: \"utf-8\"); }); return router; } }","title":"Streaming Responses (Server Side Events with text/event-stream)"},{"location":"snippets/http/#a-websocket-server","text":"class AppChannel extends ApplicationChannel { List<WebSocket> websockets = []; @override Future prepare() async { // When another isolate gets a websocket message, echo it to // websockets connected on this isolate. messageHub.listen(sendBytesToConnectedClients); } @override Controller get entryPoint { final router = Router(); // Allow websocket clients to connect to ws://host/connect router.route(\"/connect\").linkFunction((request) async { var websocket = await WebSocketTransformer.upgrade(request.raw); websocket.listen(echo, onDone: () { websockets.remove(websocket); }, cancelOnError: true); websockets.add(websocket); // Take request out of channel return null; }); return router; } void sendBytesToConnectedClients(List<int> bytes) { websockets.forEach((ws) { ws.add(bytes); }); } void echo(List<int> bytes) { sendBytesToConnectedClients(bytes); // Send to other isolates messageHub.add(bytes); } }","title":"A websocket server"},{"location":"snippets/http/#setting-content-type-and-encoding-a-response-body","text":"class AppChannel extends ApplicationChannel { final ContentType CSV = ContentType(\"text\", \"csv\", charset: \"utf-8\"); @override Future prepare() async { // CsvCodec extends dart:convert.Codec CodecRegistry.defaultInstance.add(CSV, new CsvCodec()); } @override Controller get entryPoint { final router = Router(); router.route(\"/csv\").linkFunction((req) async { // These values will get converted by CsvCodec into a comma-separated string return Response.ok([[1, 2, 3], [\"a\", \"b\", \"c\"]]) ..contentType = CSV; }); return router; } }","title":"Setting Content-Type and Encoding a Response Body"},{"location":"snippets/http/#proxy-a-file-from-another-server","text":"class AppChannel extends ApplicationChannel { @override Controller get entryPoint { final router = Router(); router.route(\"/proxy/*\").linkFunction((req) async { var fileURL = \"https://otherserver/${req.path.remainingPath}\"; var fileRequest = await client.getUrl(url); var fileResponse = await req.close(); if (fileResponse.statusCode != 200) { return new Response.notFound(); } // A dart:io.HttpResponse is a Stream<List<int>> of its body bytes. return new Response.ok(fileResponse) ..contentType = fileResponse.headers.contentType // let the data just pass through because it has already been encoded // according to content-type; applying encoding again would cause // an issue ..encodeBody = false; }); return router; } }","title":"Proxy a File From Another Server"},{"location":"snippets/orm/","text":"Conduit ORM Snippets Filter Query by Column/Property (WHERE clause) var query = new Query<Employee>(context) ..where((e) => e.title).equalTo(\"Programmer\"); var employees = await query.fetch(); Fetching Only Some Columns/Properties var query = new Query<Employee>(context) ..resultingProperties((e) => [e.id, e.name]); var employees = await query.fetch(); Sorting Rows/Objects var query = new Query<Employee>(context) ..sortBy((e) => e.salary, QuerySortOrder.ascending); var employees = await query.fetch(); Fetching Only One Row/Object var query = new Query<Employee>(context) ..where((e) => e.id).equalTo(1); var employee = await query.fetchOne(); Executing a Join (Has-One) var query = new Query<Team>(context) ..join(object: (e) => e.league); var teamsAndTheirLeague = await query.fetch(); Executing a Join (Has-Many) var query = new Query<Team>(context) ..join(set: (e) => e.players); var teamsAndTheirPlayers = await query.fetch(); Filtering Joined Rows/Objects var query = new Query<Team>(context); var subquery = query.join(set: (e) => e.players) ..where((p) => p.yearsPlayed).lessThanOrEqualTo(1); var teamsAndTheirRookiePlayers = await query.fetch(); Filter Rows/Objects by Relationship Property var query = new Query<Team>(context) ..where((t) => t.players.haveAtLeastOneWhere.yearsPlayed).lessThanOrEqualTo(1); var teamsWithRookies = await query.fetch(); Complex/Unsupported WHERE Clause (using 'OR') var query = new Query<Team>(context) ..predicate = new QueryPredicate(\"name = @name1 OR name = @name2\", { \"name1\": \"Badgers\", \"name2\": \"Gophers\" }); var badgerAndGopherTeams = await query.fetch(); Updating a Row/Object var query = new Query<Team>(context) ..where((t) => t.id).equalTo(10) ..values.name = \"Badgers\"; var team = await query.updateOne(); Configure a Database Connection from Configuration File class AppChannel extends ApplicationChannel { @override Future prepare() async { context = contextWithConnectionInfo(options.configurationFilePath.database); } ManagedContext context; @override Controller get entryPoint { final router = new Router(); ... return router; } ManagedContext contextWithConnectionInfo( DatabaseConnectionConfiguration connectionInfo) { var dataModel = new ManagedDataModel.fromCurrentMirrorSystem(); var psc = new PostgreSQLPersistentStore( connectionInfo.username, connectionInfo.password, connectionInfo.host, connectionInfo.port, connectionInfo.databaseName); return new ManagedContext(dataModel, psc); } } class MyAppConfiguration extends Configuration { MyAppConfiguration(String fileName) : super.fromFile(File(fileName)); DatabaseConnectionConfiguration database; }","title":"ORM"},{"location":"snippets/orm/#conduit-orm-snippets","text":"","title":"Conduit ORM Snippets"},{"location":"snippets/orm/#filter-query-by-columnproperty-where-clause","text":"var query = new Query<Employee>(context) ..where((e) => e.title).equalTo(\"Programmer\"); var employees = await query.fetch();","title":"Filter Query by Column/Property (WHERE clause)"},{"location":"snippets/orm/#fetching-only-some-columnsproperties","text":"var query = new Query<Employee>(context) ..resultingProperties((e) => [e.id, e.name]); var employees = await query.fetch();","title":"Fetching Only Some Columns/Properties"},{"location":"snippets/orm/#sorting-rowsobjects","text":"var query = new Query<Employee>(context) ..sortBy((e) => e.salary, QuerySortOrder.ascending); var employees = await query.fetch();","title":"Sorting Rows/Objects"},{"location":"snippets/orm/#fetching-only-one-rowobject","text":"var query = new Query<Employee>(context) ..where((e) => e.id).equalTo(1); var employee = await query.fetchOne();","title":"Fetching Only One Row/Object"},{"location":"snippets/orm/#executing-a-join-has-one","text":"var query = new Query<Team>(context) ..join(object: (e) => e.league); var teamsAndTheirLeague = await query.fetch();","title":"Executing a Join (Has-One)"},{"location":"snippets/orm/#executing-a-join-has-many","text":"var query = new Query<Team>(context) ..join(set: (e) => e.players); var teamsAndTheirPlayers = await query.fetch();","title":"Executing a Join (Has-Many)"},{"location":"snippets/orm/#filtering-joined-rowsobjects","text":"var query = new Query<Team>(context); var subquery = query.join(set: (e) => e.players) ..where((p) => p.yearsPlayed).lessThanOrEqualTo(1); var teamsAndTheirRookiePlayers = await query.fetch();","title":"Filtering Joined Rows/Objects"},{"location":"snippets/orm/#filter-rowsobjects-by-relationship-property","text":"var query = new Query<Team>(context) ..where((t) => t.players.haveAtLeastOneWhere.yearsPlayed).lessThanOrEqualTo(1); var teamsWithRookies = await query.fetch();","title":"Filter Rows/Objects by Relationship Property"},{"location":"snippets/orm/#complexunsupported-where-clause-using-or","text":"var query = new Query<Team>(context) ..predicate = new QueryPredicate(\"name = @name1 OR name = @name2\", { \"name1\": \"Badgers\", \"name2\": \"Gophers\" }); var badgerAndGopherTeams = await query.fetch();","title":"Complex/Unsupported WHERE Clause (using 'OR')"},{"location":"snippets/orm/#updating-a-rowobject","text":"var query = new Query<Team>(context) ..where((t) => t.id).equalTo(10) ..values.name = \"Badgers\"; var team = await query.updateOne();","title":"Updating a Row/Object"},{"location":"snippets/orm/#configure-a-database-connection-from-configuration-file","text":"class AppChannel extends ApplicationChannel { @override Future prepare() async { context = contextWithConnectionInfo(options.configurationFilePath.database); } ManagedContext context; @override Controller get entryPoint { final router = new Router(); ... return router; } ManagedContext contextWithConnectionInfo( DatabaseConnectionConfiguration connectionInfo) { var dataModel = new ManagedDataModel.fromCurrentMirrorSystem(); var psc = new PostgreSQLPersistentStore( connectionInfo.username, connectionInfo.password, connectionInfo.host, connectionInfo.port, connectionInfo.databaseName); return new ManagedContext(dataModel, psc); } } class MyAppConfiguration extends Configuration { MyAppConfiguration(String fileName) : super.fromFile(File(fileName)); DatabaseConnectionConfiguration database; }","title":"Configure a Database Connection from Configuration File"},{"location":"snippets/test/","text":"Conduit Test Snippets Expect that Response Returns a JSON Object with an ID test(\"that Response Returns a JSON Object\", () async { expectResponse( await app.client.request(\"/endpoint\").get(), 200, body: { \"id\": isNumber } ); }); Expect that Response Returns a List of JSON Objects with IDs test(\"that Response returns a list of JSON Objects with IDs\", () async { expectResponse( await app.client.request(\"/endpoint\").get(), 200, body: everyElement({ \"id\": isNumber }) ); }); Expect that Last-Modified Header Is After Date test(\"that Last-Modified Header Is After Date \", () async { expect( await app.client.request(\"/endpoint\").get(), hasHeaders({ \"last-modified\": isAfter(new DateTime(2017)) }); }); HTTP POST with JSON in Test test(\"that can send JSON body\", () async { var request = app.client.request(\"/endpoint\") ..json = { \"id\": 1 }; expect(await request.post(), hasStatus(202)); });","title":"Testing"},{"location":"snippets/test/#conduit-test-snippets","text":"","title":"Conduit Test Snippets"},{"location":"snippets/test/#expect-that-response-returns-a-json-object-with-an-id","text":"test(\"that Response Returns a JSON Object\", () async { expectResponse( await app.client.request(\"/endpoint\").get(), 200, body: { \"id\": isNumber } ); });","title":"Expect that Response Returns a JSON Object with an ID"},{"location":"snippets/test/#expect-that-response-returns-a-list-of-json-objects-with-ids","text":"test(\"that Response returns a list of JSON Objects with IDs\", () async { expectResponse( await app.client.request(\"/endpoint\").get(), 200, body: everyElement({ \"id\": isNumber }) ); });","title":"Expect that Response Returns a List of JSON Objects with IDs"},{"location":"snippets/test/#expect-that-last-modified-header-is-after-date","text":"test(\"that Last-Modified Header Is After Date \", () async { expect( await app.client.request(\"/endpoint\").get(), hasHeaders({ \"last-modified\": isAfter(new DateTime(2017)) }); });","title":"Expect that Last-Modified Header Is After Date"},{"location":"snippets/test/#http-post-with-json-in-test","text":"test(\"that can send JSON body\", () async { var request = app.client.request(\"/endpoint\") ..json = { \"id\": 1 }; expect(await request.post(), hasStatus(202)); });","title":"HTTP POST with JSON in Test"},{"location":"testing/","text":"Testing Conduit applications can be run, tested, debugged and profiled. You create a subclass of TestHarness<T> in your application's test/ directory. For each test suite, you install this harness to start and stop your application in 'test' mode. A test harness runs your application like a live application. You use Agent objects to send HTTP requests to your application under test. Agents add default information to all of their requests, like authorization information. You use test matchers like hasResponse or hasStatus to validate the response your application sends for a given request. You provide mock services for external services that your application communicates with. These are often driven by the contents of a configuration file. (By convention, a configuration file for tests is named config.src.yaml .) You may also create mock services with MockHTTPServer to use during testing. Guides Writing Tests with a Test Harness Testing with the ORM and OAuth 2.0 Developing Client Applications Using the Debugger and Profiling Use Mock Services","title":"Testing"},{"location":"testing/#testing","text":"Conduit applications can be run, tested, debugged and profiled. You create a subclass of TestHarness<T> in your application's test/ directory. For each test suite, you install this harness to start and stop your application in 'test' mode. A test harness runs your application like a live application. You use Agent objects to send HTTP requests to your application under test. Agents add default information to all of their requests, like authorization information. You use test matchers like hasResponse or hasStatus to validate the response your application sends for a given request. You provide mock services for external services that your application communicates with. These are often driven by the contents of a configuration file. (By convention, a configuration file for tests is named config.src.yaml .) You may also create mock services with MockHTTPServer to use during testing.","title":"Testing"},{"location":"testing/#guides","text":"Writing Tests with a Test Harness Testing with the ORM and OAuth 2.0 Developing Client Applications Using the Debugger and Profiling Use Mock Services","title":"Guides"},{"location":"testing/clients/","text":"Using Conduit when Writing Client Applications Running a Conduit server locally while developing client applications is an important part of the development process. Run applications through their bin/main.dart script or conduit serve . The former allows for debugging the application with a debugger. Enable Logging and Return Server Errors Ensure that logging is on while developing client applications by registering a listener on ApplicationChannel.logger . class MyApplicationChannel extends ApplicationChannel { @override Future prepare() async { logger.onRecord.listen((record) { print(\"$record ${record.error ?? \"\"} ${record.stackTrace ?? \"\"}\"); }); } ... } A useful feature to turn on during debugging is sending stack traces for 500 Server Error responses. Turn this flag on in a ApplicationChannel while debugging: class MyApplicationChannel extends ApplicationChannel { @override Future prepare() async { Controller.includeErrorDetailsInServerErrorResponses = true; } ... } When a 500 error is encountered, the server will send the stack trace back to the client so you can view it while developing the client application without having to switch terminals. This property should never be left on for production code. Avoid Port Conflicts Applications run with conduit serve default to port 8888. You may use the --port command-line option to pick a different port: conduit serve --port 4000 Provision a Database for Client Testing For applications that use the ORM, you must have a locally running database with a schema that matches your application's data model. If you are using OAuth 2.0, you must have also added client identifiers to the locally running database. You may add client identifiers with the conduit auth command-line tool.","title":"Developing Client Applications"},{"location":"testing/clients/#using-conduit-when-writing-client-applications","text":"Running a Conduit server locally while developing client applications is an important part of the development process. Run applications through their bin/main.dart script or conduit serve . The former allows for debugging the application with a debugger.","title":"Using Conduit when Writing Client Applications"},{"location":"testing/clients/#enable-logging-and-return-server-errors","text":"Ensure that logging is on while developing client applications by registering a listener on ApplicationChannel.logger . class MyApplicationChannel extends ApplicationChannel { @override Future prepare() async { logger.onRecord.listen((record) { print(\"$record ${record.error ?? \"\"} ${record.stackTrace ?? \"\"}\"); }); } ... } A useful feature to turn on during debugging is sending stack traces for 500 Server Error responses. Turn this flag on in a ApplicationChannel while debugging: class MyApplicationChannel extends ApplicationChannel { @override Future prepare() async { Controller.includeErrorDetailsInServerErrorResponses = true; } ... } When a 500 error is encountered, the server will send the stack trace back to the client so you can view it while developing the client application without having to switch terminals. This property should never be left on for production code.","title":"Enable Logging and Return Server Errors"},{"location":"testing/clients/#avoid-port-conflicts","text":"Applications run with conduit serve default to port 8888. You may use the --port command-line option to pick a different port: conduit serve --port 4000","title":"Avoid Port Conflicts"},{"location":"testing/clients/#provision-a-database-for-client-testing","text":"For applications that use the ORM, you must have a locally running database with a schema that matches your application's data model. If you are using OAuth 2.0, you must have also added client identifiers to the locally running database. You may add client identifiers with the conduit auth command-line tool.","title":"Provision a Database for Client Testing"},{"location":"testing/debugger/","text":"Debugging Conduit Applications The debugger may be used when running tests or developing client applications locally. Enabling the Debugger Applications created by conduit create ship with a bin/main.dart script that starts the application. When developing, running this script from an IDE is often preferred to conduit serve because the IDE can leverage its full capabilities. One such capability is a debugger. In IntelliJ IDEA (and its suite of products), you may right-click on this file and select 'Debug' from the pop-up menu to run the application in the debugger. Setting Breakpoints A valuable feature of a debugger is the ability to set breakpoints. A breakpoint pauses execution of your application at a specific point in the code, allowing you to view variable values and monitor the code path line-by-line as execution continues. To set a breakpoint, you simply click on the gutter area next to the line of code you wish to stop at. Once a debugger stops, you can view variable values in the center pane of the debugging panel. The left pane (labeled 'Frames') shows the current stack trace. The row of buttons above the stack trace allow you to continue executing code line-by-line. Each button in this row has a slightly different behavior. From left to right: The red arrow with the stack of lines continues execution until the next breakpoint is encountered. The blue downwards arrow executes the current line and moves to the next line. The blue right/downward arrow continues execution into the function that is about to be called and stops on its first line. The red right/downward arrow is the same as above, but will also jump into dependency code. The blue right/upwards arrow completes execution of the current method and stops right after the callsite. Note that currently asynchronous invocations confuse the debugger a bit. To continue past an asynchronous method to the next line, set a breakpoint on that next line and hit the big green arrow on the left column of buttons. To jump into an asynchronous method, command-click on its definition and set a breakpoint on its first line and then click the big green arrow. Profiling with Observatory You may also use Observatory to profile applications. Profiling consists of monitoring memory usage, allocations and how much time a function spends executing relative to the rest of your application. Both conduit serve and bin/main.dart support starting Observatory. When running the application with conduit serve , add the --observe flag and Observatory will start listening on port 8181 and a web browser will automatically be opened. conduit serve --observe When running the application through IntelliJ, Observatory will start listening on a random port. In the run console in IntelliJ, you may click on the Observatory hyperlink to open it in your web browser.","title":"Using the Debugger"},{"location":"testing/debugger/#debugging-conduit-applications","text":"The debugger may be used when running tests or developing client applications locally.","title":"Debugging Conduit Applications"},{"location":"testing/debugger/#enabling-the-debugger","text":"Applications created by conduit create ship with a bin/main.dart script that starts the application. When developing, running this script from an IDE is often preferred to conduit serve because the IDE can leverage its full capabilities. One such capability is a debugger. In IntelliJ IDEA (and its suite of products), you may right-click on this file and select 'Debug' from the pop-up menu to run the application in the debugger.","title":"Enabling the Debugger"},{"location":"testing/debugger/#setting-breakpoints","text":"A valuable feature of a debugger is the ability to set breakpoints. A breakpoint pauses execution of your application at a specific point in the code, allowing you to view variable values and monitor the code path line-by-line as execution continues. To set a breakpoint, you simply click on the gutter area next to the line of code you wish to stop at. Once a debugger stops, you can view variable values in the center pane of the debugging panel. The left pane (labeled 'Frames') shows the current stack trace. The row of buttons above the stack trace allow you to continue executing code line-by-line. Each button in this row has a slightly different behavior. From left to right: The red arrow with the stack of lines continues execution until the next breakpoint is encountered. The blue downwards arrow executes the current line and moves to the next line. The blue right/downward arrow continues execution into the function that is about to be called and stops on its first line. The red right/downward arrow is the same as above, but will also jump into dependency code. The blue right/upwards arrow completes execution of the current method and stops right after the callsite. Note that currently asynchronous invocations confuse the debugger a bit. To continue past an asynchronous method to the next line, set a breakpoint on that next line and hit the big green arrow on the left column of buttons. To jump into an asynchronous method, command-click on its definition and set a breakpoint on its first line and then click the big green arrow.","title":"Setting Breakpoints"},{"location":"testing/debugger/#profiling-with-observatory","text":"You may also use Observatory to profile applications. Profiling consists of monitoring memory usage, allocations and how much time a function spends executing relative to the rest of your application. Both conduit serve and bin/main.dart support starting Observatory. When running the application with conduit serve , add the --observe flag and Observatory will start listening on port 8181 and a web browser will automatically be opened. conduit serve --observe When running the application through IntelliJ, Observatory will start listening on a random port. In the run console in IntelliJ, you may click on the Observatory hyperlink to open it in your web browser.","title":"Profiling with Observatory"},{"location":"testing/mixins/","text":"Testing Applications That Use ORM and OAuth 2.0 This document describes how to set up your test code to test applications that use the ORM and OAuth 2.0. These types of applications require extra initialization steps, e.g. set up a test database. Testing Applications That Use the ORM Conduit's ORM uses PostgreSQL as its database. Before your tests run, Conduit will create your application's database tables in a local PostgreSQL database. After the tests complete, it will delete those tables. This allows you to start with an empty database for each test suite as well as control exactly which records are in your database while testing, but without having to manage database schemas or use a mock implementation (e.g., SQLite). !!! warning \"You Must Install PostgreSQL Locally\" On macOS, Postgres.app is a simple, self-contained PostgreSQL instance that you can run as a normal application. (See PostgreSQL installation for other platforms .) Local Database for Tests The same database is reused for testing all of your applications. You only have to create this database once per development machine, or when running in a CI tool like TravisCI. From PostgreSQL's prompt, run: CREATE DATABASE dart_test; CREATE USER dart WITH createdb; ALTER USER dart WITH password 'dart'; GRANT all ON DATABASE dart_test TO dart; A database configuration in your application's config.yaml.src must match the following: username: dart password: dart host: localhost port: 5432 databaseName: dart_test Your application, when run with a subclass of TestHarness<T> , will configure its database connection to connect to the local test database. You must mixin TestHarnessORMMixin with your test harness and invoke resetData by overriding onSetUp . You may also override seed to insert test data into the database. class Harness extends TestHarness<AppChannel> with TestHarnessORMMixin { @override ManagedContext get context => channel.context; @override Future onSetUp() async { await resetData(); } @override Future seed() async { /* insert some rows here */ } } !!! tip \"Seeding Data\" You should only seed static data in the seed method; this may include things like categories or country codes that cannot be changed during runtime. Data that is manipulated for specific test cases should be invoked in a test setUp callback or the test itself. Local Database for Running an Application A database separate from the test database should be used for running an application locally. You can create a database locally by running psql to open a PostgreSQL terminal and run the following commands: CREATE DATABASE my_app_name; CREATE USER my_app_user WITH PASSWORD 'mypassword'; GRANT ALL ON DATABASE my_app_name TO my_app_user; Add your schema to the local database by generating and executing migration scripts: conduit db generate conduit db upgrade --connect postgres://my_app_user:mypassword@localhost:5432/my_app_name Testing Applications That Use OAuth 2.0 Applications that use OAuth 2.0 should mixin TestHarnessAuthMixin . This mixin adds methods for registering a client identifier and authenticating a user. Both methods return an Agent with default headers with authorization information for the client identifier or user. Most often, you use package:conduit/managed_auth for an ORM-driven OAuth2 delegate. You must also mixin TestHarnessORMMixin when using this mixin. class Harness extends TestHarness<AppChannel> with TestHarnessAuthMixin<AppChannel>, TestHarnessORMMixin { @override ManagedContext get context => channel.context; @override AuthServer get authServer => channel.authServer; Agent publicAgent; @override Future onSetUp() async { await resetData(); publicAgent = await addClient(\"com.conduit.public\"); } Future<Agent> registerUser(User user, {Agent withClient}) async { withClient ??= publicAgent; final req = withClient.request(\"/register\") ..body = {\"username\": user.username, \"password\": user.password}; await req.post(); return loginUser(withClient, user.username, user.password); } }","title":"Testing with the ORM and OAuth 2.0"},{"location":"testing/mixins/#testing-applications-that-use-orm-and-oauth-20","text":"This document describes how to set up your test code to test applications that use the ORM and OAuth 2.0. These types of applications require extra initialization steps, e.g. set up a test database.","title":"Testing Applications That Use ORM and OAuth 2.0"},{"location":"testing/mixins/#testing-applications-that-use-the-orm","text":"Conduit's ORM uses PostgreSQL as its database. Before your tests run, Conduit will create your application's database tables in a local PostgreSQL database. After the tests complete, it will delete those tables. This allows you to start with an empty database for each test suite as well as control exactly which records are in your database while testing, but without having to manage database schemas or use a mock implementation (e.g., SQLite). !!! warning \"You Must Install PostgreSQL Locally\" On macOS, Postgres.app is a simple, self-contained PostgreSQL instance that you can run as a normal application. (See PostgreSQL installation for other platforms .)","title":"Testing Applications That Use the ORM"},{"location":"testing/mixins/#local-database-for-tests","text":"The same database is reused for testing all of your applications. You only have to create this database once per development machine, or when running in a CI tool like TravisCI. From PostgreSQL's prompt, run: CREATE DATABASE dart_test; CREATE USER dart WITH createdb; ALTER USER dart WITH password 'dart'; GRANT all ON DATABASE dart_test TO dart; A database configuration in your application's config.yaml.src must match the following: username: dart password: dart host: localhost port: 5432 databaseName: dart_test Your application, when run with a subclass of TestHarness<T> , will configure its database connection to connect to the local test database. You must mixin TestHarnessORMMixin with your test harness and invoke resetData by overriding onSetUp . You may also override seed to insert test data into the database. class Harness extends TestHarness<AppChannel> with TestHarnessORMMixin { @override ManagedContext get context => channel.context; @override Future onSetUp() async { await resetData(); } @override Future seed() async { /* insert some rows here */ } } !!! tip \"Seeding Data\" You should only seed static data in the seed method; this may include things like categories or country codes that cannot be changed during runtime. Data that is manipulated for specific test cases should be invoked in a test setUp callback or the test itself.","title":"Local Database for Tests"},{"location":"testing/mixins/#local-database-for-running-an-application","text":"A database separate from the test database should be used for running an application locally. You can create a database locally by running psql to open a PostgreSQL terminal and run the following commands: CREATE DATABASE my_app_name; CREATE USER my_app_user WITH PASSWORD 'mypassword'; GRANT ALL ON DATABASE my_app_name TO my_app_user; Add your schema to the local database by generating and executing migration scripts: conduit db generate conduit db upgrade --connect postgres://my_app_user:mypassword@localhost:5432/my_app_name","title":"Local Database for Running an Application"},{"location":"testing/mixins/#testing-applications-that-use-oauth-20","text":"Applications that use OAuth 2.0 should mixin TestHarnessAuthMixin . This mixin adds methods for registering a client identifier and authenticating a user. Both methods return an Agent with default headers with authorization information for the client identifier or user. Most often, you use package:conduit/managed_auth for an ORM-driven OAuth2 delegate. You must also mixin TestHarnessORMMixin when using this mixin. class Harness extends TestHarness<AppChannel> with TestHarnessAuthMixin<AppChannel>, TestHarnessORMMixin { @override ManagedContext get context => channel.context; @override AuthServer get authServer => channel.authServer; Agent publicAgent; @override Future onSetUp() async { await resetData(); publicAgent = await addClient(\"com.conduit.public\"); } Future<Agent> registerUser(User user, {Agent withClient}) async { withClient ??= publicAgent; final req = withClient.request(\"/register\") ..body = {\"username\": user.username, \"password\": user.password}; await req.post(); return loginUser(withClient, user.username, user.password); } }","title":"Testing Applications That Use OAuth 2.0"},{"location":"testing/mock/","text":"Mocking External Services A Conduit application often communicates with another server. For example, an application might make requests to the GitHub API to collect analytics about a team's workflow. When running automated tests, consuming the actual GitHub API isn't feasible - because GitHub will probably rate limit you and because the data being returned is constantly changing. To solve this problem, you can create \"mocks\" of a service during testing. Conduit has two testing utilities for this purpose - MockServer and MockHTTPServer - in the conduit/test library. Using a MockHTTPServer When testing your application, you send it requests using a TestClient . As part of the request handling logic, your application might issue requests to some other server. MockHTTPServer allows you to validate that the request your application sent was correct and gives you control what the responses are to those requests. For example, githubMock is an instance of MockHTTPServer in the following test, which ensures that the request was constructed correctly: test(\"Will get correct user from GitHub\", () async { var response = await app.client.authenticatedRequest(\"/github_profile/fred\").get(); var requestSentByYourApplicationToGitHub = await githubMock.next(); expect(requestSentByYourApplicationToGitHub.method, \"GET\"); expect(requestSentByYourApplicationToGitHub.path, \"/users/search?name=fred\"); }); In the above code, we are expecting that anytime the request GET /github_profile/fred is sent to your application, that it turns around and searches for a user in GitHub's API. This test ensures that we have correctly translated our request to a request to be made to the GitHub API. If no request was made - because of a programmer error - this test would fail because the Future returned from githubMock.next() would never complete. There is no next request, because none was ever delivered! By default, any request sent to a MockHTTPServer is a 200 OK Response with an empty body. You may change this behavior by queuing responses in a mock server. test(\"Will get correct user from GitHub\", () async { githubMock.queueResponse(new Response.ok({\"id\": 1, \"name\": \"fred\"})); var response = await app.client.authenticatedRequest(\"/github_profile/fred\").get(); expect(response, hasResponse(200, partial({ \"id\": 1, \"name\": \"fred\" }))) }); In the above code, queueResponse adds a 200 OK Response to the mock server queue with a specific body. The mock server will send that response for the next request it receives. In the implementation of /github_profile/fred , your application sends a GET /users/search?name=fred to the GitHub API - except the GitHub API is your mock server, and it returns the response you queued instead. Thus, the queued up response is the expected response of the GitHub API. After the request completes, the response is removed from the queue and subsequent responses will go back to the default. You may queue as many responses as you like. You may also simulate a failed request - one that never gets a response - like so: mockServer.queueResponse(MockHTTPServer.mockConnectionFailureResponse); You may also subclass MockHTTPServer and override its open method to add logic to determine the response. Please see the implementation of MockHTTPServer.open for more details. Configuring a MockHTTPServer A MockHTTPServer is created when setting up tests. It must be closed when tearing down tests. If you use the same mock server to across all tests (e.g., open it in setUpAll ), make sure to clear it after each test: import 'package:conduit/test.dart'; void main() { var mockServer = new MockHTTPServer(4000); setUpAll(() async { await mockServer.open(); }); tearDownAll(() async { await mockServer.close(); }); tearDown(() async { mockServer.clear(); }); } An instance of MockHTTPServer listens on localhost on a specific port. An application that makes testable external service requests should provide the base URI for those services in a configuration file. The URI for that service in the configuration file used during testing should point at localhost and a specific port. For example, if a deployed config.yaml file has the following key-values: github: baseURL: https://api.github.com/ Then config.src.yaml would have: github: baseURL: http://localhost:4000/ Your application reads this configuration file and injects the base URL into the service that will execute requests. class AppConfiguration extends Configuration { AppConfiguration(String fileName) : super.fromFile(fileName); APIConfiguration github; } class AppApplicationChannel extends ApplicationChannel { @override Future prepare() async { var config = new AppConfiguration(options.configurationFilePath); githubService = new GitHubService(baseURL: config.github.baseURL); } } Note that APIConfiguration is an existing type and is meant for this purpose. Also note that the testing strategy for database connections is not to use a mock but to use a temporary, local database that is set up and torn down during tests. This is possible because you own the data model generating code - whereas you probably don't have access to an external service's development API.","title":"Mocking Services"},{"location":"testing/mock/#mocking-external-services","text":"A Conduit application often communicates with another server. For example, an application might make requests to the GitHub API to collect analytics about a team's workflow. When running automated tests, consuming the actual GitHub API isn't feasible - because GitHub will probably rate limit you and because the data being returned is constantly changing. To solve this problem, you can create \"mocks\" of a service during testing. Conduit has two testing utilities for this purpose - MockServer and MockHTTPServer - in the conduit/test library.","title":"Mocking External Services"},{"location":"testing/mock/#using-a-mockhttpserver","text":"When testing your application, you send it requests using a TestClient . As part of the request handling logic, your application might issue requests to some other server. MockHTTPServer allows you to validate that the request your application sent was correct and gives you control what the responses are to those requests. For example, githubMock is an instance of MockHTTPServer in the following test, which ensures that the request was constructed correctly: test(\"Will get correct user from GitHub\", () async { var response = await app.client.authenticatedRequest(\"/github_profile/fred\").get(); var requestSentByYourApplicationToGitHub = await githubMock.next(); expect(requestSentByYourApplicationToGitHub.method, \"GET\"); expect(requestSentByYourApplicationToGitHub.path, \"/users/search?name=fred\"); }); In the above code, we are expecting that anytime the request GET /github_profile/fred is sent to your application, that it turns around and searches for a user in GitHub's API. This test ensures that we have correctly translated our request to a request to be made to the GitHub API. If no request was made - because of a programmer error - this test would fail because the Future returned from githubMock.next() would never complete. There is no next request, because none was ever delivered! By default, any request sent to a MockHTTPServer is a 200 OK Response with an empty body. You may change this behavior by queuing responses in a mock server. test(\"Will get correct user from GitHub\", () async { githubMock.queueResponse(new Response.ok({\"id\": 1, \"name\": \"fred\"})); var response = await app.client.authenticatedRequest(\"/github_profile/fred\").get(); expect(response, hasResponse(200, partial({ \"id\": 1, \"name\": \"fred\" }))) }); In the above code, queueResponse adds a 200 OK Response to the mock server queue with a specific body. The mock server will send that response for the next request it receives. In the implementation of /github_profile/fred , your application sends a GET /users/search?name=fred to the GitHub API - except the GitHub API is your mock server, and it returns the response you queued instead. Thus, the queued up response is the expected response of the GitHub API. After the request completes, the response is removed from the queue and subsequent responses will go back to the default. You may queue as many responses as you like. You may also simulate a failed request - one that never gets a response - like so: mockServer.queueResponse(MockHTTPServer.mockConnectionFailureResponse); You may also subclass MockHTTPServer and override its open method to add logic to determine the response. Please see the implementation of MockHTTPServer.open for more details.","title":"Using a MockHTTPServer"},{"location":"testing/mock/#configuring-a-mockhttpserver","text":"A MockHTTPServer is created when setting up tests. It must be closed when tearing down tests. If you use the same mock server to across all tests (e.g., open it in setUpAll ), make sure to clear it after each test: import 'package:conduit/test.dart'; void main() { var mockServer = new MockHTTPServer(4000); setUpAll(() async { await mockServer.open(); }); tearDownAll(() async { await mockServer.close(); }); tearDown(() async { mockServer.clear(); }); } An instance of MockHTTPServer listens on localhost on a specific port. An application that makes testable external service requests should provide the base URI for those services in a configuration file. The URI for that service in the configuration file used during testing should point at localhost and a specific port. For example, if a deployed config.yaml file has the following key-values: github: baseURL: https://api.github.com/ Then config.src.yaml would have: github: baseURL: http://localhost:4000/ Your application reads this configuration file and injects the base URL into the service that will execute requests. class AppConfiguration extends Configuration { AppConfiguration(String fileName) : super.fromFile(fileName); APIConfiguration github; } class AppApplicationChannel extends ApplicationChannel { @override Future prepare() async { var config = new AppConfiguration(options.configurationFilePath); githubService = new GitHubService(baseURL: config.github.baseURL); } } Note that APIConfiguration is an existing type and is meant for this purpose. Also note that the testing strategy for database connections is not to use a mock but to use a temporary, local database that is set up and torn down during tests. This is possible because you own the data model generating code - whereas you probably don't have access to an external service's development API.","title":"Configuring a MockHTTPServer"},{"location":"testing/tests/","text":"Testing in Conduit From the ground up, Conduit is built to be tested. In practice, this means two things: A deployed Conduit application has zero code differences from a Conduit application under test. There are helpful utilities for writing tests in Conduit. How Tests are Written A Conduit test suite starts your application with a configuration file specifically built for a test instance of your application. You write test cases that verify the responses of requests sent to this application. Sometimes, you might reach into your application's services to validate that an intended side-effect was triggered. For example, you might ensure that after a request was executed, a row was added to a database table. A TestHarness<T> is a type from package:conduit_test that handles the initialization of your application under test. It is often subclassed to add application-specific startup tasks, like seeding a database with test users or adding OAuth 2.0 clients. A test harness is installed at the beginning of your test's main function. void main() { final harness = new TestHarness<MyApplicationChannel>()..install(); test(\"GET /endpoint returns 200 and a simple object\", () async { final response = await harness.agent.get(\"/endpoint\"); expectResponse(response, 200, body: {\"key\": \"value\"}); }); }} When TestHarness.install is invoked, it installs two callbacks that will start your application in 'test mode' when the tests start, and stop it after the tests complete. An application running in 'test mode' creates a local HTTP server and instantiates your ApplicationChannel on the same isolate as your tests are running on . This allows you to reach into your application channel's services to add test expectations on the state that the services manage. When your application is started in this way, its options have some default values: the application listens on a random port the configurationFilePath is config.src.yaml The config.src.yaml file must have the same structure as your deployment configurations, but values are substituted with test control values. For example, database connection configuration will point at a local test database instead of a production database. For more details on configuring an application, see this guide . !!! note \"Harness Install\" The install method calls setUpAll and tearDownAll from package:test to start and stop your application. You can manually start and stop your application by invoking TestHarness.start and TestHarness.stop . However, this is not recommended because onSetUp and onTearDown will not be called for each test. !!! note \"Uncaught Exceptions when Testing\" A test harness configures the application to let uncaught exceptions escape so that they trigger a failure in your test. This is different than when running an application normally, where all exceptions are caught and send an error response to the HTTP client. Using a TestHarness Subclass Most applications should subclass TestHarness<T> to provide application customization. (Applications created through the CLI have a suclass in test/harness/app.dart .) You override callback methods for events that occur during testing, like when the application starts, and before and after each test. class Harness extends TestHarness<WildfireChannel> { @override Future onSetUp() async { // called before each test } } You must invoke install on your test harness at the beginning of test suite for these callbacks to be called. See harness mixins for classes that can be mixed into your harness for testing applications that use the ORM or OAuth 2.0. Using an Agent to Execute Requests A TestHarness<T> has an agent property that is used to execute requests against the application being tested. An Agent has methods like get and post to execute requests and return a response object that can be validated. Its usage looks like this: test(\"After POST to /thing, GET /thing/:id returns created thing\", () async { final postResponse = await harness.agent.post(\"/thing\", body: {\"key\": \"value\"}); expectResponse(postResponse, 200); final thingId = postResponse.body.as<Map>()[\"id\"]; final getResponse = await harness.agent.get(\"/thing/$thingId\"); expectResponse(getResponse, 200, body: { \"id\": thingId, \"key\": \"value\" }); }); Most requests can be configured and executed in methods like TestHarness.get and TestHarness.post . For additional configuration options, use TestHarness.request to create a request object that can be further customized by its properties: final request = harness.agent.request(\"/endpoint\") ..headers[\"X-Header\"] = \"Value\"; When a request includes a body, the body is encoded according to the content-type of the request (defaults to JSON). The encoding behavior is provided by CodecRegistry , the same type that manages encoding and decoding for your application logic. When adding a body to a test request, you provide the unencoded value (a Dart Map , for example) and it is encoded into the correct value (a JSON object, for example). On the inverse side, when validating a response body, the body is already decoded to a Dart type prior to your test code receiving the response. !!! note \"Codecs and CodecRegistry\" Your tests will run on the same isolate as your application. Whatever codecs have been registered in the codec repository by your application are automatically made available to the code that encodes and decodes your tests requests. You don't have to do anything special to opt-in to non-default codecs. Agents Add Default Values to Requests An Agent has defaults values that it applies to requests from it. These values include headers and the request body content-type. For example, you might want all requests to have an extra header value, without having to write the code to add the header for each request. The default agent of a harness creates requests that have a application/json contentType . Additional agents can be created for different sets of defaults. This is especially useful when testing endpoints that require authorization, where credentials need to be attached to each request. This is a common enough task that there are harness mixins that make this task easier. Writing Test Expectations After an agent executes a request, you write test expectations on its response. These expectations include verifying the status code, headers and body of the response are the desired values. Expectations are set by applying matchers to the properties of a response. For example: test(\"GET /foo returns 200 OK\", () async { final response = await harness.agent.get(\"/foo\"); expect(response.statusCode, 200); expect(response, hasHeaders({\"x-timestamp\": greaterThan(DateTime(2020))})); expect(response, hasBody(isNull)); }); Validating response headers and bodies can be more complex than validating a status code. The hasBody and hasHeaders matchers make expectations on the response headers and body easier to write. The hasHeaders matcher takes a map of header names and values, and expects that the response's headers contains a matching header for each one in the map. The value may be a String or another Matcher . The response can have more headers than expected - those headers are ignored. If you want to exactly specify all headers, there is an optional flag to pass hasHeaders . The hasBody matcher takes any object or matcher that is compared to the decoded body of the response. The body is decoded according to its content-type prior to this comparison. For example, if your response returns a JSON object {\"key\": \"value\"} , this object is first decoded into a Dart Map with the value {'key': 'value'} . The following matchers would all be true: // exact match of Dart Map expect(response, hasBody({'key': 'value'})); // a map that contains a key whose value starts with 'v' expect(response, hasBody({'key': startsWith('v')})); // a map that contains the key 'key' expect(response, hasBody(containsKey('key'))); // a map with one entry expect(response, hasBody(hasLength(1))); For large response bodies where you have other test coverage, you may only want to set expectations for a few values. For example, you might have a map with 50 keys, but all you care about it making sure that status='pending' . For this, there is a partial map matcher. It behaves similar to hasHeaders in that it only checks the keys you provide - any other keys are ignored. For example: // Just ensure the body contains an object with at least status=pending, version>1 expect(response, hasBody(partial({ \"status\": \"pending\", \"version\": greaterThan(1) }))); When using partial , you can also ensure that a map doesn't have a key with the isNotPresent matcher. test(\"Get 200 that at least have these keys\", () async { var response = await app.client.request(\"/endpoint\").get(); expect(response, hasResponse(200, partial({ \"key3\": isNotPresent }))); }); This ensures that key3 is not in the map. This is different than verifying key3: null , which would be true if key3 's value was actually the null value. See the API Reference for conduit_test for more matchers. Verifying Side Effects For requests that are not idempotent (they change data in some way), you must also verify the state of the data has changed correctly after the request. This is often done by sending another request your application handles to get the updated data. For example, after you create an employee with POST /employees , you verify the employee was stored correctly by expecting GET /employees/:id has the same data you just sent it. Sometimes, the expected changes are not accessible through your API. For example, let's say that creating a new employee adds a record to an auditing database, but this database is not accessible through a public API. When testing, however, you would want to ensure that record was added to the database. You can access your application's services (like its database connection) in your tests through TestHarness.channel . For example, you might execute a Query<T> against your application's test database: test(\"POST /employees adds an audit log record\", () async { final response = await harness.agent.post(\"/employees\", body: { \"name\": \"Fred\" }); expect(response, hasStatus(202)); final context = harness.channel.context; final query = new Query<AuditRecord>(context) ..where((record) => record.user.id).equalTo(response.body.as<Map>()['id']); final record = await query.fetchOne(); expect(record, isNotNull); }); Anything the ApplicationChannel can access, so too can the tests. Further Reading For testing applications that use OAuth 2.0 or the ORM, see the guide on mixins for important behavior.","title":"Writing Tests"},{"location":"testing/tests/#testing-in-conduit","text":"From the ground up, Conduit is built to be tested. In practice, this means two things: A deployed Conduit application has zero code differences from a Conduit application under test. There are helpful utilities for writing tests in Conduit.","title":"Testing in Conduit"},{"location":"testing/tests/#how-tests-are-written","text":"A Conduit test suite starts your application with a configuration file specifically built for a test instance of your application. You write test cases that verify the responses of requests sent to this application. Sometimes, you might reach into your application's services to validate that an intended side-effect was triggered. For example, you might ensure that after a request was executed, a row was added to a database table. A TestHarness<T> is a type from package:conduit_test that handles the initialization of your application under test. It is often subclassed to add application-specific startup tasks, like seeding a database with test users or adding OAuth 2.0 clients. A test harness is installed at the beginning of your test's main function. void main() { final harness = new TestHarness<MyApplicationChannel>()..install(); test(\"GET /endpoint returns 200 and a simple object\", () async { final response = await harness.agent.get(\"/endpoint\"); expectResponse(response, 200, body: {\"key\": \"value\"}); }); }} When TestHarness.install is invoked, it installs two callbacks that will start your application in 'test mode' when the tests start, and stop it after the tests complete. An application running in 'test mode' creates a local HTTP server and instantiates your ApplicationChannel on the same isolate as your tests are running on . This allows you to reach into your application channel's services to add test expectations on the state that the services manage. When your application is started in this way, its options have some default values: the application listens on a random port the configurationFilePath is config.src.yaml The config.src.yaml file must have the same structure as your deployment configurations, but values are substituted with test control values. For example, database connection configuration will point at a local test database instead of a production database. For more details on configuring an application, see this guide . !!! note \"Harness Install\" The install method calls setUpAll and tearDownAll from package:test to start and stop your application. You can manually start and stop your application by invoking TestHarness.start and TestHarness.stop . However, this is not recommended because onSetUp and onTearDown will not be called for each test. !!! note \"Uncaught Exceptions when Testing\" A test harness configures the application to let uncaught exceptions escape so that they trigger a failure in your test. This is different than when running an application normally, where all exceptions are caught and send an error response to the HTTP client.","title":"How Tests are Written"},{"location":"testing/tests/#using-a-testharness-subclass","text":"Most applications should subclass TestHarness<T> to provide application customization. (Applications created through the CLI have a suclass in test/harness/app.dart .) You override callback methods for events that occur during testing, like when the application starts, and before and after each test. class Harness extends TestHarness<WildfireChannel> { @override Future onSetUp() async { // called before each test } } You must invoke install on your test harness at the beginning of test suite for these callbacks to be called. See harness mixins for classes that can be mixed into your harness for testing applications that use the ORM or OAuth 2.0.","title":"Using a TestHarness Subclass"},{"location":"testing/tests/#using-an-agent-to-execute-requests","text":"A TestHarness<T> has an agent property that is used to execute requests against the application being tested. An Agent has methods like get and post to execute requests and return a response object that can be validated. Its usage looks like this: test(\"After POST to /thing, GET /thing/:id returns created thing\", () async { final postResponse = await harness.agent.post(\"/thing\", body: {\"key\": \"value\"}); expectResponse(postResponse, 200); final thingId = postResponse.body.as<Map>()[\"id\"]; final getResponse = await harness.agent.get(\"/thing/$thingId\"); expectResponse(getResponse, 200, body: { \"id\": thingId, \"key\": \"value\" }); }); Most requests can be configured and executed in methods like TestHarness.get and TestHarness.post . For additional configuration options, use TestHarness.request to create a request object that can be further customized by its properties: final request = harness.agent.request(\"/endpoint\") ..headers[\"X-Header\"] = \"Value\"; When a request includes a body, the body is encoded according to the content-type of the request (defaults to JSON). The encoding behavior is provided by CodecRegistry , the same type that manages encoding and decoding for your application logic. When adding a body to a test request, you provide the unencoded value (a Dart Map , for example) and it is encoded into the correct value (a JSON object, for example). On the inverse side, when validating a response body, the body is already decoded to a Dart type prior to your test code receiving the response. !!! note \"Codecs and CodecRegistry\" Your tests will run on the same isolate as your application. Whatever codecs have been registered in the codec repository by your application are automatically made available to the code that encodes and decodes your tests requests. You don't have to do anything special to opt-in to non-default codecs.","title":"Using an Agent to Execute Requests"},{"location":"testing/tests/#agents-add-default-values-to-requests","text":"An Agent has defaults values that it applies to requests from it. These values include headers and the request body content-type. For example, you might want all requests to have an extra header value, without having to write the code to add the header for each request. The default agent of a harness creates requests that have a application/json contentType . Additional agents can be created for different sets of defaults. This is especially useful when testing endpoints that require authorization, where credentials need to be attached to each request. This is a common enough task that there are harness mixins that make this task easier.","title":"Agents Add Default Values to Requests"},{"location":"testing/tests/#writing-test-expectations","text":"After an agent executes a request, you write test expectations on its response. These expectations include verifying the status code, headers and body of the response are the desired values. Expectations are set by applying matchers to the properties of a response. For example: test(\"GET /foo returns 200 OK\", () async { final response = await harness.agent.get(\"/foo\"); expect(response.statusCode, 200); expect(response, hasHeaders({\"x-timestamp\": greaterThan(DateTime(2020))})); expect(response, hasBody(isNull)); }); Validating response headers and bodies can be more complex than validating a status code. The hasBody and hasHeaders matchers make expectations on the response headers and body easier to write. The hasHeaders matcher takes a map of header names and values, and expects that the response's headers contains a matching header for each one in the map. The value may be a String or another Matcher . The response can have more headers than expected - those headers are ignored. If you want to exactly specify all headers, there is an optional flag to pass hasHeaders . The hasBody matcher takes any object or matcher that is compared to the decoded body of the response. The body is decoded according to its content-type prior to this comparison. For example, if your response returns a JSON object {\"key\": \"value\"} , this object is first decoded into a Dart Map with the value {'key': 'value'} . The following matchers would all be true: // exact match of Dart Map expect(response, hasBody({'key': 'value'})); // a map that contains a key whose value starts with 'v' expect(response, hasBody({'key': startsWith('v')})); // a map that contains the key 'key' expect(response, hasBody(containsKey('key'))); // a map with one entry expect(response, hasBody(hasLength(1))); For large response bodies where you have other test coverage, you may only want to set expectations for a few values. For example, you might have a map with 50 keys, but all you care about it making sure that status='pending' . For this, there is a partial map matcher. It behaves similar to hasHeaders in that it only checks the keys you provide - any other keys are ignored. For example: // Just ensure the body contains an object with at least status=pending, version>1 expect(response, hasBody(partial({ \"status\": \"pending\", \"version\": greaterThan(1) }))); When using partial , you can also ensure that a map doesn't have a key with the isNotPresent matcher. test(\"Get 200 that at least have these keys\", () async { var response = await app.client.request(\"/endpoint\").get(); expect(response, hasResponse(200, partial({ \"key3\": isNotPresent }))); }); This ensures that key3 is not in the map. This is different than verifying key3: null , which would be true if key3 's value was actually the null value. See the API Reference for conduit_test for more matchers.","title":"Writing Test Expectations"},{"location":"testing/tests/#verifying-side-effects","text":"For requests that are not idempotent (they change data in some way), you must also verify the state of the data has changed correctly after the request. This is often done by sending another request your application handles to get the updated data. For example, after you create an employee with POST /employees , you verify the employee was stored correctly by expecting GET /employees/:id has the same data you just sent it. Sometimes, the expected changes are not accessible through your API. For example, let's say that creating a new employee adds a record to an auditing database, but this database is not accessible through a public API. When testing, however, you would want to ensure that record was added to the database. You can access your application's services (like its database connection) in your tests through TestHarness.channel . For example, you might execute a Query<T> against your application's test database: test(\"POST /employees adds an audit log record\", () async { final response = await harness.agent.post(\"/employees\", body: { \"name\": \"Fred\" }); expect(response, hasStatus(202)); final context = harness.channel.context; final query = new Query<AuditRecord>(context) ..where((record) => record.user.id).equalTo(response.body.as<Map>()['id']); final record = await query.fetchOne(); expect(record, isNotNull); }); Anything the ApplicationChannel can access, so too can the tests.","title":"Verifying Side Effects"},{"location":"testing/tests/#further-reading","text":"For testing applications that use OAuth 2.0 or the ORM, see the guide on mixins for important behavior.","title":"Further Reading"},{"location":"tut/","text":"Tutorial","title":"Tutorial"},{"location":"tut/#tutorial","text":"","title":"Tutorial"},{"location":"tut/deploying-and-other-fun-things/","text":"Deploying a Conduit Application The last chapter is a quick one - we'll get our application and its database running locally. When writing tests, the harness creates temporary tables that are destroyed when the tests end. Those tables are created in a database named dart_test that is exclusively used for this purpose. All of your projects will use this same database for running tests. To run the application outside of the tests, you'll need another database. Run the psql command-line tool and enter the following SQL: CREATE DATABASE quiz; CREATE USER quiz_user WITH createdb; ALTER USER quiz_user WITH password 'quizzy'; GRANT all ON database quiz TO quiz_user; This creates a database quiz that quiz_user has access to. Now, add quiz 's data model to this database by running the following commands in the project directory: conduit db generate conduit db upgrade --connect postgres://quiz_user:quizzy@localhost:5432/quiz The first command generates a migration file in migrations/ that adds tables _Question and _Answer , and the second command executes that migration file on the newly created database. After adding the data model to the quiz database, run the following commands in psql to insert a question and answer: \\c quiz INSERT INTO _question (description) VALUES ('What is 1+1?'); INSERT INTO _answer (description, question_index) VALUES ('2', 1); The application is currently hard-coded to connect to the test database. We'll write a bit of code to read connection info from a YAML configuration file instead. At the bottom of quiz_sink.dart , create a Configuration subclass: class QuizConfig extends Configuration { QuizConfig(String filename) : super.fromFile(filename); DatabaseConnectionConfiguration database; } Update QuizSink 's constructor to create its persistent store from configuration values: QuizSink(ApplicationOptions appConfig) : super(appConfig) { logger.onRecord.listen((rec) => print(\"$rec ${rec.error ?? \"\"} ${rec.stackTrace ?? \"\"}\")); var dataModel = new ManagedDataModel.fromCurrentMirrorSystem(); var configValues = new QuizConfig(appConfig.configurationFilePath); var persistentStore = new PostgreSQLPersistentStore.fromConnectionInfo( configValues.database.username, configValues.database.password, configValues.database.host, configValues.database.port, configValues.database.databaseName); context = new ManagedContext(dataModel, persistentStore); } Finally, create the file config.yaml in the root of the project directory and add the following key-values pairs: database: username: quiz_user password: quizzy host: localhost port: 5432 databaseName: quiz Run conduit serve and open a browser to http://localhost:8888/questions - you'll see the question in your database. For other ways of running a Conduit application (and tips for running them remotely), take a look at the Deploy Conduit seciton of the docs. The configurationFilePath defaults to config.yaml when using conduit serve . In the test harness, the configurationFilePath is set to config.src.yaml . To continue running the tests, add the database connection configuration for dart_test database to the file config.src.yaml . Onward We've only touched on a small part of Conduit, but we've hit the fundamentals pretty well. The rest of the guides on this site will take you deeper on these topics, and topics we haven't covered like OAuth 2.0. It's very important that you get comfortable using the API reference in addition to these guides. If you are looking to solve a problem, start by looking at the API reference for all of the objects you have access to (including the type you are writing the method for). The properties and methods you have access to will lead you to more properties and methods that'll eventually do what you want done. And lastly, remember to create a new project: conduit create my_next_big_idea","title":"Deploying a Conduit Application"},{"location":"tut/deploying-and-other-fun-things/#deploying-a-conduit-application","text":"The last chapter is a quick one - we'll get our application and its database running locally. When writing tests, the harness creates temporary tables that are destroyed when the tests end. Those tables are created in a database named dart_test that is exclusively used for this purpose. All of your projects will use this same database for running tests. To run the application outside of the tests, you'll need another database. Run the psql command-line tool and enter the following SQL: CREATE DATABASE quiz; CREATE USER quiz_user WITH createdb; ALTER USER quiz_user WITH password 'quizzy'; GRANT all ON database quiz TO quiz_user; This creates a database quiz that quiz_user has access to. Now, add quiz 's data model to this database by running the following commands in the project directory: conduit db generate conduit db upgrade --connect postgres://quiz_user:quizzy@localhost:5432/quiz The first command generates a migration file in migrations/ that adds tables _Question and _Answer , and the second command executes that migration file on the newly created database. After adding the data model to the quiz database, run the following commands in psql to insert a question and answer: \\c quiz INSERT INTO _question (description) VALUES ('What is 1+1?'); INSERT INTO _answer (description, question_index) VALUES ('2', 1); The application is currently hard-coded to connect to the test database. We'll write a bit of code to read connection info from a YAML configuration file instead. At the bottom of quiz_sink.dart , create a Configuration subclass: class QuizConfig extends Configuration { QuizConfig(String filename) : super.fromFile(filename); DatabaseConnectionConfiguration database; } Update QuizSink 's constructor to create its persistent store from configuration values: QuizSink(ApplicationOptions appConfig) : super(appConfig) { logger.onRecord.listen((rec) => print(\"$rec ${rec.error ?? \"\"} ${rec.stackTrace ?? \"\"}\")); var dataModel = new ManagedDataModel.fromCurrentMirrorSystem(); var configValues = new QuizConfig(appConfig.configurationFilePath); var persistentStore = new PostgreSQLPersistentStore.fromConnectionInfo( configValues.database.username, configValues.database.password, configValues.database.host, configValues.database.port, configValues.database.databaseName); context = new ManagedContext(dataModel, persistentStore); } Finally, create the file config.yaml in the root of the project directory and add the following key-values pairs: database: username: quiz_user password: quizzy host: localhost port: 5432 databaseName: quiz Run conduit serve and open a browser to http://localhost:8888/questions - you'll see the question in your database. For other ways of running a Conduit application (and tips for running them remotely), take a look at the Deploy Conduit seciton of the docs. The configurationFilePath defaults to config.yaml when using conduit serve . In the test harness, the configurationFilePath is set to config.src.yaml . To continue running the tests, add the database connection configuration for dart_test database to the file config.src.yaml .","title":"Deploying a Conduit Application"},{"location":"tut/deploying-and-other-fun-things/#onward","text":"We've only touched on a small part of Conduit, but we've hit the fundamentals pretty well. The rest of the guides on this site will take you deeper on these topics, and topics we haven't covered like OAuth 2.0. It's very important that you get comfortable using the API reference in addition to these guides. If you are looking to solve a problem, start by looking at the API reference for all of the objects you have access to (including the type you are writing the method for). The properties and methods you have access to will lead you to more properties and methods that'll eventually do what you want done. And lastly, remember to create a new project: conduit create my_next_big_idea","title":"Onward"},{"location":"tut/executing-queries/","text":"Reading from a Database We will continue to build on the last chapter's project, heroes , by storing our heroes in a database. This will let us to edit our heroes and keep the changes when we restart the application. Object-Relational Mapping A relational database management system (like PostgreSQL or MySQL) stores its data in the form of tables. A table represents some sort of entity - like a person or a bank account. Each table has columns that describe the attributes of that entity - like a name or a balance. Every row in a table is an instance of that entity - like a single person named Bob or a bank account. In an object-oriented framework like Conduit, we have representations for tables, columns and rows. A class represents a table, its instances are rows, and instance properties are column values. An ORM translates rows in a database to and from objects in an application. Conduit Database Example #1 Example #2 Class Table Person Bank Account Instance Row A person named Bob Sally's Bank Account Property Column Person's Name Bank Account Balance In Conduit, each database table-class pairing is called an entity . Collectively, an application's entities are called its data model . Building a Data Model In our heroes application, we will have one type of entity - a \"hero\". To create a new entity, we subclass ManagedObject<T> . Create a new directory lib/model/ and then add a new file to this directory named hero.dart . Add the following code: import 'package:heroes/heroes.dart'; class Hero extends ManagedObject<_Hero> implements _Hero {} class _Hero { @primaryKey int id; @Column(unique: true) String name; } This declares a Hero entity. Entities are always made up of two classes. The _Hero class is a direct mapping of a database table. This table's name will have the same name as the class: _Hero . Every property declared in this class will have a corresponding column in this table. Therefore, the _Hero table will have two columns - id and name . The id column is this table's primary key (a unique identifier for each hero). The name of each hero must be unique. The other class, Hero , is what we work with in our code - when we fetch heroes from a database, they will be instances of Hero . The Hero class is called the instance type of the entity, because that's what we have instances of. _Hero is the table definition of the entity. You won't use the table definition for anything other than describing the database table. An instance type must implement its table definition; this gives our Hero all of the properties of _Hero . An instance type must extend ManagedObject<T> , where T is also the table definition. ManagedObject<T> has behavior for automatically transferring objects to the database and back (among other things). !!! tip \"Transient Properties\" Properties declared in the instance type aren't stored in the database. This is different than properties in the table definition. For example, a database table might have a firstName and lastName , but it's useful in some places to have a fullName property. Declaring the fullName property in the instance type means we have easy access to the full name, but we still store the first and last name individually. Defining a Context Our application needs to know two things to execute database queries: What is the data model (our collection of entities)? What database are we connecting to? Both of these things are set up when an application is first started. In channel.dart , add a new property context and update prepare() : class HeroesChannel extends ApplicationChannel { ManagedContext context; @override Future prepare() async { logger.onRecord.listen((rec) => print(\"$rec ${rec.error ?? \"\"} ${rec.stackTrace ?? \"\"}\")); final dataModel = ManagedDataModel.fromCurrentMirrorSystem(); final persistentStore = PostgreSQLPersistentStore.fromConnectionInfo( \"heroes_user\", \"password\", \"localhost\", 5432, \"heroes\"); context = ManagedContext(dataModel, persistentStore); } @override Controller get entryPoint { ... ManagedDataModel.fromCurrentMirrorSystem() will find all of our ManagedObject<T> subclasses and 'compile' them into a data model. A PostgreSQLPersistentStore takes database connection information that it will use to connect and send queries to a database. Together, these objects are packaged in a ManagedContext . !!! tip \"Configuring a Database Connection\" This tutorial hardcodes the information needed to connect to a database. In a future chapter, we will move these values to a configuration file so that we can change them during tests and various deployment environments. The context will coordinate with these two objects to execute queries and translate objects to and from the database. Controllers that make database queries need a reference to the context. So, we'll want HeroesController to have access to the context. In heroes_controller.dart , add a property and create a new constructor: class HeroesController extends ResourceController { HeroesController(this.context); final ManagedContext context; ... Now that HeroesController requires a context in its constructor, we need to pass it the context we created in prepare() . Update entryPoint in channel.dart . @override Controller get entryPoint { final router = Router(); router .route(\"/heroes/[:id]\") .link(() => HeroesController(context)); router .route(\"/example\") .linkFunction((request) async { return new Response.ok({\"key\": \"value\"}); }); return router; } Now that we've 'injected' this context into our HeroesController constructor, each HeroesController can execute database queries. !!! note \"Service Objects and Dependency Injection\" Our context is an example of a service object . A service encapsulates logic and state into a single object that can be reused in multiple controllers. A typical service object accesses another server, like a database or another REST API. Some service objects may simply provide a simplified interface to a complex process, like applying transforms to an image. Services are passed in a controller's constructor; this is called dependency injection . Unlike many frameworks, Conduit does not require a complex dependency injection framework; this is because you write the code to create instances of your controllers and can pass whatever you like in their constructor. Executing Queries Our operation methods in HeroesController currently return heroes from an in-memory list. To fetch data from a database instead of this list, we create and execute instances of Query<T> in our ManagedContext . Let's start by replacing getAllHeroes in heroes_controller.dart . Make sure to import your model/hero.dart file at the top: import 'package:heroes/heroes.dart'; import 'package:heroes/model/hero.dart'; class HeroesController extends ResourceController { HeroesController(this.context); final ManagedContext context; @Operation.get() Future<Response> getAllHeroes() async { final heroQuery = Query<Hero>(context); final heroes = await heroQuery.fetch(); return Response.ok(heroes); } ... Here, we create an instance of Query<Hero> and then execute its fetch() method. The type argument to Query<T> is an instance type; it lets the query know which table to fetch rows from and the type of objects that are returned by the query. The context argument tells it which database to fetch it from. The fetch() execution method returns a List<Hero> . We write that list to the body of the response. Now, let's update getHeroByID to fetch a single hero from the database. @Operation.get('id') Future<Response> getHeroByID(@Bind.path('id') int id) async { final heroQuery = Query<Hero>(context) ..where((h) => h.id).equalTo(id); final hero = await heroQuery.fetchOne(); if (hero == null) { return Response.notFound(); } return Response.ok(hero); } This query does two interesting things. First, it uses the where method to filter heroes that have the same id as the path variable. For example, /heroes/1 will fetch a hero with an id of 1 . This works because Query.where adds a SQL WHERE clause to the query. We'd get the following SQL: SELECT id, name FROM _question WHERE id = 1; The where method uses the property selector syntax. This syntax is a closure that takes an argument of the type being queried, and must return a property of that object. This creates an expression object that targets the selected property. By invoking methods like equalTo on this expression object, a boolean expression is added to the query. !!! tip \"Property Selectors\" Many query configuration methods use the property selector syntax. Setting up a keyboard shortcut (called a Live Template in IntelliJ) to enter the syntax is beneficial. A downloadable settings configuration for IntelliJ exists here that includes this shortcut. The fetchOne() execution method will fetch a single object that fulfills all of the expressions applied to the query. If no database row meets the criteria, null is returned. Our controller returns a 404 Not Found response in that scenario. We have now written code that fetches heroes from a database instead of from in memory, but we don't have a database - yet. !!! tip \"fetchObjectWithID, fetchOne() and Unique Properties\" You can also fetch an object by its primary key with the method ManagedContext.fetchObjectWithID . When fetching with fetchOne , make sure the search criteria is guaranteed to be unique. Setting Up a Database For development, you'll need to install a PostgreSQL server on your local machine. If you are on macOS, use Postgres.app . This native macOS application manages starting and stopping PostgreSQL servers on your machine. For other platforms, see this page . !!! warning \"9.6 or Greater\" The minimum version of PostgreSQL needed to work with Conduit is 9.6. If you installed Postgres.app, open the application and select the + button on the bottom left corner of the screen to create a new database server. Choose a version (at least 9.6, but the most recent version is best), name the server whatever you like, and leave the rest of the options unchanged before clicking Create Server . Once the server has been created, click Start . A list of databases available on this server will be shown as named, database icons. Double-click on any of them to open the psql command-line tool. !!! tip \"psql\" For other platforms, psql should be available in your $PATH . You can also add Postgres.app 's psql to your path with the directions here . In psql , create a new database and a user to manage it. CREATE DATABASE heroes; CREATE USER heroes_user WITH createdb; ALTER USER heroes_user WITH password 'password'; GRANT all ON database heroes TO heroes_user; Next, we need to create the table where heroes are stored in this database. From your project directory, run the following command: conduit db generate This command will create a new migration file . A migration file is a Dart script that runs a series of SQL commands to alter a database's schema. It is created in a new directory in your project named migrations/ . Open migrations/00000001_initial.migration.dart , it should look like this: import 'package:conduit/conduit.dart'; import 'dart:async'; class Migration1 extends Migration { @override Future upgrade() async { database.createTable(SchemaTable( \"_Hero\", [ SchemaColumn(\"id\", ManagedPropertyType.bigInteger, isPrimaryKey: true, autoincrement: true, isIndexed: false, isNullable: false, isUnique: false), SchemaColumn(\"name\", ManagedPropertyType.string, isPrimaryKey: false, autoincrement: false, isIndexed: false, isNullable: false, isUnique: true), ], )); } @override Future downgrade() async {} @override Future seed() async {} } In a moment, we'll execute this migration file. That will create a new table named _Hero with columns for id and name . Before we run it, we should seed the database with some initial heroes. In the seed() method, add the following: @override Future seed() async { final heroNames = [\"Mr. Nice\", \"Narco\", \"Bombasto\", \"Celeritas\", \"Magneta\"]; for (final heroName in heroNames) { await database.store.execute(\"INSERT INTO _Hero (name) VALUES (@name)\", substitutionValues: { \"name\": heroName }); } } Apply this migration file to our locally running heroes database with the following command in the project directory: conduit db upgrade --connect postgres://heroes_user:password@localhost:5432/heroes Re-run your application with conduit serve . Then, reload http://conduit-tutorial.conduit.dart.io . Your dashboard of heroes and detail page for each will still show up - but this time, they are sourced from a database. !!! warning \"ManagedObjects and Migration Scripts\" In our migration's seed() method, we executed SQL queries instead of using the Conduit ORM. It is very important that you do not use Query<T> , ManagedObject<T> or other elements of the Conduit ORM in migration files. Migration files represent an ordered series of historical steps that describe your database schema. If you replay those steps (which is what executing a migration file does), you will end up with the same database schema every time. However, a ManagedObject<T> subclass changes over time - the definition of a managed object is not historical, it only represents the current point in time. Since a ManagedObject<T> subclass can change, using one in our migration file would mean that our migration file could change. Query Parameters and HTTP Headers In the browser application, the dashboard has a text field for searching heroes. When you enter text into it, it will send the search term to the server by appending a query parameter to GET /heroes . For example, if you entered the text abc , it'd make this request: GET /heroes?name=abc Our Conduit application can use this value to return a list of heroes that contains the search string. In heroes_controller.dart , modify getAllHeroes() to bind the 'name' query parameter: @Operation.get() Future<Response> getAllHeroes({@Bind.query('name') String name}) async { final heroQuery = Query<Hero>(context); if (name != null) { heroQuery.where((h) => h.name).contains(name, caseSensitive: false); } final heroes = await heroQuery.fetch(); return Response.ok(heroes); } You can re-run your Conduit application and use the search bar in the client application. The @Bind.query('name') annotation will bind the value of the 'name' query parameter if it is included in the request URL. Otherwise, name will be null. Notice that name is an optional parameter (it is surrounded by curly brackets). An optional parameter in an operation method is also optional in the HTTP request. If we removed the curly brackets from this binding, the 'name' query parameter would become required and the request GET /heroes without ?name=x would fail with a 400 Bad Request. !!! tip \"ResourceController Binding\" There is even more to bindings than we've shown (like automatically parsing bound values into types like int and DateTime ). For more information, see ResourceControllers . Binding query and header parameters in a operation method is a good way to make your code more intentional and avoid boilerplate parsing code. Conduit is able to generate better documentation when using bindings.","title":"2. Reading from a Database"},{"location":"tut/executing-queries/#reading-from-a-database","text":"We will continue to build on the last chapter's project, heroes , by storing our heroes in a database. This will let us to edit our heroes and keep the changes when we restart the application.","title":"Reading from a Database"},{"location":"tut/executing-queries/#object-relational-mapping","text":"A relational database management system (like PostgreSQL or MySQL) stores its data in the form of tables. A table represents some sort of entity - like a person or a bank account. Each table has columns that describe the attributes of that entity - like a name or a balance. Every row in a table is an instance of that entity - like a single person named Bob or a bank account. In an object-oriented framework like Conduit, we have representations for tables, columns and rows. A class represents a table, its instances are rows, and instance properties are column values. An ORM translates rows in a database to and from objects in an application. Conduit Database Example #1 Example #2 Class Table Person Bank Account Instance Row A person named Bob Sally's Bank Account Property Column Person's Name Bank Account Balance In Conduit, each database table-class pairing is called an entity . Collectively, an application's entities are called its data model .","title":"Object-Relational Mapping"},{"location":"tut/executing-queries/#building-a-data-model","text":"In our heroes application, we will have one type of entity - a \"hero\". To create a new entity, we subclass ManagedObject<T> . Create a new directory lib/model/ and then add a new file to this directory named hero.dart . Add the following code: import 'package:heroes/heroes.dart'; class Hero extends ManagedObject<_Hero> implements _Hero {} class _Hero { @primaryKey int id; @Column(unique: true) String name; } This declares a Hero entity. Entities are always made up of two classes. The _Hero class is a direct mapping of a database table. This table's name will have the same name as the class: _Hero . Every property declared in this class will have a corresponding column in this table. Therefore, the _Hero table will have two columns - id and name . The id column is this table's primary key (a unique identifier for each hero). The name of each hero must be unique. The other class, Hero , is what we work with in our code - when we fetch heroes from a database, they will be instances of Hero . The Hero class is called the instance type of the entity, because that's what we have instances of. _Hero is the table definition of the entity. You won't use the table definition for anything other than describing the database table. An instance type must implement its table definition; this gives our Hero all of the properties of _Hero . An instance type must extend ManagedObject<T> , where T is also the table definition. ManagedObject<T> has behavior for automatically transferring objects to the database and back (among other things). !!! tip \"Transient Properties\" Properties declared in the instance type aren't stored in the database. This is different than properties in the table definition. For example, a database table might have a firstName and lastName , but it's useful in some places to have a fullName property. Declaring the fullName property in the instance type means we have easy access to the full name, but we still store the first and last name individually.","title":"Building a Data Model"},{"location":"tut/executing-queries/#defining-a-context","text":"Our application needs to know two things to execute database queries: What is the data model (our collection of entities)? What database are we connecting to? Both of these things are set up when an application is first started. In channel.dart , add a new property context and update prepare() : class HeroesChannel extends ApplicationChannel { ManagedContext context; @override Future prepare() async { logger.onRecord.listen((rec) => print(\"$rec ${rec.error ?? \"\"} ${rec.stackTrace ?? \"\"}\")); final dataModel = ManagedDataModel.fromCurrentMirrorSystem(); final persistentStore = PostgreSQLPersistentStore.fromConnectionInfo( \"heroes_user\", \"password\", \"localhost\", 5432, \"heroes\"); context = ManagedContext(dataModel, persistentStore); } @override Controller get entryPoint { ... ManagedDataModel.fromCurrentMirrorSystem() will find all of our ManagedObject<T> subclasses and 'compile' them into a data model. A PostgreSQLPersistentStore takes database connection information that it will use to connect and send queries to a database. Together, these objects are packaged in a ManagedContext . !!! tip \"Configuring a Database Connection\" This tutorial hardcodes the information needed to connect to a database. In a future chapter, we will move these values to a configuration file so that we can change them during tests and various deployment environments. The context will coordinate with these two objects to execute queries and translate objects to and from the database. Controllers that make database queries need a reference to the context. So, we'll want HeroesController to have access to the context. In heroes_controller.dart , add a property and create a new constructor: class HeroesController extends ResourceController { HeroesController(this.context); final ManagedContext context; ... Now that HeroesController requires a context in its constructor, we need to pass it the context we created in prepare() . Update entryPoint in channel.dart . @override Controller get entryPoint { final router = Router(); router .route(\"/heroes/[:id]\") .link(() => HeroesController(context)); router .route(\"/example\") .linkFunction((request) async { return new Response.ok({\"key\": \"value\"}); }); return router; } Now that we've 'injected' this context into our HeroesController constructor, each HeroesController can execute database queries. !!! note \"Service Objects and Dependency Injection\" Our context is an example of a service object . A service encapsulates logic and state into a single object that can be reused in multiple controllers. A typical service object accesses another server, like a database or another REST API. Some service objects may simply provide a simplified interface to a complex process, like applying transforms to an image. Services are passed in a controller's constructor; this is called dependency injection . Unlike many frameworks, Conduit does not require a complex dependency injection framework; this is because you write the code to create instances of your controllers and can pass whatever you like in their constructor.","title":"Defining a Context"},{"location":"tut/executing-queries/#executing-queries","text":"Our operation methods in HeroesController currently return heroes from an in-memory list. To fetch data from a database instead of this list, we create and execute instances of Query<T> in our ManagedContext . Let's start by replacing getAllHeroes in heroes_controller.dart . Make sure to import your model/hero.dart file at the top: import 'package:heroes/heroes.dart'; import 'package:heroes/model/hero.dart'; class HeroesController extends ResourceController { HeroesController(this.context); final ManagedContext context; @Operation.get() Future<Response> getAllHeroes() async { final heroQuery = Query<Hero>(context); final heroes = await heroQuery.fetch(); return Response.ok(heroes); } ... Here, we create an instance of Query<Hero> and then execute its fetch() method. The type argument to Query<T> is an instance type; it lets the query know which table to fetch rows from and the type of objects that are returned by the query. The context argument tells it which database to fetch it from. The fetch() execution method returns a List<Hero> . We write that list to the body of the response. Now, let's update getHeroByID to fetch a single hero from the database. @Operation.get('id') Future<Response> getHeroByID(@Bind.path('id') int id) async { final heroQuery = Query<Hero>(context) ..where((h) => h.id).equalTo(id); final hero = await heroQuery.fetchOne(); if (hero == null) { return Response.notFound(); } return Response.ok(hero); } This query does two interesting things. First, it uses the where method to filter heroes that have the same id as the path variable. For example, /heroes/1 will fetch a hero with an id of 1 . This works because Query.where adds a SQL WHERE clause to the query. We'd get the following SQL: SELECT id, name FROM _question WHERE id = 1; The where method uses the property selector syntax. This syntax is a closure that takes an argument of the type being queried, and must return a property of that object. This creates an expression object that targets the selected property. By invoking methods like equalTo on this expression object, a boolean expression is added to the query. !!! tip \"Property Selectors\" Many query configuration methods use the property selector syntax. Setting up a keyboard shortcut (called a Live Template in IntelliJ) to enter the syntax is beneficial. A downloadable settings configuration for IntelliJ exists here that includes this shortcut. The fetchOne() execution method will fetch a single object that fulfills all of the expressions applied to the query. If no database row meets the criteria, null is returned. Our controller returns a 404 Not Found response in that scenario. We have now written code that fetches heroes from a database instead of from in memory, but we don't have a database - yet. !!! tip \"fetchObjectWithID, fetchOne() and Unique Properties\" You can also fetch an object by its primary key with the method ManagedContext.fetchObjectWithID . When fetching with fetchOne , make sure the search criteria is guaranteed to be unique.","title":"Executing Queries"},{"location":"tut/executing-queries/#setting-up-a-database","text":"For development, you'll need to install a PostgreSQL server on your local machine. If you are on macOS, use Postgres.app . This native macOS application manages starting and stopping PostgreSQL servers on your machine. For other platforms, see this page . !!! warning \"9.6 or Greater\" The minimum version of PostgreSQL needed to work with Conduit is 9.6. If you installed Postgres.app, open the application and select the + button on the bottom left corner of the screen to create a new database server. Choose a version (at least 9.6, but the most recent version is best), name the server whatever you like, and leave the rest of the options unchanged before clicking Create Server . Once the server has been created, click Start . A list of databases available on this server will be shown as named, database icons. Double-click on any of them to open the psql command-line tool. !!! tip \"psql\" For other platforms, psql should be available in your $PATH . You can also add Postgres.app 's psql to your path with the directions here . In psql , create a new database and a user to manage it. CREATE DATABASE heroes; CREATE USER heroes_user WITH createdb; ALTER USER heroes_user WITH password 'password'; GRANT all ON database heroes TO heroes_user; Next, we need to create the table where heroes are stored in this database. From your project directory, run the following command: conduit db generate This command will create a new migration file . A migration file is a Dart script that runs a series of SQL commands to alter a database's schema. It is created in a new directory in your project named migrations/ . Open migrations/00000001_initial.migration.dart , it should look like this: import 'package:conduit/conduit.dart'; import 'dart:async'; class Migration1 extends Migration { @override Future upgrade() async { database.createTable(SchemaTable( \"_Hero\", [ SchemaColumn(\"id\", ManagedPropertyType.bigInteger, isPrimaryKey: true, autoincrement: true, isIndexed: false, isNullable: false, isUnique: false), SchemaColumn(\"name\", ManagedPropertyType.string, isPrimaryKey: false, autoincrement: false, isIndexed: false, isNullable: false, isUnique: true), ], )); } @override Future downgrade() async {} @override Future seed() async {} } In a moment, we'll execute this migration file. That will create a new table named _Hero with columns for id and name . Before we run it, we should seed the database with some initial heroes. In the seed() method, add the following: @override Future seed() async { final heroNames = [\"Mr. Nice\", \"Narco\", \"Bombasto\", \"Celeritas\", \"Magneta\"]; for (final heroName in heroNames) { await database.store.execute(\"INSERT INTO _Hero (name) VALUES (@name)\", substitutionValues: { \"name\": heroName }); } } Apply this migration file to our locally running heroes database with the following command in the project directory: conduit db upgrade --connect postgres://heroes_user:password@localhost:5432/heroes Re-run your application with conduit serve . Then, reload http://conduit-tutorial.conduit.dart.io . Your dashboard of heroes and detail page for each will still show up - but this time, they are sourced from a database. !!! warning \"ManagedObjects and Migration Scripts\" In our migration's seed() method, we executed SQL queries instead of using the Conduit ORM. It is very important that you do not use Query<T> , ManagedObject<T> or other elements of the Conduit ORM in migration files. Migration files represent an ordered series of historical steps that describe your database schema. If you replay those steps (which is what executing a migration file does), you will end up with the same database schema every time. However, a ManagedObject<T> subclass changes over time - the definition of a managed object is not historical, it only represents the current point in time. Since a ManagedObject<T> subclass can change, using one in our migration file would mean that our migration file could change.","title":"Setting Up a Database"},{"location":"tut/executing-queries/#query-parameters-and-http-headers","text":"In the browser application, the dashboard has a text field for searching heroes. When you enter text into it, it will send the search term to the server by appending a query parameter to GET /heroes . For example, if you entered the text abc , it'd make this request: GET /heroes?name=abc Our Conduit application can use this value to return a list of heroes that contains the search string. In heroes_controller.dart , modify getAllHeroes() to bind the 'name' query parameter: @Operation.get() Future<Response> getAllHeroes({@Bind.query('name') String name}) async { final heroQuery = Query<Hero>(context); if (name != null) { heroQuery.where((h) => h.name).contains(name, caseSensitive: false); } final heroes = await heroQuery.fetch(); return Response.ok(heroes); } You can re-run your Conduit application and use the search bar in the client application. The @Bind.query('name') annotation will bind the value of the 'name' query parameter if it is included in the request URL. Otherwise, name will be null. Notice that name is an optional parameter (it is surrounded by curly brackets). An optional parameter in an operation method is also optional in the HTTP request. If we removed the curly brackets from this binding, the 'name' query parameter would become required and the request GET /heroes without ?name=x would fail with a 400 Bad Request. !!! tip \"ResourceController Binding\" There is even more to bindings than we've shown (like automatically parsing bound values into types like int and DateTime ). For more information, see ResourceControllers . Binding query and header parameters in a operation method is a good way to make your code more intentional and avoid boilerplate parsing code. Conduit is able to generate better documentation when using bindings.","title":"Query Parameters and HTTP Headers"},{"location":"tut/getting-started/","text":"Getting Started By the end of this tutorial, you will have created a Conduit application that serves fictional heroes from a PostgreSQL database. You will learn the following: Run a Conduit application Route HTTP requests to the appropriate handler in your code Store and retrieve database data Write automated tests for each endpoint Require authorization for HTTP requests Installation Make sure that your system has the latest stable version of dart installed. Find the version suited for your operating system here: https://dart.dev/get-dart Install the conduit command line tool by running the following command in your shell: pub global activate conduit Creating a Project Create a new project named heroes by entering the following in your shell: conduit create heroes This creates a heroes project directory with a default server implementation populating it. Handling HTTP Requests In your browser, navigate to http://conduit-tutorial.conduit.dart.io . This browser application is a 'Hero Manager' - it allows a user to view, create, delete and update heroes. (It is a slightly modified version of the AngularDart Tour of Heroes Tutorial .) It will make HTTP requests to http://localhost:8888 to fetch and manipulate hero data. The application you will build in this tutorial respond to those requests. !!! warning \"Running the Browser Application Locally\" The browser application is served over HTTP so that it can access your Conduit application when it runs locally on your machine. Your browser may warn you about navigating to an insecure webpage, because it is in fact insecure. You can run this application locally by grabbing the source code from here . In this first chapter, you will write code to handle two requests: one to get a list of heroes, and the other to get a single hero by its identifier. Those requests are: GET /heroes to the list of heroes GET /heroes/:id to get an individual hero !!! tip \"HTTP Operation Shorthand\" The term GET /heroes is called an operation. It is the combination of the HTTP method and the path of the request. Each operation is unique to an application, so your code is segmented into units for each operation. Sections with a colon, like the ':id' segment, are variable: they can be 1, 2, 3, and so on. Controller Objects Handle Requests Requests are handled by controller objects . A controller object can respond to a request. It can also take other action and let another controller respond. For example, it might check if the request is authorized, or send analytical data to some other service. Controllers are composed together, and each controller in the composition performs its logic in order. This allows for some controllers to be reused, and for better code organization. A composition of controllers is called a channel because requests flow in one direction through the controllers. Our application will link two controllers: a Router that makes sure the request path is /heroes or /heroes/:id a HeroesControllers that responds with hero objects Your application starts with a channel object called the application channel . You link the controllers in your application to this channel. Each application has a subclass of ApplicationChannel that you override methods in to set up your controllers. This type is already declared in lib/channel.dart - open this file and find ApplicationChannel.entryPoint : @override Controller get entryPoint { final router = Router(); router .route('/example') .linkFunction((request) async { return Response.ok({'key': 'value'}); }); return router; } When your application gets a request, the entryPoint controller is the first to handle it. In our case, this is a Router - a subclass of Controller . !!! tip \"Controller Subclassing\" Every controller you use will be a subclass of Controller . There are some controller subclasses already in Conduit for common behaviors. You use the route method on a router to attach a controller to a route . A route is a string syntax that matches the path of a request. In our current implementation, the route will match every request with the path /example . When that request is received, a linked function runs and returns a 200 OK response with an example JSON object body. We need to route the path /heroes to a controller of our own, so we can control what happens. Let's create a HeroesController . Create a new file in lib/controller/heroes_controller.dart and add the following code (you will need to create the subdirectory lib/controller/ ): import 'package:conduit/conduit.dart'; import 'package:heroes/heroes.dart'; class HeroesController extends Controller { final _heroes = [ {'id': 11, 'name': 'Mr. Nice'}, {'id': 12, 'name': 'Narco'}, {'id': 13, 'name': 'Bombasto'}, {'id': 14, 'name': 'Celeritas'}, {'id': 15, 'name': 'Magneta'}, ]; @override Future<RequestOrResponse> handle(Request request) async { return Response.ok(_heroes); } } Notice that HeroesController is a subclass of Controller ; this is what makes it a controller object. It overrides its handle method by returning a Response object. This response object has a 200 OK status code, and it body contains a JSON-encoded list of hero objects. When a controller returns a Response object from its handle method, it is sent to the client. Right now, our HeroesController isn't hooked up to the application channel. We need to link it to the router. First, import our new file at the top of channel.dart . import 'controller/heroes_controller.dart'; Then link this HeroesController to the Router for the path /heroes : @override Controller get entryPoint { final router = Router(); router .route('/heroes') .link(() => HeroesController()); router .route('/example') .linkFunction((request) async { return Response.ok({'key': 'value'}); }); return router; } We now have a application that will return a list of heroes. In the project directory, run the following command from the command-line: conduit serve This will start your application running locally. Reload the browser page http://conduit-tutorial.conduit.dart.io . It will make a request to http://localhost:8888/heroes and your application will serve it. You'll see your heroes in your web browser: Screenshot of Heroes Application You can also see the actual response of your request by entering the following into your shell: curl -X GET http://localhost:8888/heroes You'll get JSON output like this: [ {\"id\":11,\"name\":\"Mr. Nice\"}, {\"id\":12,\"name\":\"Narco\"}, {\"id\":13,\"name\":\"Bombasto\"}, {\"id\":14,\"name\":\"Celeritas\"}, {\"id\":15,\"name\":\"Magneta\"} ] You'll also see this request logged in the shell that you started conduit serve in. Linking Controllers When a controller handles a request, it can either send a response or let one of its linked controllers handle the request. By default, a Router will send a 404 Not Found response for any request. Adding a route to a Router creates an entry point to a new channel that controllers can be linked to. In our application, HeroesController is linked to the route /heroes . Controllers come in two different flavors: endpoint and middleware. Endpoint controllers, like HeroesController , always send a response. They implement the behavior that a request is seeking. Middleware controllers, like Router , handles requests before they reach an endpoint controller. A router, for example, handles a request by directing it to the right controller. Controllers like Authorizer verify the authorization of the request. You can create all kinds of controllers to provide any behavior you like. A channel can have zero or many middleware controllers, but must end in an endpoint controller. Most controllers can only have one linked controller, but a Router allows for many. For example, a larger application might look like this: @override Controller get entryPoint { final router = Router(); router .route('/users') .link(() => APIKeyValidator()) .link(() => Authorizer.bearer()) .link(() => UsersController()); router .route('/posts') .link(() => APIKeyValidator()) .link(() => PostsController()); return router; } Each of these objects is a subclass of Controller , giving them the ability to be linked together to handle requests. A request goes through controllers in the order they are linked. A request for the path /users will go through an APIKeyValidator , an Authorizer and finally a UsersController . Each of these controllers has an opportunity to respond, preventing the next controller from receiving the request. Advanced Routing Right now, our application handles GET /heroes requests. The browser application uses the this list to populate its hero dashboard. If we click on an individual hero, the browser application will display an individual hero. When navigating to this page, the browser application makes a request to our server for an individual hero. This request contains the unique id of the selected hero in the path, e.g. /heroes/11 or /heroes/13 . Our server doesn't handle this request yet - it only handles requests that have exactly the path /heroes . Since a request for individual heroes will have a path that changes depending on the hero, we need our route to include a path variable . A path variable is a segment of route that matches a value for the same segment in the incoming request path. A path variable is a segment prefixed with a colon ( : ). For example, the route /heroes/:id contains a path variable named id . If the request path is /heroes/1 , /heroes/2 , and so on, the request will be sent to our HeroesController . The HeroesController will have access to the value of the path variable to determine which hero to return. There's one hiccup. The route /heroes/:id no longer matches the path /heroes . It'd be a lot easier to organize our code if both /heroes and /heroes/:id went to our HeroesController ; it does heroic stuff. For this reason, we can declare the :id portion of our route to be optional by wrapping it in square brackets. In channel.dart , modify the /heroes route: router .route('/heroes/[:id]') .link(() => HeroesController()); Since the second segment of the path is optional, the path /heroes still matches the route. If the path contains a second segment, the value of that segment is bound to the path variable named id . We can access path variables through the Request object. In heroes_controller.dart , modify handle : // In just a moment, we'll replace this code with something even better, // but it's important to understand where this information comes from first! @override Future<RequestOrResponse> handle(Request request) async { if (request.path.variables.containsKey('id')) { final id = int.parse(request.path.variables['id']); final hero = _heroes.firstWhere((hero) => hero['id'] == id, orElse: () => null); if (hero == null) { return Response.notFound(); } return Response.ok(hero); } return Response.ok(_heroes); } In your shell currently running the application, hit Ctrl-C to stop the application. Then, run conduit serve again. In the browser application, click on a hero and you will be taken to a detail page for that hero. You can verify that your server is responding correctly by executing curl -X GET http://localhost:8888/heroes/11 to view the single hero object. You can also trigger a 404 Not Found response by getting a hero that doesn't exist. ResourceControllers and Operation Methods Our HeroesController is OK right now, but it'll soon run into a problem: what happens when we want to create a new hero? Or update an existing hero's name? Our handle method will start to get unmanageable, quickly. That's where ResourceController comes in. A ResourceController allows you to create a distinct method for each operation that we can perform on our heroes. One method will handle getting a list of heroes, another will handle getting a single hero, and so on. Each method has an annotation that identifies the HTTP method and path variables the request must have to trigger it. In heroes_controller.dart , replace HeroesController with the following: class HeroesController extends ResourceController { final _heroes = [ {'id': 11, 'name': 'Mr. Nice'}, {'id': 12, 'name': 'Narco'}, {'id': 13, 'name': 'Bombasto'}, {'id': 14, 'name': 'Celeritas'}, {'id': 15, 'name': 'Magneta'}, ]; @Operation.get() Future<Response> getAllHeroes() async { return Response.ok(_heroes); } @Operation.get('id') Future<Response> getHeroByID() async { final id = int.parse(request.path.variables['id']); final hero = _heroes.firstWhere((hero) => hero['id'] == id, orElse: () => null); if (hero == null) { return Response.notFound(); } return Response.ok(hero); } } Notice that we didn't have to override handle in ResourceController . A ResourceController implements this method to call one of our operation methods . An operation method - like getAllHeroes and getHeroByID - must have an Operation annotation. The named constructor Operation.get means these methods get called when the request's method is GET. An operation method must also return a Future<Response> . getHeroByID 's annotation also has an argument - the name of our path variable id . If that path variable exists in the request's path, getHeroByID will be called. If it doesn't exist, getAllHeroes will be called. !!! tip \"Naming Operation Methods\" The plain English phrase for an operation - like 'get hero by id' - is a really good name for an operation method and a good name will be useful when you generate OpenAPI documentation from your code. Reload the application by hitting Ctrl-C in the terminal that ran conduit serve and then run conduit serve again. The browser application should still behave the same. !!! tip \"Browser Clients\" In addition to curl , you can create a SwaggerUI browser application that executes requests against your locally running application. In your project directory, run conduit document client and it will generate a file named client.html . Open this file in your browser for a UI that constructs and executes requests that your application supports. Request Binding In our getHeroByID method, we make a dangerous assumption that the path variable 'id' can be parsed into an integer. If 'id' were something else, like a string, int.parse would throw an exception. When exceptions are thrown in operation methods, the controller catches it and sends a 500 Server Error response. 500s are bad, they don't tell the client what's wrong. A 404 Not Found is a better response here, but writing the code to catch that exception and create this response is cumbersome. Instead, we can rely on a feature of operation methods called request binding . An operation method can declare parameters and bind them to properties of the request. When our operation method gets called, it will be passed values from the request as arguments. Request bindings automatically parse values into the type of the parameter (and return a better error response if parsing fails). Change the method getHeroByID() : @Operation.get('id') Future<Response> getHeroByID(@Bind.path('id') int id) async { final hero = _heroes.firstWhere((hero) => hero['id'] == id, orElse: () => null); if (hero == null) { return Response.notFound(); } return Response.ok(hero); } The value of the path variable id will be parsed as an integer and be available to this method in the id parameter. The @Bind annotation on an operation method parameter tells Conduit the value from the request we want bound. Using the named constructor Bind.path binds a path variable, and the name of that variable is indicated in the argument to this constructor. You can bind path variables, headers, query parameters and bodies. When binding path variables, we have to specify which path variable with the argument to @Bind.path(pathVariableName) . !!! tip \"Bound Parameter Names\" The name of a bound parameter doesn't have to match the name of the path variable. We could have declared it as @Bind.path('id') int heroID . Only the argument to Bind 's constructor must match the actual name of the path variable. This is valuable for other types of bindings, like headers, that may contain characters that aren't valid Dart variable names, e.g. X-API-Key . The More You Know: Multi-threading and Application State In this simple exercise, we used a constant list of heroes as our source of data. For a simple getting-your-feet-wet demo, this is fine. However, in a real application, you'd store this data in a database. That way you could add data to it and not risk losing it when the application was restarted. More generally, a web server should never hang on to data that can change. While previously just a best practice, stateless web servers are becoming a requirement with the prevalence of containerization and tools like Kubernetes. Conduit makes it a bit easier to detect violations of this rule with its multi-threading strategy. When you run a Conduit application, it creates multiple threads. Each of these threads has its own isolated heap in memory; meaning data that exists on one thread can't be accessed from other threads. In Dart, these isolated threads are called isolates . An instance of your application channel is created for each isolate. Each HTTP request is given to just one of the isolates to be handled. In a sense, your one application behaves the same as running your application on multiple servers behind a load balancer. (It also makes your application substantially faster.) If you are storing any data in your application, you'll find out really quickly. Why? A request that changes data will only change that data in one of your application's isolates. When you make a request to get that data again, its unlikely that you'll see the changes - another isolate with different data will probably handle that request.","title":"1. Getting Started"},{"location":"tut/getting-started/#getting-started","text":"By the end of this tutorial, you will have created a Conduit application that serves fictional heroes from a PostgreSQL database. You will learn the following: Run a Conduit application Route HTTP requests to the appropriate handler in your code Store and retrieve database data Write automated tests for each endpoint Require authorization for HTTP requests","title":"Getting Started"},{"location":"tut/getting-started/#installation","text":"Make sure that your system has the latest stable version of dart installed. Find the version suited for your operating system here: https://dart.dev/get-dart Install the conduit command line tool by running the following command in your shell: pub global activate conduit","title":"Installation"},{"location":"tut/getting-started/#creating-a-project","text":"Create a new project named heroes by entering the following in your shell: conduit create heroes This creates a heroes project directory with a default server implementation populating it.","title":"Creating a Project"},{"location":"tut/getting-started/#handling-http-requests","text":"In your browser, navigate to http://conduit-tutorial.conduit.dart.io . This browser application is a 'Hero Manager' - it allows a user to view, create, delete and update heroes. (It is a slightly modified version of the AngularDart Tour of Heroes Tutorial .) It will make HTTP requests to http://localhost:8888 to fetch and manipulate hero data. The application you will build in this tutorial respond to those requests. !!! warning \"Running the Browser Application Locally\" The browser application is served over HTTP so that it can access your Conduit application when it runs locally on your machine. Your browser may warn you about navigating to an insecure webpage, because it is in fact insecure. You can run this application locally by grabbing the source code from here . In this first chapter, you will write code to handle two requests: one to get a list of heroes, and the other to get a single hero by its identifier. Those requests are: GET /heroes to the list of heroes GET /heroes/:id to get an individual hero !!! tip \"HTTP Operation Shorthand\" The term GET /heroes is called an operation. It is the combination of the HTTP method and the path of the request. Each operation is unique to an application, so your code is segmented into units for each operation. Sections with a colon, like the ':id' segment, are variable: they can be 1, 2, 3, and so on.","title":"Handling HTTP Requests"},{"location":"tut/getting-started/#controller-objects-handle-requests","text":"Requests are handled by controller objects . A controller object can respond to a request. It can also take other action and let another controller respond. For example, it might check if the request is authorized, or send analytical data to some other service. Controllers are composed together, and each controller in the composition performs its logic in order. This allows for some controllers to be reused, and for better code organization. A composition of controllers is called a channel because requests flow in one direction through the controllers. Our application will link two controllers: a Router that makes sure the request path is /heroes or /heroes/:id a HeroesControllers that responds with hero objects Your application starts with a channel object called the application channel . You link the controllers in your application to this channel. Each application has a subclass of ApplicationChannel that you override methods in to set up your controllers. This type is already declared in lib/channel.dart - open this file and find ApplicationChannel.entryPoint : @override Controller get entryPoint { final router = Router(); router .route('/example') .linkFunction((request) async { return Response.ok({'key': 'value'}); }); return router; } When your application gets a request, the entryPoint controller is the first to handle it. In our case, this is a Router - a subclass of Controller . !!! tip \"Controller Subclassing\" Every controller you use will be a subclass of Controller . There are some controller subclasses already in Conduit for common behaviors. You use the route method on a router to attach a controller to a route . A route is a string syntax that matches the path of a request. In our current implementation, the route will match every request with the path /example . When that request is received, a linked function runs and returns a 200 OK response with an example JSON object body. We need to route the path /heroes to a controller of our own, so we can control what happens. Let's create a HeroesController . Create a new file in lib/controller/heroes_controller.dart and add the following code (you will need to create the subdirectory lib/controller/ ): import 'package:conduit/conduit.dart'; import 'package:heroes/heroes.dart'; class HeroesController extends Controller { final _heroes = [ {'id': 11, 'name': 'Mr. Nice'}, {'id': 12, 'name': 'Narco'}, {'id': 13, 'name': 'Bombasto'}, {'id': 14, 'name': 'Celeritas'}, {'id': 15, 'name': 'Magneta'}, ]; @override Future<RequestOrResponse> handle(Request request) async { return Response.ok(_heroes); } } Notice that HeroesController is a subclass of Controller ; this is what makes it a controller object. It overrides its handle method by returning a Response object. This response object has a 200 OK status code, and it body contains a JSON-encoded list of hero objects. When a controller returns a Response object from its handle method, it is sent to the client. Right now, our HeroesController isn't hooked up to the application channel. We need to link it to the router. First, import our new file at the top of channel.dart . import 'controller/heroes_controller.dart'; Then link this HeroesController to the Router for the path /heroes : @override Controller get entryPoint { final router = Router(); router .route('/heroes') .link(() => HeroesController()); router .route('/example') .linkFunction((request) async { return Response.ok({'key': 'value'}); }); return router; } We now have a application that will return a list of heroes. In the project directory, run the following command from the command-line: conduit serve This will start your application running locally. Reload the browser page http://conduit-tutorial.conduit.dart.io . It will make a request to http://localhost:8888/heroes and your application will serve it. You'll see your heroes in your web browser:","title":"Controller Objects Handle Requests"},{"location":"tut/getting-started/#screenshot-of-heroes-application","text":"You can also see the actual response of your request by entering the following into your shell: curl -X GET http://localhost:8888/heroes You'll get JSON output like this: [ {\"id\":11,\"name\":\"Mr. Nice\"}, {\"id\":12,\"name\":\"Narco\"}, {\"id\":13,\"name\":\"Bombasto\"}, {\"id\":14,\"name\":\"Celeritas\"}, {\"id\":15,\"name\":\"Magneta\"} ] You'll also see this request logged in the shell that you started conduit serve in.","title":"Screenshot of Heroes Application"},{"location":"tut/getting-started/#linking-controllers","text":"When a controller handles a request, it can either send a response or let one of its linked controllers handle the request. By default, a Router will send a 404 Not Found response for any request. Adding a route to a Router creates an entry point to a new channel that controllers can be linked to. In our application, HeroesController is linked to the route /heroes . Controllers come in two different flavors: endpoint and middleware. Endpoint controllers, like HeroesController , always send a response. They implement the behavior that a request is seeking. Middleware controllers, like Router , handles requests before they reach an endpoint controller. A router, for example, handles a request by directing it to the right controller. Controllers like Authorizer verify the authorization of the request. You can create all kinds of controllers to provide any behavior you like. A channel can have zero or many middleware controllers, but must end in an endpoint controller. Most controllers can only have one linked controller, but a Router allows for many. For example, a larger application might look like this: @override Controller get entryPoint { final router = Router(); router .route('/users') .link(() => APIKeyValidator()) .link(() => Authorizer.bearer()) .link(() => UsersController()); router .route('/posts') .link(() => APIKeyValidator()) .link(() => PostsController()); return router; } Each of these objects is a subclass of Controller , giving them the ability to be linked together to handle requests. A request goes through controllers in the order they are linked. A request for the path /users will go through an APIKeyValidator , an Authorizer and finally a UsersController . Each of these controllers has an opportunity to respond, preventing the next controller from receiving the request.","title":"Linking Controllers"},{"location":"tut/getting-started/#advanced-routing","text":"Right now, our application handles GET /heroes requests. The browser application uses the this list to populate its hero dashboard. If we click on an individual hero, the browser application will display an individual hero. When navigating to this page, the browser application makes a request to our server for an individual hero. This request contains the unique id of the selected hero in the path, e.g. /heroes/11 or /heroes/13 . Our server doesn't handle this request yet - it only handles requests that have exactly the path /heroes . Since a request for individual heroes will have a path that changes depending on the hero, we need our route to include a path variable . A path variable is a segment of route that matches a value for the same segment in the incoming request path. A path variable is a segment prefixed with a colon ( : ). For example, the route /heroes/:id contains a path variable named id . If the request path is /heroes/1 , /heroes/2 , and so on, the request will be sent to our HeroesController . The HeroesController will have access to the value of the path variable to determine which hero to return. There's one hiccup. The route /heroes/:id no longer matches the path /heroes . It'd be a lot easier to organize our code if both /heroes and /heroes/:id went to our HeroesController ; it does heroic stuff. For this reason, we can declare the :id portion of our route to be optional by wrapping it in square brackets. In channel.dart , modify the /heroes route: router .route('/heroes/[:id]') .link(() => HeroesController()); Since the second segment of the path is optional, the path /heroes still matches the route. If the path contains a second segment, the value of that segment is bound to the path variable named id . We can access path variables through the Request object. In heroes_controller.dart , modify handle : // In just a moment, we'll replace this code with something even better, // but it's important to understand where this information comes from first! @override Future<RequestOrResponse> handle(Request request) async { if (request.path.variables.containsKey('id')) { final id = int.parse(request.path.variables['id']); final hero = _heroes.firstWhere((hero) => hero['id'] == id, orElse: () => null); if (hero == null) { return Response.notFound(); } return Response.ok(hero); } return Response.ok(_heroes); } In your shell currently running the application, hit Ctrl-C to stop the application. Then, run conduit serve again. In the browser application, click on a hero and you will be taken to a detail page for that hero. You can verify that your server is responding correctly by executing curl -X GET http://localhost:8888/heroes/11 to view the single hero object. You can also trigger a 404 Not Found response by getting a hero that doesn't exist.","title":"Advanced Routing"},{"location":"tut/getting-started/#resourcecontrollers-and-operation-methods","text":"Our HeroesController is OK right now, but it'll soon run into a problem: what happens when we want to create a new hero? Or update an existing hero's name? Our handle method will start to get unmanageable, quickly. That's where ResourceController comes in. A ResourceController allows you to create a distinct method for each operation that we can perform on our heroes. One method will handle getting a list of heroes, another will handle getting a single hero, and so on. Each method has an annotation that identifies the HTTP method and path variables the request must have to trigger it. In heroes_controller.dart , replace HeroesController with the following: class HeroesController extends ResourceController { final _heroes = [ {'id': 11, 'name': 'Mr. Nice'}, {'id': 12, 'name': 'Narco'}, {'id': 13, 'name': 'Bombasto'}, {'id': 14, 'name': 'Celeritas'}, {'id': 15, 'name': 'Magneta'}, ]; @Operation.get() Future<Response> getAllHeroes() async { return Response.ok(_heroes); } @Operation.get('id') Future<Response> getHeroByID() async { final id = int.parse(request.path.variables['id']); final hero = _heroes.firstWhere((hero) => hero['id'] == id, orElse: () => null); if (hero == null) { return Response.notFound(); } return Response.ok(hero); } } Notice that we didn't have to override handle in ResourceController . A ResourceController implements this method to call one of our operation methods . An operation method - like getAllHeroes and getHeroByID - must have an Operation annotation. The named constructor Operation.get means these methods get called when the request's method is GET. An operation method must also return a Future<Response> . getHeroByID 's annotation also has an argument - the name of our path variable id . If that path variable exists in the request's path, getHeroByID will be called. If it doesn't exist, getAllHeroes will be called. !!! tip \"Naming Operation Methods\" The plain English phrase for an operation - like 'get hero by id' - is a really good name for an operation method and a good name will be useful when you generate OpenAPI documentation from your code. Reload the application by hitting Ctrl-C in the terminal that ran conduit serve and then run conduit serve again. The browser application should still behave the same. !!! tip \"Browser Clients\" In addition to curl , you can create a SwaggerUI browser application that executes requests against your locally running application. In your project directory, run conduit document client and it will generate a file named client.html . Open this file in your browser for a UI that constructs and executes requests that your application supports.","title":"ResourceControllers and Operation Methods"},{"location":"tut/getting-started/#request-binding","text":"In our getHeroByID method, we make a dangerous assumption that the path variable 'id' can be parsed into an integer. If 'id' were something else, like a string, int.parse would throw an exception. When exceptions are thrown in operation methods, the controller catches it and sends a 500 Server Error response. 500s are bad, they don't tell the client what's wrong. A 404 Not Found is a better response here, but writing the code to catch that exception and create this response is cumbersome. Instead, we can rely on a feature of operation methods called request binding . An operation method can declare parameters and bind them to properties of the request. When our operation method gets called, it will be passed values from the request as arguments. Request bindings automatically parse values into the type of the parameter (and return a better error response if parsing fails). Change the method getHeroByID() : @Operation.get('id') Future<Response> getHeroByID(@Bind.path('id') int id) async { final hero = _heroes.firstWhere((hero) => hero['id'] == id, orElse: () => null); if (hero == null) { return Response.notFound(); } return Response.ok(hero); } The value of the path variable id will be parsed as an integer and be available to this method in the id parameter. The @Bind annotation on an operation method parameter tells Conduit the value from the request we want bound. Using the named constructor Bind.path binds a path variable, and the name of that variable is indicated in the argument to this constructor. You can bind path variables, headers, query parameters and bodies. When binding path variables, we have to specify which path variable with the argument to @Bind.path(pathVariableName) . !!! tip \"Bound Parameter Names\" The name of a bound parameter doesn't have to match the name of the path variable. We could have declared it as @Bind.path('id') int heroID . Only the argument to Bind 's constructor must match the actual name of the path variable. This is valuable for other types of bindings, like headers, that may contain characters that aren't valid Dart variable names, e.g. X-API-Key .","title":"Request Binding"},{"location":"tut/getting-started/#the-more-you-know-multi-threading-and-application-state","text":"In this simple exercise, we used a constant list of heroes as our source of data. For a simple getting-your-feet-wet demo, this is fine. However, in a real application, you'd store this data in a database. That way you could add data to it and not risk losing it when the application was restarted. More generally, a web server should never hang on to data that can change. While previously just a best practice, stateless web servers are becoming a requirement with the prevalence of containerization and tools like Kubernetes. Conduit makes it a bit easier to detect violations of this rule with its multi-threading strategy. When you run a Conduit application, it creates multiple threads. Each of these threads has its own isolated heap in memory; meaning data that exists on one thread can't be accessed from other threads. In Dart, these isolated threads are called isolates . An instance of your application channel is created for each isolate. Each HTTP request is given to just one of the isolates to be handled. In a sense, your one application behaves the same as running your application on multiple servers behind a load balancer. (It also makes your application substantially faster.) If you are storing any data in your application, you'll find out really quickly. Why? A request that changes data will only change that data in one of your application's isolates. When you make a request to get that data again, its unlikely that you'll see the changes - another isolate with different data will probably handle that request.","title":"The More You Know: Multi-threading and Application State"},{"location":"tut/oauth2/","text":"Authentication and Authorization with OAuth 2.0 Our heroes application lets anyone create or view the same set of heroes. We will continue to build on the last chapter's project, heroes , requiring a user to log in before viewing or creating heroes. !!! note \"We're Done With the Browser App\" We're at the point now where using the browser application to test our Conduit app gets a bit cumbersome. From here on out, we'll use curl , conduit document client and tests. The Basics of OAuth 2.0 OAuth 2.0 is an authorization framework that also contains guidance on authentication. Authentication is the process of proving you are a particular user, typically through a username and password. Authorization is the process of ensuring that a user can access a particular resource or collection of resources. In our application, a user will have to be authenticated before being authorized to view or create heroes. In a simple authentication and authorization scheme, each HTTP request contains the username and password (credentials) of the user in an Authorization header. There are a number of security risks involved in doing this, so OAuth 2.0 takes another approach: you send your credentials once, and get a 'access token' in return. You then send this access token in each request. Because the server grants the token, it knows that you've already entered your credentials (you've authenticated ) and it remembers who the token belongs to. It's effectively the same thing as sending your credentials each time, except that the token has a time limit and can be revoked when things go wrong. Conduit has a built-in OAuth 2.0 implementation that leverages the ORM. This implementation is part of the conduit package, but it is a separate library named conduit/managed_auth . It takes a few steps to set up that might be difficult to understand if you are not familiar with OAuth 2.0, but you'll get a well-tested, secure authorization implementation. Setting up OAuth 2.0: Creating a User Type Our application needs some concept of a 'user' - a person who logs into the application to manage heroes. This user will have a username and password. In a later exercise, a user will also have a list of heroes that belong to them. Create a new file model/user.dart and enter the following code: import 'package:conduit/managed_auth.dart'; import 'package:heroes/heroes.dart'; import 'package:heroes/model/hero.dart'; class User extends ManagedObject<_User> implements _User, ManagedAuthResourceOwner<_User> {} class _User extends ResourceOwnerTableDefinition {} The imported library package:conduit/managed_auth.dart contains types that use the ORM to store users, tokens and other OAuth 2.0 related data. One of those types is ResourceOwnerTableDefinition , the superclass of our user's table definition. This type contains all of the required fields that Conduit needs to implement authentication. !!! tip \"Resource Owners\" A resource owner is a more general term for a 'user' that comes from the OAuth 2.0 specification. In the framework, you'll see types and variables using some variant of resource owner , but for all intents and purposes, you can consider this a 'user'. If you are curious, ResourceOwnerTableDefinition looks like this: class ResourceOwnerTableDefinition { @primaryKey int id; @Column(unique: true, indexed: true) String username; @Column(omitByDefault: true) String hashedPassword; @Column(omitByDefault: true) String salt; ManagedSet<ManagedAuthToken> tokens; } Because these fields are in User 's table definition, our User table has all of these database columns. !!! note \"ManagedAuthResourceOwner\" Note that User implements ManagedAuthResourceOwner<_User> - this is a requirement of any OAuth 2.0 resource owner type when using package:conduit/managed_auth . Setting up OAuth 2.0: AuthServer and its Delegate Now that we have a user, we need some way to create new users and authenticate them. Authentication is fairly tricky, especially in OAuth 2.0, so there is a service object that does the hard part for us called an AuthServer . This type has all of the logic needed to authentication and authorize users. For example, an AuthServer can generate a new token if given valid user credentials. In channel.dart , add the following imports to the top of your file: import 'package:conduit/managed_auth.dart'; import 'package:heroes/model/user.dart'; Then, declare a new authServer property in your channel and initialize it in prepare : class HeroesChannel extends ApplicationChannel { ManagedContext context; // Add this field AuthServer authServer; Future prepare() async { logger.onRecord.listen((rec) => print(\"$rec ${rec.error ?? \"\"} ${rec.stackTrace ?? \"\"}\")); final config = HeroConfig(options.configurationFilePath); final dataModel = ManagedDataModel.fromCurrentMirrorSystem(); final persistentStore = PostgreSQLPersistentStore.fromConnectionInfo( config.database.username, config.database.password, config.database.host, config.database.port, config.database.databaseName); context = ManagedContext(dataModel, persistentStore); // Add these two lines: final authStorage = ManagedAuthDelegate<User>(context); authServer = AuthServer(authStorage); } ... While an AuthServer handles the logic of authentication and authorization, it doesn't know how to store or fetch the data it uses for those tasks. Instead, it relies on a delegate object to handle storing and fetching data from a database. In our application, we use ManagedAuthDelegate<T> - from package:conduit/managed_auth - as the delegate. This type uses the ORM for these tasks; the type argument must be our application's user object. !!! tip \"Delegation\" Delegation is a design pattern where an object has multiple callbacks that are grouped into an interface. Instead of defining a closure for each callback, a type implements methods that get called by the delegating object. It is a way of organizing large amounts of related callbacks into a tidy class. By importing conduit/managed_auth , we've added a few more managed objects to our application (to store tokens and other authentication data) and we also have a new User managed object. It's a good time to run a database migration. From your project directory, run the following commands: conduit db generate conduit db upgrade --connect postgres://heroes_user:password@localhost:5432/heroes Setting up OAuth 2.0: Registering Users Now that we have the concept of a user, our database and application are set up to handle authentication, we can start creating new users. Let's create a new controller for registering users. This controller will accept POST requests that contain a username and password in the body. It will insert a new user into the database and securely hash the user's password. Before we create this controller, there is something we need to consider: our registration endpoint will require the user's password, but we store the user's password as a cryptographic hash. This prevents someone with access to your database from knowing a user's password. In order to bind the body of a request to a User object, it needs a password field, but we don't want to store the password in the database without first hashing it. We can accomplish this with transient properties . A transient property is a property of a managed object that isn't stored in the database. They are declared in the managed object subclass instead of the table definition. By default, a transient property is not read from a request body or encoded into a response body; unless we add the Serialize annotation to it. Add this property to your User type: class User extends ManagedObject<_User> implements _User, ManagedAuthResourceOwner<_User> { @Serialize(input: true, output: false) String password; } This declares that a User has a transient property password that can be read on input (from a request body), but is not sent on output (to a response body). We don't have to run a database migration because transient properties are not stored in a database. Now, create the file controller/register_controller.dart and enter the following code: import 'dart:async'; import 'package:conduit/conduit.dart'; import 'package:heroes/model/user.dart'; class RegisterController extends ResourceController { RegisterController(this.context, this.authServer); final ManagedContext context; final AuthServer authServer; @Operation.post() Future<Response> createUser(@Bind.body() User user) async { // Check for required parameters before we spend time hashing if (user.username == null || user.password == null) { return Response.badRequest( body: {\"error\": \"username and password required.\"}); } user ..salt = generateRandomSalt() ..hashedPassword = authServer.hashPassword(user.password, user.salt); return Response.ok(await Query(context, values: user).insert()); } } This controller takes POST requests that contain a user. A user has many fields (username, password, hashedPassword, salt), but we will calculate the latter two and only require that the request contain the first two. The controller generates a salt and hash of the password before storing it in the database. In channel.dart , let's link this controller - don't forget to import it! import 'package:heroes/controller/register_controller.dart'; ... @override Controller get entryPoint { final router = Router(); router .route('/heroes/[:id]') .link(() => HeroesController(context)); router .route('/register') .link(() => RegisterController(context, authServer)); return router; } } Let's run the application and create a new user using curl from the command-line. (We'll specify -n1 to designate using one isolate and speed up startup.) conduit serve -n1 Then, issue a request to your server: curl -X POST http://localhost:8888/register -H 'Content-Type: application/json' -d '{\"username\":\"bob\", \"password\":\"password\"}' You'll get back the new user object and its username: {\"id\":1,\"username\":\"bob\"} Setting up OAuth 2.0: Authenticating Users Now that we have a user with a password, we can create an endpoint that takes user credentials and returns an access token. The good news is that this controller already exists in Conduit, you just have to hook it up to a route. Update entryPoint in channel.dart to add an AuthController for the route /auth/token : @override Controller get entryPoint { final router = Router(); // add this route router .route('/auth/token') .link(() => AuthController(authServer)); router .route('/heroes/[:id]') .link(() => HeroesController(context)); router .route('/register') .link(() => RegisterController(context, authServer)); return router; } An AuthController follows the OAuth 2.0 specification for granting access tokens when given valid user credentials. To understand how a request to this endpoint must be structured, we need to discuss OAuth 2.0 clients . In OAuth 2.0, a client is an application that is allowed to access your server on behalf of a user. A client can be a browser application, a mobile application, another server, a voice assistant, etc. A client always has an identifier string, typically something like 'com.conduit.dart.account_app.mobile'. When authenticating, a user is always authenticated through a client. This client information must be attached to every authentication request, and the server must validate that the client had been previously registered. Therefore, we need to register a new client for our application. A client is stored in our application's database using the conduit auth add-client CLI. Run the following command from your project directory: conduit auth add-client --id com.heroes.tutorial --connect postgres://heroes_user:password@localhost:5432/heroes !!! note \"OAuth 2.0 Clients\" A client must have an identifier, but it may also have a secret, redirect URI and list of allowed scopes. See the guides on OAuth 2.0 for how these options impacts authentication. Most notably, a client identifier must have a secret to issue a refresh token . Clients are stored in an application's database. This will insert a new row into an OAuth 2.0 client table created by our last round of database migration and allow us to make authentication requests. An authentication request must meet all of the following criteria: the client identifier (and secret, if it exists) are included as a basic Authorization header. the username and password are included in the request body the key-value grant_type=password is included in the request body the request body content-type is application/x-www-form-urlencoded ; this means the request body is effectively a query string (e.g. username=bob&password=pw&grant_type=password ) In Dart code, this would look like this: import 'dart:async'; import 'dart:convert'; import 'package:http/http.dart' as http; // Must include http: any package in your pubspec.yaml Future<void> main() async { const clientID = \"org.hasenbalg.zeiterfassung\"; const body = \"username=bob&password=password&grant_type=password\"; // Note the trailing colon (:) after the clientID. // A client identifier secret would follow this, but there is no secret, so it is the empty string. final String clientCredentials = const Base64Encoder().convert(\"$clientID:\".codeUnits); final http.Response response = await http.post(\"http://localhost:8888/auth/token\", headers: { \"Content-Type\": \"application/x-www-form-urlencoded\", \"Authorization\": \"Basic $clientCredentials\" }, body: body); print(response.body); } You can execute that code or you can use the following curl : curl -X POST http://localhost:8888/auth/token -H 'Authorization: Basic Y29tLmhlcm9lcy50dXRvcmlhbDo=' -H 'Content-Type: application/x-www-form-urlencoded' -d 'username=bob&password=password&grant_type=password' If you were successful, you'll get the following response containing an access token: {\"access_token\":\"687PWKFHRTQ9MveQ2dKvP95D4cWie1gh\",\"token_type\":\"bearer\",\"expires_in\":86399} Hang on to this access token, we'll use it in a moment. Setting up OAuth 2.0: Securing Routes Now that we can create and authenticate users, we can protect our heroes from anonymous users by requiring an access token for hero requests. In channel.dart , link an Authorizer in the middle of the /heroes channel: router .route('/heroes/[:id]') .link(() => Authorizer.bearer(authServer)) .link(() => HeroesController(context)); An Authorizer protects a channel from unauthorized requests by validating the Authorization header of a request. When created with Authorizer.bearer , it ensures that the authorization header contains a valid access token. Restart your application and try and access the /heroes endpoint without including any authorization: curl -X GET --verbose http://localhost:8888/heroes You'll get a 401 Unauthorized response. Now, include your access token in a bearer authorization header (note that your token will be different): curl -X GET http://localhost:8888/heroes -H 'Authorization: Bearer 687PWKFHRTQ9MveQ2dKvP95D4cWie1gh' You'll get back your list of heroes! !!! note \"Other Uses of Authorizer\" An Authorizer can validate access token scopes and basic authorization credentials. You'll see examples of these in a later exercise.","title":"5. Authentication and Authorization"},{"location":"tut/oauth2/#authentication-and-authorization-with-oauth-20","text":"Our heroes application lets anyone create or view the same set of heroes. We will continue to build on the last chapter's project, heroes , requiring a user to log in before viewing or creating heroes. !!! note \"We're Done With the Browser App\" We're at the point now where using the browser application to test our Conduit app gets a bit cumbersome. From here on out, we'll use curl , conduit document client and tests.","title":"Authentication and Authorization with OAuth 2.0"},{"location":"tut/oauth2/#the-basics-of-oauth-20","text":"OAuth 2.0 is an authorization framework that also contains guidance on authentication. Authentication is the process of proving you are a particular user, typically through a username and password. Authorization is the process of ensuring that a user can access a particular resource or collection of resources. In our application, a user will have to be authenticated before being authorized to view or create heroes. In a simple authentication and authorization scheme, each HTTP request contains the username and password (credentials) of the user in an Authorization header. There are a number of security risks involved in doing this, so OAuth 2.0 takes another approach: you send your credentials once, and get a 'access token' in return. You then send this access token in each request. Because the server grants the token, it knows that you've already entered your credentials (you've authenticated ) and it remembers who the token belongs to. It's effectively the same thing as sending your credentials each time, except that the token has a time limit and can be revoked when things go wrong. Conduit has a built-in OAuth 2.0 implementation that leverages the ORM. This implementation is part of the conduit package, but it is a separate library named conduit/managed_auth . It takes a few steps to set up that might be difficult to understand if you are not familiar with OAuth 2.0, but you'll get a well-tested, secure authorization implementation.","title":"The Basics of OAuth 2.0"},{"location":"tut/oauth2/#setting-up-oauth-20-creating-a-user-type","text":"Our application needs some concept of a 'user' - a person who logs into the application to manage heroes. This user will have a username and password. In a later exercise, a user will also have a list of heroes that belong to them. Create a new file model/user.dart and enter the following code: import 'package:conduit/managed_auth.dart'; import 'package:heroes/heroes.dart'; import 'package:heroes/model/hero.dart'; class User extends ManagedObject<_User> implements _User, ManagedAuthResourceOwner<_User> {} class _User extends ResourceOwnerTableDefinition {} The imported library package:conduit/managed_auth.dart contains types that use the ORM to store users, tokens and other OAuth 2.0 related data. One of those types is ResourceOwnerTableDefinition , the superclass of our user's table definition. This type contains all of the required fields that Conduit needs to implement authentication. !!! tip \"Resource Owners\" A resource owner is a more general term for a 'user' that comes from the OAuth 2.0 specification. In the framework, you'll see types and variables using some variant of resource owner , but for all intents and purposes, you can consider this a 'user'. If you are curious, ResourceOwnerTableDefinition looks like this: class ResourceOwnerTableDefinition { @primaryKey int id; @Column(unique: true, indexed: true) String username; @Column(omitByDefault: true) String hashedPassword; @Column(omitByDefault: true) String salt; ManagedSet<ManagedAuthToken> tokens; } Because these fields are in User 's table definition, our User table has all of these database columns. !!! note \"ManagedAuthResourceOwner\" Note that User implements ManagedAuthResourceOwner<_User> - this is a requirement of any OAuth 2.0 resource owner type when using package:conduit/managed_auth .","title":"Setting up OAuth 2.0: Creating a User Type"},{"location":"tut/oauth2/#setting-up-oauth-20-authserver-and-its-delegate","text":"Now that we have a user, we need some way to create new users and authenticate them. Authentication is fairly tricky, especially in OAuth 2.0, so there is a service object that does the hard part for us called an AuthServer . This type has all of the logic needed to authentication and authorize users. For example, an AuthServer can generate a new token if given valid user credentials. In channel.dart , add the following imports to the top of your file: import 'package:conduit/managed_auth.dart'; import 'package:heroes/model/user.dart'; Then, declare a new authServer property in your channel and initialize it in prepare : class HeroesChannel extends ApplicationChannel { ManagedContext context; // Add this field AuthServer authServer; Future prepare() async { logger.onRecord.listen((rec) => print(\"$rec ${rec.error ?? \"\"} ${rec.stackTrace ?? \"\"}\")); final config = HeroConfig(options.configurationFilePath); final dataModel = ManagedDataModel.fromCurrentMirrorSystem(); final persistentStore = PostgreSQLPersistentStore.fromConnectionInfo( config.database.username, config.database.password, config.database.host, config.database.port, config.database.databaseName); context = ManagedContext(dataModel, persistentStore); // Add these two lines: final authStorage = ManagedAuthDelegate<User>(context); authServer = AuthServer(authStorage); } ... While an AuthServer handles the logic of authentication and authorization, it doesn't know how to store or fetch the data it uses for those tasks. Instead, it relies on a delegate object to handle storing and fetching data from a database. In our application, we use ManagedAuthDelegate<T> - from package:conduit/managed_auth - as the delegate. This type uses the ORM for these tasks; the type argument must be our application's user object. !!! tip \"Delegation\" Delegation is a design pattern where an object has multiple callbacks that are grouped into an interface. Instead of defining a closure for each callback, a type implements methods that get called by the delegating object. It is a way of organizing large amounts of related callbacks into a tidy class. By importing conduit/managed_auth , we've added a few more managed objects to our application (to store tokens and other authentication data) and we also have a new User managed object. It's a good time to run a database migration. From your project directory, run the following commands: conduit db generate conduit db upgrade --connect postgres://heroes_user:password@localhost:5432/heroes","title":"Setting up OAuth 2.0: AuthServer and its Delegate"},{"location":"tut/oauth2/#setting-up-oauth-20-registering-users","text":"Now that we have the concept of a user, our database and application are set up to handle authentication, we can start creating new users. Let's create a new controller for registering users. This controller will accept POST requests that contain a username and password in the body. It will insert a new user into the database and securely hash the user's password. Before we create this controller, there is something we need to consider: our registration endpoint will require the user's password, but we store the user's password as a cryptographic hash. This prevents someone with access to your database from knowing a user's password. In order to bind the body of a request to a User object, it needs a password field, but we don't want to store the password in the database without first hashing it. We can accomplish this with transient properties . A transient property is a property of a managed object that isn't stored in the database. They are declared in the managed object subclass instead of the table definition. By default, a transient property is not read from a request body or encoded into a response body; unless we add the Serialize annotation to it. Add this property to your User type: class User extends ManagedObject<_User> implements _User, ManagedAuthResourceOwner<_User> { @Serialize(input: true, output: false) String password; } This declares that a User has a transient property password that can be read on input (from a request body), but is not sent on output (to a response body). We don't have to run a database migration because transient properties are not stored in a database. Now, create the file controller/register_controller.dart and enter the following code: import 'dart:async'; import 'package:conduit/conduit.dart'; import 'package:heroes/model/user.dart'; class RegisterController extends ResourceController { RegisterController(this.context, this.authServer); final ManagedContext context; final AuthServer authServer; @Operation.post() Future<Response> createUser(@Bind.body() User user) async { // Check for required parameters before we spend time hashing if (user.username == null || user.password == null) { return Response.badRequest( body: {\"error\": \"username and password required.\"}); } user ..salt = generateRandomSalt() ..hashedPassword = authServer.hashPassword(user.password, user.salt); return Response.ok(await Query(context, values: user).insert()); } } This controller takes POST requests that contain a user. A user has many fields (username, password, hashedPassword, salt), but we will calculate the latter two and only require that the request contain the first two. The controller generates a salt and hash of the password before storing it in the database. In channel.dart , let's link this controller - don't forget to import it! import 'package:heroes/controller/register_controller.dart'; ... @override Controller get entryPoint { final router = Router(); router .route('/heroes/[:id]') .link(() => HeroesController(context)); router .route('/register') .link(() => RegisterController(context, authServer)); return router; } } Let's run the application and create a new user using curl from the command-line. (We'll specify -n1 to designate using one isolate and speed up startup.) conduit serve -n1 Then, issue a request to your server: curl -X POST http://localhost:8888/register -H 'Content-Type: application/json' -d '{\"username\":\"bob\", \"password\":\"password\"}' You'll get back the new user object and its username: {\"id\":1,\"username\":\"bob\"}","title":"Setting up OAuth 2.0: Registering Users"},{"location":"tut/oauth2/#setting-up-oauth-20-authenticating-users","text":"Now that we have a user with a password, we can create an endpoint that takes user credentials and returns an access token. The good news is that this controller already exists in Conduit, you just have to hook it up to a route. Update entryPoint in channel.dart to add an AuthController for the route /auth/token : @override Controller get entryPoint { final router = Router(); // add this route router .route('/auth/token') .link(() => AuthController(authServer)); router .route('/heroes/[:id]') .link(() => HeroesController(context)); router .route('/register') .link(() => RegisterController(context, authServer)); return router; } An AuthController follows the OAuth 2.0 specification for granting access tokens when given valid user credentials. To understand how a request to this endpoint must be structured, we need to discuss OAuth 2.0 clients . In OAuth 2.0, a client is an application that is allowed to access your server on behalf of a user. A client can be a browser application, a mobile application, another server, a voice assistant, etc. A client always has an identifier string, typically something like 'com.conduit.dart.account_app.mobile'. When authenticating, a user is always authenticated through a client. This client information must be attached to every authentication request, and the server must validate that the client had been previously registered. Therefore, we need to register a new client for our application. A client is stored in our application's database using the conduit auth add-client CLI. Run the following command from your project directory: conduit auth add-client --id com.heroes.tutorial --connect postgres://heroes_user:password@localhost:5432/heroes !!! note \"OAuth 2.0 Clients\" A client must have an identifier, but it may also have a secret, redirect URI and list of allowed scopes. See the guides on OAuth 2.0 for how these options impacts authentication. Most notably, a client identifier must have a secret to issue a refresh token . Clients are stored in an application's database. This will insert a new row into an OAuth 2.0 client table created by our last round of database migration and allow us to make authentication requests. An authentication request must meet all of the following criteria: the client identifier (and secret, if it exists) are included as a basic Authorization header. the username and password are included in the request body the key-value grant_type=password is included in the request body the request body content-type is application/x-www-form-urlencoded ; this means the request body is effectively a query string (e.g. username=bob&password=pw&grant_type=password ) In Dart code, this would look like this: import 'dart:async'; import 'dart:convert'; import 'package:http/http.dart' as http; // Must include http: any package in your pubspec.yaml Future<void> main() async { const clientID = \"org.hasenbalg.zeiterfassung\"; const body = \"username=bob&password=password&grant_type=password\"; // Note the trailing colon (:) after the clientID. // A client identifier secret would follow this, but there is no secret, so it is the empty string. final String clientCredentials = const Base64Encoder().convert(\"$clientID:\".codeUnits); final http.Response response = await http.post(\"http://localhost:8888/auth/token\", headers: { \"Content-Type\": \"application/x-www-form-urlencoded\", \"Authorization\": \"Basic $clientCredentials\" }, body: body); print(response.body); } You can execute that code or you can use the following curl : curl -X POST http://localhost:8888/auth/token -H 'Authorization: Basic Y29tLmhlcm9lcy50dXRvcmlhbDo=' -H 'Content-Type: application/x-www-form-urlencoded' -d 'username=bob&password=password&grant_type=password' If you were successful, you'll get the following response containing an access token: {\"access_token\":\"687PWKFHRTQ9MveQ2dKvP95D4cWie1gh\",\"token_type\":\"bearer\",\"expires_in\":86399} Hang on to this access token, we'll use it in a moment.","title":"Setting up OAuth 2.0: Authenticating Users"},{"location":"tut/oauth2/#setting-up-oauth-20-securing-routes","text":"Now that we can create and authenticate users, we can protect our heroes from anonymous users by requiring an access token for hero requests. In channel.dart , link an Authorizer in the middle of the /heroes channel: router .route('/heroes/[:id]') .link(() => Authorizer.bearer(authServer)) .link(() => HeroesController(context)); An Authorizer protects a channel from unauthorized requests by validating the Authorization header of a request. When created with Authorizer.bearer , it ensures that the authorization header contains a valid access token. Restart your application and try and access the /heroes endpoint without including any authorization: curl -X GET --verbose http://localhost:8888/heroes You'll get a 401 Unauthorized response. Now, include your access token in a bearer authorization header (note that your token will be different): curl -X GET http://localhost:8888/heroes -H 'Authorization: Bearer 687PWKFHRTQ9MveQ2dKvP95D4cWie1gh' You'll get back your list of heroes! !!! note \"Other Uses of Authorizer\" An Authorizer can validate access token scopes and basic authorization credentials. You'll see examples of these in a later exercise.","title":"Setting up OAuth 2.0: Securing Routes"},{"location":"tut/storing-data/","text":"Storing Data in a Database In the previous exercise, we loaded some heroes into the database our application reads from. Now, we will allow our application to store, delete and modify heroes in the database. Before we embark on this part of the journey, it's important that we understand how an HTTP API is intended to work. HTTP Resources and Methods The HTTP specification defines the concept of a resource . A resource can be anything - a hero, a bank account, a light switch in your home, a temperature sensor in Antarctica, etc. Some of these things are physical objects (the light switch), and some are digital - and they are all resources. An HTTP server application is an interface to these resources; a client requests that something be done with a resource, and the server finds a way to get it done. Resources are identified with a URI. A URI universally identifies a resource: it has the address of a server to connect to, and a path that identifies the resource on that server. When writing Conduit applications, we don't care much about the server part of a URL - the internet figures out that part. What we do care about is the path of the URL - like /heroes . An application uses the URL path to determine which resource the request wants to work with. Right now, our application works with hero resources. A request with the path /heroes/1 wants to do something with an individual hero (that is identified by the number 1 ). A request with the path /heroes will act on the entire collection of heroes. These actions are primarily described by the request method (like GET, POST, OR DELETE). Each of these methods has a general meaning that describes an action that can be applied to a resource. For example, a GET /heroes means \"get me all of the hero resources\". The meaning for each of these methods are as follows: GET: returns a collection of some resource or an individual resource POST: inserts or appends a resource to a collection of some resource; a representation of the resource is in the request body PUT: replaces a resource with the contents of the request body (or in some cases, replaces the entire collection of some resource) DELETE: deletes a resource (or in some cases, deletes the entire collection of some resource) It turns out, we can create a lot of incredible behavior by just combining these methods and a request path. More importantly, by following these specifications, client applications can use generic libraries to access any HTTP API with very little effort. This allows us to create complex systems that are easily made available to a browser, mobile phone or any other internet-connected device. Inserting Data We'll start by adding behavior that allows for new heroes to be inserted into the database. Following our previous discussion, the HTTP request must take the form POST /heroes - we are appending a new hero to the collection of heroes. This request will contain the JSON representation of a hero in its body, for example: { \"name\": \"Master of Conduits\" } Our HeroesController will handle this operation. In general, a single endpoint controller should handle every operation on a resource collection and its individual resources. In heroes_controller.dart , add the following operation method: @Operation.post() Future<Response> createHero() async { final Map<String, dynamic> body = await request.body.decode(); final query = Query<Hero>(context) ..values.name = body['name'] as String; final insertedHero = await query.insert(); return Response.ok(insertedHero); } There are three important things happening here: this method decodes the JSON object from the request's body, constructs a query that inserts a new hero with the name in the JSON object, and then returns the newly inserted hero in the response. If the decoded body doesn't match the type of the variable or parameter it is being assigned to, a status code 400 exception is thrown. This means that decoding the body in this way checks that the body is the expected format and returns an error to the client on your behalf if it is not. For example, if someone posts a list of JSON objects, they will get a 400 Bad Request response because we expect a single JSON object in our method. An insertion query sets the properties of its values object. The values object is an instance of the type being inserted. Invoking insert on a query inserts a row with its values. A new hero, with its primary key set by the database, is returned and returned as the body of the response. The generated SQL for the above would be something like: INSERT INTO _Hero (name) VALUES ('Hero Name'); !!! tip \"Column Attributes\" The id of a hero is automatically generated because of its @primaryKey annotation. This annotation is a Column that configures the id to be both a primary key and be 'auto-incrementing'. Auto-incremented columns values are generated automatically (1, 2, 3...). See the API reference for Column for column options. Re-run your application. In the browser application, click on Heroes near the top of the page. Then, enter a name into the Hero name: field and click Add . The new hero will appear. You can re-run the application and that hero will still be available, because it has been stored in the database on your machine. Assigning values one-by-one from a request body to a query is cumbersome. You can also auto-magically ingest a request body into a managed object and assign it to the values of a query: @Operation.post() Future<Response> createHero() async { final hero = Hero() ..read(await request.body.decode(), ignore: [\"id\"]); final query = Query<Hero>(context)..values = hero; final insertedHero = await query.insert(); return Response.ok(insertedHero); } The read method reads a Map<String, dynamic> into a managed object. Each key's value is assigned to the property of the same name. The ignore: optional parameter removes values for that key from the map before reading it. You can also reject or require keys in this way. If a request body contains a key that isn't declared as property of the managed object, a 400 status code exception is thrown. !!! tip \"Sub-resources\" We mentioned that a single controller should handle every operation for a resource collection and its individual resources. Some resources are complex enough that they can have sub-resources. For example, an organization of heroes (like the X-Men or Fantastic Four) contains heroes, but it might also contain buildings and equipment owned by the organization. The heroes, buildings and equipment are sub-resources of an organization. Each sub-resource should have its own route and controller instead of trying to shove everything into a single route and controller. See the following code snippet for an example. @override Controller get entryPoint { return Router() ..route(\"/organizations/[:orgName]\") .link(() => OrganizationController()); ..route(\"/organizations/:orgName/heroes/[:heroID]\") .link(() => OrgHeroesController()); ..route(\"/organizations/:orgName/buildings/[:buildingID]\") .link(() => OrgBuildingController()); } Request and Response Bodies So far, we've largely glossed over how request and response bodies are handled, and now is a good time to dig in to this topic. Response Body Encoding When we create a response, we specify its status code and optionally its headers and body. For example, the following creates a response with a status code of 200 OK with an empty list body: Response.ok([]) The first argument to Response.ok is a body object . A body object is automatically encoded according to the contentType of its response. By default, the content type of a response is application/json - so by default, all of our response body objects are JSON-encoded in the response body. !!! note \"Other Response Constructors\" The default constructor for a Response takes a status code, map of headers and a body object: Response(200, {}, \"body\") . There are many named constructors for Response , like Response.ok or Response.notFound . These constructors set the status code and expose parameters that are intended for that type of response. For example, a 200 OK response should have a body, so Response.ok has a required body object argument. See the API reference for Response for possible constructors and properties of a response. To change the format a body object is encoded into, you set the contentType of the response. For example, Response.ok([]) ..contentType = new ContentType(\"application\", \"xml\"); The default supported content types are JSON, application/x-www-form-urlencoded and all text/* types. To encode other content-types, you must register a Codec with CodecRegistry. A body object is only valid if the codec selected by the response's content-type can encode it. If it can't, an error will be thrown and a 500 Server Error response is sent instead. Types that implement Serializable may also be body objects. Objects that implement this type provide an asMap() method that converts their properties into a Map before being passed to the encoder. This Map must be encodable for the response's content-type codec. You may also provide a List of Serializable , for which the list of each object's asMap() is passed to the encoder. ManagedObject implements the Serializable interface, and therefore all managed objects (and lists of managed objects) can be body objects. Request Body Decoding Every Request has a body property of type RequestBody . A RequestBody decodes the contents of the request body into Dart objects that you use in your application. This decoding is performed by the Codec that is associated with the request's content-type. The decoded object is determined by the format of the data - for example, a JSON array decodes into a List , a JSON object into a Map . When you write code to decode a request body, you are also validating the request body is in the expected format. For example, your HeroesController invokes decode like this: Map<String, dynamic> body = await request.body.decode(); The decode method has a type argument that is inferred to be a Map<String, dynamic> . If the decoded body is not a Map , an exception is thrown that sends an appropriate error response to the client. You may also bind the body of a request to an operation method parameter. Let's bind a Hero instance to a request body in our HeroesController . Update the code in that file to the following: @Operation.post() Future<Response> createHero(@Bind.body(ignore: [\"id\"]) Hero inputHero) async { final query = Query<Hero>(context) ..values = inputHero; final insertedHero = await query.insert(); return Response.ok(insertedHero); } Values in the request body object are decoded into a Hero object - each key in the request body maps to a property of our Hero . For example, the value for the key 'name' is stored in the inputHero.name . If decoding the request body into a Hero instance fails for any reason, a 400 Bad Request response is sent and the operation method is not called. !!! tip \"Binding Serializables\" A body can be bound to any type - a request will only succeed if the decoded body matches the expected type. When a Serializable subclass (or List<Serializable> ) is bound to a body, it enforces the body to be decoded into a Map<String, dynamic> (or a List<Map<String, dynamic>> ). All ManagedObject s implement Serializable , and therefore you may bind managed objects (and lists of such) using body binding. Re-run your heroes application. On http://conduit-tutorial.conduit.dart.io , click on the Heroes button on the top of the screen. In the text field, enter a new hero name and click Add . You'll see your new hero added to the list! You can shutdown your application and run it again and you'll still be able to fetch your new hero. !!! tip \"Query Construction\" Properties like values and where prevent errors by type and name checking columns with the analyzer. They're also great for speeding up writing code because your IDE will autocomplete property names. There is specific behavior a query uses to decide whether it should include a value from these two properties in the SQL it generates.","title":"3. Storing Data in a Database"},{"location":"tut/storing-data/#storing-data-in-a-database","text":"In the previous exercise, we loaded some heroes into the database our application reads from. Now, we will allow our application to store, delete and modify heroes in the database. Before we embark on this part of the journey, it's important that we understand how an HTTP API is intended to work.","title":"Storing Data in a Database"},{"location":"tut/storing-data/#http-resources-and-methods","text":"The HTTP specification defines the concept of a resource . A resource can be anything - a hero, a bank account, a light switch in your home, a temperature sensor in Antarctica, etc. Some of these things are physical objects (the light switch), and some are digital - and they are all resources. An HTTP server application is an interface to these resources; a client requests that something be done with a resource, and the server finds a way to get it done. Resources are identified with a URI. A URI universally identifies a resource: it has the address of a server to connect to, and a path that identifies the resource on that server. When writing Conduit applications, we don't care much about the server part of a URL - the internet figures out that part. What we do care about is the path of the URL - like /heroes . An application uses the URL path to determine which resource the request wants to work with. Right now, our application works with hero resources. A request with the path /heroes/1 wants to do something with an individual hero (that is identified by the number 1 ). A request with the path /heroes will act on the entire collection of heroes. These actions are primarily described by the request method (like GET, POST, OR DELETE). Each of these methods has a general meaning that describes an action that can be applied to a resource. For example, a GET /heroes means \"get me all of the hero resources\". The meaning for each of these methods are as follows: GET: returns a collection of some resource or an individual resource POST: inserts or appends a resource to a collection of some resource; a representation of the resource is in the request body PUT: replaces a resource with the contents of the request body (or in some cases, replaces the entire collection of some resource) DELETE: deletes a resource (or in some cases, deletes the entire collection of some resource) It turns out, we can create a lot of incredible behavior by just combining these methods and a request path. More importantly, by following these specifications, client applications can use generic libraries to access any HTTP API with very little effort. This allows us to create complex systems that are easily made available to a browser, mobile phone or any other internet-connected device.","title":"HTTP Resources and Methods"},{"location":"tut/storing-data/#inserting-data","text":"We'll start by adding behavior that allows for new heroes to be inserted into the database. Following our previous discussion, the HTTP request must take the form POST /heroes - we are appending a new hero to the collection of heroes. This request will contain the JSON representation of a hero in its body, for example: { \"name\": \"Master of Conduits\" } Our HeroesController will handle this operation. In general, a single endpoint controller should handle every operation on a resource collection and its individual resources. In heroes_controller.dart , add the following operation method: @Operation.post() Future<Response> createHero() async { final Map<String, dynamic> body = await request.body.decode(); final query = Query<Hero>(context) ..values.name = body['name'] as String; final insertedHero = await query.insert(); return Response.ok(insertedHero); } There are three important things happening here: this method decodes the JSON object from the request's body, constructs a query that inserts a new hero with the name in the JSON object, and then returns the newly inserted hero in the response. If the decoded body doesn't match the type of the variable or parameter it is being assigned to, a status code 400 exception is thrown. This means that decoding the body in this way checks that the body is the expected format and returns an error to the client on your behalf if it is not. For example, if someone posts a list of JSON objects, they will get a 400 Bad Request response because we expect a single JSON object in our method. An insertion query sets the properties of its values object. The values object is an instance of the type being inserted. Invoking insert on a query inserts a row with its values. A new hero, with its primary key set by the database, is returned and returned as the body of the response. The generated SQL for the above would be something like: INSERT INTO _Hero (name) VALUES ('Hero Name'); !!! tip \"Column Attributes\" The id of a hero is automatically generated because of its @primaryKey annotation. This annotation is a Column that configures the id to be both a primary key and be 'auto-incrementing'. Auto-incremented columns values are generated automatically (1, 2, 3...). See the API reference for Column for column options. Re-run your application. In the browser application, click on Heroes near the top of the page. Then, enter a name into the Hero name: field and click Add . The new hero will appear. You can re-run the application and that hero will still be available, because it has been stored in the database on your machine. Assigning values one-by-one from a request body to a query is cumbersome. You can also auto-magically ingest a request body into a managed object and assign it to the values of a query: @Operation.post() Future<Response> createHero() async { final hero = Hero() ..read(await request.body.decode(), ignore: [\"id\"]); final query = Query<Hero>(context)..values = hero; final insertedHero = await query.insert(); return Response.ok(insertedHero); } The read method reads a Map<String, dynamic> into a managed object. Each key's value is assigned to the property of the same name. The ignore: optional parameter removes values for that key from the map before reading it. You can also reject or require keys in this way. If a request body contains a key that isn't declared as property of the managed object, a 400 status code exception is thrown. !!! tip \"Sub-resources\" We mentioned that a single controller should handle every operation for a resource collection and its individual resources. Some resources are complex enough that they can have sub-resources. For example, an organization of heroes (like the X-Men or Fantastic Four) contains heroes, but it might also contain buildings and equipment owned by the organization. The heroes, buildings and equipment are sub-resources of an organization. Each sub-resource should have its own route and controller instead of trying to shove everything into a single route and controller. See the following code snippet for an example. @override Controller get entryPoint { return Router() ..route(\"/organizations/[:orgName]\") .link(() => OrganizationController()); ..route(\"/organizations/:orgName/heroes/[:heroID]\") .link(() => OrgHeroesController()); ..route(\"/organizations/:orgName/buildings/[:buildingID]\") .link(() => OrgBuildingController()); }","title":"Inserting Data"},{"location":"tut/storing-data/#request-and-response-bodies","text":"So far, we've largely glossed over how request and response bodies are handled, and now is a good time to dig in to this topic.","title":"Request and Response Bodies"},{"location":"tut/storing-data/#response-body-encoding","text":"When we create a response, we specify its status code and optionally its headers and body. For example, the following creates a response with a status code of 200 OK with an empty list body: Response.ok([]) The first argument to Response.ok is a body object . A body object is automatically encoded according to the contentType of its response. By default, the content type of a response is application/json - so by default, all of our response body objects are JSON-encoded in the response body. !!! note \"Other Response Constructors\" The default constructor for a Response takes a status code, map of headers and a body object: Response(200, {}, \"body\") . There are many named constructors for Response , like Response.ok or Response.notFound . These constructors set the status code and expose parameters that are intended for that type of response. For example, a 200 OK response should have a body, so Response.ok has a required body object argument. See the API reference for Response for possible constructors and properties of a response. To change the format a body object is encoded into, you set the contentType of the response. For example, Response.ok([]) ..contentType = new ContentType(\"application\", \"xml\"); The default supported content types are JSON, application/x-www-form-urlencoded and all text/* types. To encode other content-types, you must register a Codec with CodecRegistry. A body object is only valid if the codec selected by the response's content-type can encode it. If it can't, an error will be thrown and a 500 Server Error response is sent instead. Types that implement Serializable may also be body objects. Objects that implement this type provide an asMap() method that converts their properties into a Map before being passed to the encoder. This Map must be encodable for the response's content-type codec. You may also provide a List of Serializable , for which the list of each object's asMap() is passed to the encoder. ManagedObject implements the Serializable interface, and therefore all managed objects (and lists of managed objects) can be body objects.","title":"Response Body Encoding"},{"location":"tut/storing-data/#request-body-decoding","text":"Every Request has a body property of type RequestBody . A RequestBody decodes the contents of the request body into Dart objects that you use in your application. This decoding is performed by the Codec that is associated with the request's content-type. The decoded object is determined by the format of the data - for example, a JSON array decodes into a List , a JSON object into a Map . When you write code to decode a request body, you are also validating the request body is in the expected format. For example, your HeroesController invokes decode like this: Map<String, dynamic> body = await request.body.decode(); The decode method has a type argument that is inferred to be a Map<String, dynamic> . If the decoded body is not a Map , an exception is thrown that sends an appropriate error response to the client. You may also bind the body of a request to an operation method parameter. Let's bind a Hero instance to a request body in our HeroesController . Update the code in that file to the following: @Operation.post() Future<Response> createHero(@Bind.body(ignore: [\"id\"]) Hero inputHero) async { final query = Query<Hero>(context) ..values = inputHero; final insertedHero = await query.insert(); return Response.ok(insertedHero); } Values in the request body object are decoded into a Hero object - each key in the request body maps to a property of our Hero . For example, the value for the key 'name' is stored in the inputHero.name . If decoding the request body into a Hero instance fails for any reason, a 400 Bad Request response is sent and the operation method is not called. !!! tip \"Binding Serializables\" A body can be bound to any type - a request will only succeed if the decoded body matches the expected type. When a Serializable subclass (or List<Serializable> ) is bound to a body, it enforces the body to be decoded into a Map<String, dynamic> (or a List<Map<String, dynamic>> ). All ManagedObject s implement Serializable , and therefore you may bind managed objects (and lists of such) using body binding. Re-run your heroes application. On http://conduit-tutorial.conduit.dart.io , click on the Heroes button on the top of the screen. In the text field, enter a new hero name and click Add . You'll see your new hero added to the list! You can shutdown your application and run it again and you'll still be able to fetch your new hero. !!! tip \"Query Construction\" Properties like values and where prevent errors by type and name checking columns with the analyzer. They're also great for speeding up writing code because your IDE will autocomplete property names. There is specific behavior a query uses to decide whether it should include a value from these two properties in the SQL it generates.","title":"Request Body Decoding"},{"location":"tut/writing-tests/","text":"Configuration and Writing Tests We will continue to build on the last chapter's project, heroes , by writing automated tests for it. We will also set up configurable environments for our application. Application Configuration Right now, our application hardcodes its database connection information. This is bad because we want to use a different database when we're testing, running locally and running in production. It's also bad because we'd have to check our database password into version control. We can create a configuration file to store values like database connection information, and use a different configuration file for each environment. The heroes application needs to be able to configure the username, password, host port and name of the database it uses. Open the file config.yaml , which is empty, and enter the following key-value pairs: database: host: localhost port: 5432 username: heroes_user password: password databaseName: heroes These are the same values we used in our application channel. We'll want to replace the hardcoded values with whatever values are in this file. In lib/channel.dart , declare a new class at the bottom of the file: class HeroConfig extends Configuration { HeroConfig(String path): super.fromFile(File(path)); DatabaseConfiguration database; } A Configuration subclass declares the expected properties of a configuration file. HeroConfig has one property named database - this matches the name of our top-level key in config.yaml . A DatabaseConfiguration is a built-in configuration type that has properties for host , port , username , password and databaseName . We can load config.yaml into a HeroConfig because they have the same structure and all of the key names match the property names in our configuration types. !!! tip \"Invalid Configuration\" If your configuration file and configuration object don't have a matching structure, an error will be thrown when your application starts and tell you which values are missing. Let's load config.yaml and use its values to set up our database connection by replacing the prepare method in lib/channel.dart : @override Future prepare() async { logger.onRecord.listen( (rec) => print(\"$rec ${rec.error ?? \"\"} ${rec.stackTrace ?? \"\"}\")); final config = HeroConfig(options.configurationFilePath); final dataModel = ManagedDataModel.fromCurrentMirrorSystem(); final persistentStore = PostgreSQLPersistentStore.fromConnectionInfo( config.database.username, config.database.password, config.database.host, config.database.port, config.database.databaseName); context = ManagedContext(dataModel, persistentStore); } When our application starts, our channel has access to an options property that has the command-line arguments that started the application. By default, the value of configurationFilePath is config.yaml (it corresponds to --config-path in conduit serve ). When config.yaml is read, its values are read into a HeroConfig and are used to configure our database connection. Re-run your application and it'll work exactly the same as it did before - except now, we can substitute databases depending on how we run the application. Configuration Template You shouldn't check config.yaml into version control because it contains sensitive information. However, it is important to check in a configuration source file . A configuration source file has the same structure as HeroConfig , but it has values for your test environment - both locally and with continuous integration tools. It is also used as a template for your deployed configuration files. !!! tip \"Sensitive Information\" Use a platform like Heroku or Kubernetes. You can store sensitive information in secured environment variables. You can substitute environment variables in a configuration file by using the variable's name with a $ prefix as a value, e.g. password: $DATABASE_PASSWORD . A configuration source file should be named config.src.yaml , and one currently exists as an empty file in your project. Enter the following configuration into this file: database: host: localhost port: 5432 username: dart password: dart databaseName: dart_test This file has the expected structure, but has different values for the database information (for a database that we will create shortly). In the next section, we'll use this configuration file to run our automated tests. Testing in Conduit So far, we've tested our application by using a web application. This isn't a good way to test an application. A better way is to write automated test cases. An automated test case not only tests the code you are working on, but makes sure the code you've worked on in the past continues to work as you make changes. A good development practice is to configure TravisCI to run all of your tests for every code change. Because testing is so important, there is a package for writing Conduit application tests. In this chapter, we will use this package to make sure our hero endpoints are working correctly. !!! note \"package:conduit_test\" The package conduit_test and test was already added to your pubspec.yaml file as a test dependency by the template generator. In all Dart applications, a test suite is a Dart script with a main function. In this function, the test function is called multiple times to register expectations. A test passes if all of your expectations are met. An example Dart test looks like this: import 'package:test/test.dart'; void main() { test(\"1+1 = 2\", () { // Expect that 1 + 1 = 2 expect(1 + 1, equals(2)); }); } Setting up your Development Environment In config.src.yaml , we target the database dart:dart@localhost:5432/dart_test . This is a 'special' database that is used by all Conduit applications for automated testing (by default). When your application is tested, its tables are temporarily added to this database and then discarded after tests complete. This means that no data is stored in between test runs. Create this database by running psql and enter the following SQL: CREATE DATABASE dart_test; CREATE USER dart WITH createdb; ALTER USER dart WITH password 'dart'; GRANT all ON database dart_test TO dart; !!! tip \"dart_test Database\" You only have to create this database once per machine, and in any continuous integration scripts. All of your Conduit applications will use this database for automated testing. Fun fact - you can run multiple application's tests simultaneously using this database because the tables only exist for the database connection that created them. Writing Your First Test We will create a test suite to make sure that all hero endpoints return the right data, and make the right changes. Create a new file named test/hero_controller_test.dart . !!! warning \"Test Files Names and Locations\" A test file must end in _test.dart and must be in the test/ directory of your project, or it won't be run. At the top of this file, import your application's test harness and enter the following main function: import 'harness/app.dart'; void main() { final harness = Harness()..install(); } A test harness is an object that starts and stops your application when running a test suite, as long as you call its install method. This harness can then send requests to your application, and you can expect that the response is correct. Add a test to the main function that makes sure we get back a 200 OK when we call GET /heroes : void main() { final harness = Harness()..install(); test(\"GET /heroes returns 200 OK\", () async { final response = await harness.agent.get(\"/heroes\"); expectResponse(response, 200); }); } A harness has an Agent that can send requests to the application it started. Methods like get and post take a path (and optionally headers and a body) and return a response object. This object is used in expectResponse to validate the status code and other values. Tests in Conduit are written in this way: make a request, expect that the response is intended. Because our application makes database queries, we have to to upload our database schema to the test database before each test. Fortunately, this is something our test harness can also do. In test/harness/app.dart , mixin TestHarnessORMMixin and override two methods: class Harness extends TestHarness<HeroesChannel> with TestHarnessORMMixin { @override ManagedContext get context => channel.context; @override Future onSetUp() async { await resetData(); } } The mixin gives our harness the method resetData . This method deletes everything from the test database and uploads the schema in a pristine state. By calling this method in onSetUp , our test harness will reset data before each test. !!! tip \"New Project Templates\" Using the -t command-line argument with conduit create allows you to select a template. Templates like db and db_and_auth have a test harness that already mixes in TestHarnessORMMixin . Now, we can run this test by right-clicking on the main function in hero_controller_test.dart and selecting Run tests in 'hero_controller_test.dart' . A panel will appear that shows the results of your tests. You'll see a green checkmark next to the test in this panel to show that your test succeeded. If your test did not succeed, the reason will be printed to the console. If your test failed because of an error in your code, you will also be able to see the stack trace of the error. !!! tip \"Running Tests\" You can also run all of your tests for an application by running pub run test from your project's directory. You can re-run a test with the green play button at the top right corner of the screen, or the keyboard shortcut associated with it (this shortcut varies depending on your installation). We should expect that more than just the status code is correct. Let's verify that the body is a list, where every element is an object that contains an id and name. Update your test: test(\"GET /heroes returns 200 OK\", () async { final response = await harness.agent.get(\"/heroes\"); expectResponse(response, 200, body: everyElement({ \"id\": greaterThan(0), \"name\": isString, })); }); This expectation ensures that the body is a list and that every element is an object with a id greater than 0, and a name that is a string. When expecting a body value, the body is first decoded from its content-type before the expectation. In practice, this means that your JSON response body is deserialized into an object or list. Your expectations of the body are built from Dart objects like List and Object that deserialized from JSON. !!! tip \"Matchers\" The function everyElement is a Matcher from package:matcher . There are many types of matchers for all kinds of scenarios, and package:conduit_test includes Conduit-specific matchers. See the conduit_test API Reference for all Conduit matchers. This test actually has an error that we will fix in it by using another matcher. Right now, this endpoint returns an empty list because there are no heroes in the database! Let's insert a hero before we make this request, and also expect that there is at least one element in the body. Make sure to import hero.dart at the top of the file! import 'package:heroes/model/hero.dart'; import 'harness/app.dart'; void main() { final harness = Harness()..install(); test(\"GET /heroes returns 200 OK\", () async { final query = Query<Hero>(harness.application.channel.context) ..values.name = \"Bob\"; await query.insert(); final response = await harness.agent.get(\"/heroes\"); expectResponse(response, 200, body: allOf([ hasLength(greaterThan(0)), everyElement({ \"id\": greaterThan(0), \"name\": isString, }) ])); }); } This test first inserts a hero named 'Bob' before getting all heroes. We compose a matcher where each element has to match the expected list, but also have a length greater than 0. Re-run your tests, and they should still pass. Writing More Tests Let's write a few more tests for when we POST /heroes . In the first test, we'll make a mistake on purpose to see how tests fail. Add the following test: test(\"POST /heroes returns 200 OK\", () async { final response = await harness.agent.post(\"/heroes\", body: { \"name\": \"Fred\" }); expectResponse(response, 200, body: { \"id\": greaterThan(0), \"name\": \"Bob\" }); }); This test creates a hero named 'Fred', but expects that the returned hero has the name 'Bob'. When we run the test, we see this test failure: Expected: --- HTTP Response --- - Status code must be 200 - Headers can be anything - Body after decoding must be: {'id': <a value greater than <0>>, 'name': 'Bob'} --------------------- Actual: TestResponse:<----------- - Status code is 200 - Headers are the following: - content-encoding: gzip - content-length: 42 - x-frame-options: SAMEORIGIN - content-type: application/json; charset=utf-8 - x-xss-protection: 1; mode=block - x-content-type-options: nosniff - server: conduit/1 Decoded body is: {id: 1, name: Fred} ------------------------- > Which: the body differs for the following reasons: was 'Fred' instead of 'Bob' at location ['name'] The 'Expected' value tells us the response we expected - that it has a status code of 200, any headers and the body must have a certain structure. The 'Actual' value tells us what the actual response was - a 200 OK, a bunch of headers, and a body a hero named 'Fred'. 'Which' tells us exactly what went wrong - we were expecting 'Bob', not 'Fred'. Let's update our test to expect 'Fred'. test(\"POST /heroes returns 200 OK\", () async { final response = await harness.agent.post(\"/heroes\", body: { \"name\": \"Fred\" }); expectResponse(response, 200, body: { \"id\": greaterThan(0), \"name\": \"Fred\" }); }); We shouldn't just test success cases. Let's also expect that if we try and insert a hero with the same name, we get a 409 error response. test(\"POST /heroes returns 200 OK\", () async { await harness.agent.post(\"/heroes\", body: { \"name\": \"Fred\" }); final badResponse = await harness.agent.post(\"/heroes\", body: { \"name\": \"Fred\" }); expectResponse(badResponse, 409); }); In this test, we request two 'Fred' heroes be created, and the second request fails with a 409 because name is a unique property of a hero. Notice that the first request didn't fail, even though we had created a 'Fred' hero in the previous test - that's because we reset the database for each test in our harness.","title":"4. Configuration and Testing"},{"location":"tut/writing-tests/#configuration-and-writing-tests","text":"We will continue to build on the last chapter's project, heroes , by writing automated tests for it. We will also set up configurable environments for our application.","title":"Configuration and Writing Tests"},{"location":"tut/writing-tests/#application-configuration","text":"Right now, our application hardcodes its database connection information. This is bad because we want to use a different database when we're testing, running locally and running in production. It's also bad because we'd have to check our database password into version control. We can create a configuration file to store values like database connection information, and use a different configuration file for each environment. The heroes application needs to be able to configure the username, password, host port and name of the database it uses. Open the file config.yaml , which is empty, and enter the following key-value pairs: database: host: localhost port: 5432 username: heroes_user password: password databaseName: heroes These are the same values we used in our application channel. We'll want to replace the hardcoded values with whatever values are in this file. In lib/channel.dart , declare a new class at the bottom of the file: class HeroConfig extends Configuration { HeroConfig(String path): super.fromFile(File(path)); DatabaseConfiguration database; } A Configuration subclass declares the expected properties of a configuration file. HeroConfig has one property named database - this matches the name of our top-level key in config.yaml . A DatabaseConfiguration is a built-in configuration type that has properties for host , port , username , password and databaseName . We can load config.yaml into a HeroConfig because they have the same structure and all of the key names match the property names in our configuration types. !!! tip \"Invalid Configuration\" If your configuration file and configuration object don't have a matching structure, an error will be thrown when your application starts and tell you which values are missing. Let's load config.yaml and use its values to set up our database connection by replacing the prepare method in lib/channel.dart : @override Future prepare() async { logger.onRecord.listen( (rec) => print(\"$rec ${rec.error ?? \"\"} ${rec.stackTrace ?? \"\"}\")); final config = HeroConfig(options.configurationFilePath); final dataModel = ManagedDataModel.fromCurrentMirrorSystem(); final persistentStore = PostgreSQLPersistentStore.fromConnectionInfo( config.database.username, config.database.password, config.database.host, config.database.port, config.database.databaseName); context = ManagedContext(dataModel, persistentStore); } When our application starts, our channel has access to an options property that has the command-line arguments that started the application. By default, the value of configurationFilePath is config.yaml (it corresponds to --config-path in conduit serve ). When config.yaml is read, its values are read into a HeroConfig and are used to configure our database connection. Re-run your application and it'll work exactly the same as it did before - except now, we can substitute databases depending on how we run the application.","title":"Application Configuration"},{"location":"tut/writing-tests/#configuration-template","text":"You shouldn't check config.yaml into version control because it contains sensitive information. However, it is important to check in a configuration source file . A configuration source file has the same structure as HeroConfig , but it has values for your test environment - both locally and with continuous integration tools. It is also used as a template for your deployed configuration files. !!! tip \"Sensitive Information\" Use a platform like Heroku or Kubernetes. You can store sensitive information in secured environment variables. You can substitute environment variables in a configuration file by using the variable's name with a $ prefix as a value, e.g. password: $DATABASE_PASSWORD . A configuration source file should be named config.src.yaml , and one currently exists as an empty file in your project. Enter the following configuration into this file: database: host: localhost port: 5432 username: dart password: dart databaseName: dart_test This file has the expected structure, but has different values for the database information (for a database that we will create shortly). In the next section, we'll use this configuration file to run our automated tests.","title":"Configuration Template"},{"location":"tut/writing-tests/#testing-in-conduit","text":"So far, we've tested our application by using a web application. This isn't a good way to test an application. A better way is to write automated test cases. An automated test case not only tests the code you are working on, but makes sure the code you've worked on in the past continues to work as you make changes. A good development practice is to configure TravisCI to run all of your tests for every code change. Because testing is so important, there is a package for writing Conduit application tests. In this chapter, we will use this package to make sure our hero endpoints are working correctly. !!! note \"package:conduit_test\" The package conduit_test and test was already added to your pubspec.yaml file as a test dependency by the template generator. In all Dart applications, a test suite is a Dart script with a main function. In this function, the test function is called multiple times to register expectations. A test passes if all of your expectations are met. An example Dart test looks like this: import 'package:test/test.dart'; void main() { test(\"1+1 = 2\", () { // Expect that 1 + 1 = 2 expect(1 + 1, equals(2)); }); }","title":"Testing in Conduit"},{"location":"tut/writing-tests/#setting-up-your-development-environment","text":"In config.src.yaml , we target the database dart:dart@localhost:5432/dart_test . This is a 'special' database that is used by all Conduit applications for automated testing (by default). When your application is tested, its tables are temporarily added to this database and then discarded after tests complete. This means that no data is stored in between test runs. Create this database by running psql and enter the following SQL: CREATE DATABASE dart_test; CREATE USER dart WITH createdb; ALTER USER dart WITH password 'dart'; GRANT all ON database dart_test TO dart; !!! tip \"dart_test Database\" You only have to create this database once per machine, and in any continuous integration scripts. All of your Conduit applications will use this database for automated testing. Fun fact - you can run multiple application's tests simultaneously using this database because the tables only exist for the database connection that created them.","title":"Setting up your Development Environment"},{"location":"tut/writing-tests/#writing-your-first-test","text":"We will create a test suite to make sure that all hero endpoints return the right data, and make the right changes. Create a new file named test/hero_controller_test.dart . !!! warning \"Test Files Names and Locations\" A test file must end in _test.dart and must be in the test/ directory of your project, or it won't be run. At the top of this file, import your application's test harness and enter the following main function: import 'harness/app.dart'; void main() { final harness = Harness()..install(); } A test harness is an object that starts and stops your application when running a test suite, as long as you call its install method. This harness can then send requests to your application, and you can expect that the response is correct. Add a test to the main function that makes sure we get back a 200 OK when we call GET /heroes : void main() { final harness = Harness()..install(); test(\"GET /heroes returns 200 OK\", () async { final response = await harness.agent.get(\"/heroes\"); expectResponse(response, 200); }); } A harness has an Agent that can send requests to the application it started. Methods like get and post take a path (and optionally headers and a body) and return a response object. This object is used in expectResponse to validate the status code and other values. Tests in Conduit are written in this way: make a request, expect that the response is intended. Because our application makes database queries, we have to to upload our database schema to the test database before each test. Fortunately, this is something our test harness can also do. In test/harness/app.dart , mixin TestHarnessORMMixin and override two methods: class Harness extends TestHarness<HeroesChannel> with TestHarnessORMMixin { @override ManagedContext get context => channel.context; @override Future onSetUp() async { await resetData(); } } The mixin gives our harness the method resetData . This method deletes everything from the test database and uploads the schema in a pristine state. By calling this method in onSetUp , our test harness will reset data before each test. !!! tip \"New Project Templates\" Using the -t command-line argument with conduit create allows you to select a template. Templates like db and db_and_auth have a test harness that already mixes in TestHarnessORMMixin . Now, we can run this test by right-clicking on the main function in hero_controller_test.dart and selecting Run tests in 'hero_controller_test.dart' . A panel will appear that shows the results of your tests. You'll see a green checkmark next to the test in this panel to show that your test succeeded. If your test did not succeed, the reason will be printed to the console. If your test failed because of an error in your code, you will also be able to see the stack trace of the error. !!! tip \"Running Tests\" You can also run all of your tests for an application by running pub run test from your project's directory. You can re-run a test with the green play button at the top right corner of the screen, or the keyboard shortcut associated with it (this shortcut varies depending on your installation). We should expect that more than just the status code is correct. Let's verify that the body is a list, where every element is an object that contains an id and name. Update your test: test(\"GET /heroes returns 200 OK\", () async { final response = await harness.agent.get(\"/heroes\"); expectResponse(response, 200, body: everyElement({ \"id\": greaterThan(0), \"name\": isString, })); }); This expectation ensures that the body is a list and that every element is an object with a id greater than 0, and a name that is a string. When expecting a body value, the body is first decoded from its content-type before the expectation. In practice, this means that your JSON response body is deserialized into an object or list. Your expectations of the body are built from Dart objects like List and Object that deserialized from JSON. !!! tip \"Matchers\" The function everyElement is a Matcher from package:matcher . There are many types of matchers for all kinds of scenarios, and package:conduit_test includes Conduit-specific matchers. See the conduit_test API Reference for all Conduit matchers. This test actually has an error that we will fix in it by using another matcher. Right now, this endpoint returns an empty list because there are no heroes in the database! Let's insert a hero before we make this request, and also expect that there is at least one element in the body. Make sure to import hero.dart at the top of the file! import 'package:heroes/model/hero.dart'; import 'harness/app.dart'; void main() { final harness = Harness()..install(); test(\"GET /heroes returns 200 OK\", () async { final query = Query<Hero>(harness.application.channel.context) ..values.name = \"Bob\"; await query.insert(); final response = await harness.agent.get(\"/heroes\"); expectResponse(response, 200, body: allOf([ hasLength(greaterThan(0)), everyElement({ \"id\": greaterThan(0), \"name\": isString, }) ])); }); } This test first inserts a hero named 'Bob' before getting all heroes. We compose a matcher where each element has to match the expected list, but also have a length greater than 0. Re-run your tests, and they should still pass.","title":"Writing Your First Test"},{"location":"tut/writing-tests/#writing-more-tests","text":"Let's write a few more tests for when we POST /heroes . In the first test, we'll make a mistake on purpose to see how tests fail. Add the following test: test(\"POST /heroes returns 200 OK\", () async { final response = await harness.agent.post(\"/heroes\", body: { \"name\": \"Fred\" }); expectResponse(response, 200, body: { \"id\": greaterThan(0), \"name\": \"Bob\" }); }); This test creates a hero named 'Fred', but expects that the returned hero has the name 'Bob'. When we run the test, we see this test failure: Expected: --- HTTP Response --- - Status code must be 200 - Headers can be anything - Body after decoding must be: {'id': <a value greater than <0>>, 'name': 'Bob'} --------------------- Actual: TestResponse:<----------- - Status code is 200 - Headers are the following: - content-encoding: gzip - content-length: 42 - x-frame-options: SAMEORIGIN - content-type: application/json; charset=utf-8 - x-xss-protection: 1; mode=block - x-content-type-options: nosniff - server: conduit/1 Decoded body is: {id: 1, name: Fred} ------------------------- > Which: the body differs for the following reasons: was 'Fred' instead of 'Bob' at location ['name'] The 'Expected' value tells us the response we expected - that it has a status code of 200, any headers and the body must have a certain structure. The 'Actual' value tells us what the actual response was - a 200 OK, a bunch of headers, and a body a hero named 'Fred'. 'Which' tells us exactly what went wrong - we were expecting 'Bob', not 'Fred'. Let's update our test to expect 'Fred'. test(\"POST /heroes returns 200 OK\", () async { final response = await harness.agent.post(\"/heroes\", body: { \"name\": \"Fred\" }); expectResponse(response, 200, body: { \"id\": greaterThan(0), \"name\": \"Fred\" }); }); We shouldn't just test success cases. Let's also expect that if we try and insert a hero with the same name, we get a 409 error response. test(\"POST /heroes returns 200 OK\", () async { await harness.agent.post(\"/heroes\", body: { \"name\": \"Fred\" }); final badResponse = await harness.agent.post(\"/heroes\", body: { \"name\": \"Fred\" }); expectResponse(badResponse, 409); }); In this test, we request two 'Fred' heroes be created, and the second request fails with a 409 because name is a unique property of a hero. Notice that the first request didn't fail, even though we had created a 'Fred' hero in the previous test - that's because we reset the database for each test in our harness.","title":"Writing More Tests"}]}